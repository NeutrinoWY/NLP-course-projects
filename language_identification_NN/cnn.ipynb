{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-IeIpm79Fqi",
    "outputId": "951e977b-4368-4b9f-d341-2070e8f3b743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "ynDK5thyzl_v"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import csv, re, sys\n",
    "from io import StringIO\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import emoji, string\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from keras import layers, utils\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, BatchNormalization, Activation, Concatenate, Dense, Dropout, Input, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "#from keras.models import load_model\n",
    "#from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "import math\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "LdU0eW2fbQjs"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1\n",
    "EMBEDDING_SIZE = 100\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbiXkA8QAeyV"
   },
   "source": [
    "# **Define functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "-4R3thLDAdZu"
   },
   "outputs": [],
   "source": [
    "def load_dataset(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.content.decode('utf8')\n",
    "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
    "    df.columns = ['tweet', 'label']\n",
    "    return df\n",
    "\n",
    "\n",
    "# clean text data\n",
    "def clean_text(text):\n",
    "  # remove url\n",
    "  text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "  # remove @sb. \n",
    "  text = re.sub('@\\S+|@\\S+', '', text)\n",
    "  # remove #sth.\n",
    "  text = re.sub('#\\S+|#\\S+','',text)\n",
    "  # remove numbers\n",
    "  text = re.sub(r'[0-9]+','',text)\n",
    "  # remove other punctuations\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "  # remove emoji\n",
    "  text = ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "  return text\n",
    "\n",
    "\n",
    "def get_length(train, test):\n",
    "  \"\"\"get the max, mean, median character lengths of the tweets.\"\"\"\n",
    "  lengths_tr = [len(s.strip()) for s in train['tweet'] ]\n",
    "  lengths_te = [len(s.strip()) for s in test['tweet']]\n",
    "  print(\"maximum lengths in training and test data:\",max(lengths_tr), max(lengths_te))\n",
    "  print(\"average lengths in training and test data:\", np.mean(lengths_tr), np.mean(lengths_te))\n",
    "  print(\"medium lengths in training and test data:\", np.median(lengths_tr), np.median(lengths_te))\n",
    "  return max(max(lengths_tr), max(lengths_te))\n",
    "\n",
    "\n",
    "def preprocess(df_train, df_test, MAX_LENGTH):\n",
    "  \"\"\"tokenize, character to index to sequence the text, one hot encoding to vectorize labels.\"\"\"\n",
    "  text_train = df_train['tweet']\n",
    "  text_test = df_test['tweet']\n",
    "  label_train = df_train['label']\n",
    "  label_test = df_test['label']\n",
    "\n",
    "  # character-level tokenization\n",
    "  tokenizer = Tokenizer(num_words=None, lower=True, char_level=True)  \n",
    "  tokenizer.fit_on_texts(text_train)\n",
    "  X_train = tokenizer.texts_to_sequences(text_train)\n",
    "  X_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "  char_size = len(tokenizer.word_index) + 1 \n",
    "\n",
    "  print(text_train[5000])\n",
    "  print(X_train[5000])\n",
    "\n",
    "  X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
    "  X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
    "\n",
    "  # one-hot encoding for labels\n",
    "  enc = LabelBinarizer().fit(label_train)\n",
    "  y_train = enc.transform(label_train)\n",
    "  y_test = enc.transform(label_test)\n",
    "\n",
    "  return X_train, y_train, X_test, label_test, char_size\n",
    "  \n",
    "\n",
    "\n",
    "def create_model(num_filters, kernel_size, strides=1, char_size=5039, EMBEDING_SIZE=100, MAX_LENGTH=100):\n",
    "    \"\"\"create a CNN model, use it in grid search cv, to get best num_filters and kernel size.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(char_size, EMBEDDING_SIZE, input_length=MAX_LENGTH))\n",
    "    model.add(layers.Conv1D(num_filters, kernel_size, strides=1, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(69, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_model(X,y,char_size,pooling='GlobalMax', dropout=True, strides=1, batch_size=32, optim='adam',epochs=300):\n",
    "    \"\"\"train models by choosing different pooling strategy, dropout, batch size and optimizer.\"\"\"\n",
    "\n",
    "    # initialize CNN model\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=char_size, output_dim=EMBEDDING_SIZE, input_length=MAX_LENGTH, trainable=False))\n",
    "    model.add(Conv1D(128, 3, activation='relu', strides=strides)) \n",
    "    if pooling=='GlobalMax':\n",
    "      model.add(GlobalMaxPooling1D())\n",
    "    elif pooling=='GlobalAve':\n",
    "      model.add(GlobalAveragePooling1D())\n",
    "    if dropout:\n",
    "      model.add(Dropout(0.2))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(69, activation='softmax'))\n",
    "    model.compile(optimizer=optim, loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # split dataset into training and validation sets\n",
    "    Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE )\n",
    "\n",
    "    # define early stop\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "\n",
    "    # fit model on training set and validate on validation set\n",
    "    history = model.fit(Xtrain,ytrain,epochs=epochs,verbose=2,validation_data=(Xval,yval), callbacks=[es],batch_size=batch_size)\n",
    "    loss, accuracy = model.evaluate(Xtrain, ytrain,verbose=1)\n",
    "    print(\"Training loss: {:.4f}, Traning accuracy: {:.4f}\".format(loss, accuracy))\n",
    "    loss, accuracy = model.evaluate(Xval,yval,verbose=1)\n",
    "    print(\"Validation loss:  {:.4f}, Validation accuracy: {:.4f}\".format(loss, accuracy))\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "def prediction(model, X_test, label_test, unique_labels):\n",
    "  \"\"\"predict test labels, calculate accuracy.\"\"\"\n",
    "  y_pred_probs = model.predict(X_test)\n",
    "  #print(y_pred_probs[0])\n",
    "  y_pred_idx = [np.argmax(y_pred_probs[i]) for i in range(len(y_pred_probs))]\n",
    "  y_pred_label = [unique_labels[idx] for idx in y_pred_idx]\n",
    "  accuracy = accuracy_score(y_pred_label, label_test)\n",
    "  print(\"Test Accuracy is: {:.4f}\".format(accuracy))\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjjza8k5xkwu"
   },
   "source": [
    "# **Load files into dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "kj4_cIgho3Qt"
   },
   "outputs": [],
   "source": [
    "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
    "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "BCLdrs43pJC1"
   },
   "outputs": [],
   "source": [
    "df_train_dev = load_dataset(url_train_dev)\n",
    "df_test = load_dataset(url_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBowmpaI6t8V"
   },
   "source": [
    "# **Inspect the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULdxA6w11CEn",
    "outputId": "8c440592-60ee-466f-f7cb-5c3062d817ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52675 entries, 0 to 52674\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   52675 non-null  object\n",
      " 1   label   52675 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 823.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "WcekVCla1zMH",
    "outputId": "50d0ce24-72e4-4b0e-a22e-7abd91deb799"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يا ابو سلو عرفتني</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...    ar\n",
       "1  فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...    ar\n",
       "2  ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...    ar\n",
       "3                                  يا ابو سلو عرفتني    ar\n",
       "4  ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...    ar"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m71TMZ0W1xWK",
    "outputId": "9a9103eb-7bc0-40bf-dee6-6de310c230eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tweet\n",
      "label         \n",
      "ar        2199\n",
      "ar_LATN     12\n",
      "az           1\n",
      "bg           2\n",
      "bn           8\n",
      "bs           4\n",
      "ca          22\n",
      "cs           4\n",
      "cy           1\n",
      "da           7\n",
      "de         171\n",
      "dv           1\n",
      "el          28\n",
      "en       18508\n",
      "es        5930\n",
      "et           2\n",
      "fa          18\n",
      "fi          15\n",
      "fr         946\n",
      "gl           3\n",
      "ha           1\n",
      "he          27\n",
      "hi          16\n",
      "hi-Latn     15\n",
      "hr           5\n",
      "ht           2\n",
      "hu          15\n",
      "hy           2\n",
      "id        3006\n",
      "is           1\n",
      "it         339\n",
      "ja       10421\n",
      "ja_LATN      1\n",
      "jv          10\n",
      "km           2\n",
      "ko         458\n",
      "ko_LATN      1\n",
      "ms         119\n",
      "ne           5\n",
      "nl         182\n",
      "no          11\n",
      "pl          93\n",
      "ps           1\n",
      "ps_LATN      1\n",
      "pt        2878\n",
      "ro          12\n",
      "ru         978\n",
      "si           1\n",
      "sl           2\n",
      "sq           9\n",
      "sr          22\n",
      "su          10\n",
      "sv          54\n",
      "sw           6\n",
      "ta           9\n",
      "ta_LATN      1\n",
      "th         462\n",
      "tl         320\n",
      "tn           1\n",
      "tr         669\n",
      "uk          16\n",
      "und       4537\n",
      "ur           7\n",
      "ur_LATN     12\n",
      "vi          16\n",
      "wo           1\n",
      "xh           1\n",
      "zh-CN       25\n",
      "zh-TW       10\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.groupby(['label']).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQuE9fKn1--R",
    "outputId": "c45f1443-75b8-4ac4-cfaa-36658c82d905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = df_train_dev.label.unique()\n",
    "len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUb1ZXhI_9ZB",
    "outputId": "82fe2b50-cc07-49cf-ccd9-9da6154ca123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique labels in test set\n",
    "len(df_test.label.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwIIsmwK22Uf"
   },
   "source": [
    "# **Clean the data**\n",
    "* remove url\n",
    "* remove \"#topics\", \"@sb\"\n",
    "* remove numbers\n",
    "* remove punctuations\n",
    "* remove emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "aOgTx2_r20cx"
   },
   "outputs": [],
   "source": [
    "df_train_dev['tweet'] = df_train_dev['tweet'].apply(clean_text)\n",
    "df_test['tweet'] = df_test['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFmxxWTgTLJO",
    "outputId": "02b6c676-12c6-4c10-b671-66d5a2570652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum lengths in training and test data: 5979 3602\n",
      "average lengths in training and test data: 43.219003322259134 43.388658784547026\n",
      "medium lengths in training and test data: 34.0 35.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5979"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# character length of tweets\n",
    "get_length(df_train_dev, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qTfwiFmNRRI"
   },
   "source": [
    "#  **Preprocess / vectorization**\n",
    "* one-hot encoding to vectorize labels\n",
    "* character indices to encode texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JyYzQFghx1m",
    "outputId": "bf5cc2bc-9ecd-47aa-99ca-a6876b9a269d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at the very least I ate the whole Slayer burger\n",
      "[3, 6, 1, 6, 14, 2, 1, 23, 2, 9, 18, 1, 10, 2, 3, 8, 6, 1, 5, 1, 3, 6, 2, 1, 6, 14, 2, 1, 21, 14, 4, 10, 2, 1, 8, 10, 3, 18, 2, 9, 1, 19, 11, 9, 16, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, label_test, char_size = preprocess(df_train_dev, df_test,MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULR-m1SwMh7Q",
    "outputId": "d3ad95a9-970e-478c-aaa1-71e2beb6d6a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5039"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjU2jcNj92xn"
   },
   "source": [
    "# **Hyperparameter Search by RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ax0g_VhLq6l"
   },
   "outputs": [],
   "source": [
    "param_grid = dict(num_filters=[64, 128],\n",
    "                  kernel_size=[3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C79nM9hUALPY",
    "outputId": "ca0631da-eb37-4ec5-da78-ceccf936d39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 20.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=4, error_score=nan,\n",
      "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82e0c276d8>,\n",
      "                   iid='deprecated', n_iter=1, n_jobs=None,\n",
      "                   param_distributions={'kernel_size': [3, 5],\n",
      "                                        'num_filters': [64, 128]},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=1)\n",
      "0.6232661493122578\n",
      "{'num_filters': 128, 'kernel_size': 3}\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model,\n",
    "                            epochs=40, batch_size=32,\n",
    "                            verbose=False)\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=4, verbose=1, n_iter=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid_result)\n",
    "print(grid_result.best_score_)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7laxpj1rzx9"
   },
   "source": [
    "# **Train the Anchor Model and Predict Test Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeEthiWMCRFI",
    "outputId": "4c2d0518-db24-4cae-9166-95d475fb875f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_27 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 0.9456 - categorical_accuracy: 0.7446 - val_loss: 0.4965 - val_categorical_accuracy: 0.8617\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 0.4938 - categorical_accuracy: 0.8637 - val_loss: 0.3778 - val_categorical_accuracy: 0.8942\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 0.4048 - categorical_accuracy: 0.8869 - val_loss: 0.3338 - val_categorical_accuracy: 0.9017\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 0.3584 - categorical_accuracy: 0.8987 - val_loss: 0.3064 - val_categorical_accuracy: 0.9099\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.3254 - categorical_accuracy: 0.9073 - val_loss: 0.2853 - val_categorical_accuracy: 0.9161\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 0.3051 - categorical_accuracy: 0.9120 - val_loss: 0.2822 - val_categorical_accuracy: 0.9175\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.2850 - categorical_accuracy: 0.9163 - val_loss: 0.2661 - val_categorical_accuracy: 0.9198\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.2729 - categorical_accuracy: 0.9198 - val_loss: 0.2579 - val_categorical_accuracy: 0.9232\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.2603 - categorical_accuracy: 0.9227 - val_loss: 0.2457 - val_categorical_accuracy: 0.9262\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 0.2477 - categorical_accuracy: 0.9256 - val_loss: 0.2456 - val_categorical_accuracy: 0.9244\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 0.2366 - categorical_accuracy: 0.9265 - val_loss: 0.2409 - val_categorical_accuracy: 0.9271\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.2270 - categorical_accuracy: 0.9302 - val_loss: 0.2369 - val_categorical_accuracy: 0.9281\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.2196 - categorical_accuracy: 0.9324 - val_loss: 0.2293 - val_categorical_accuracy: 0.9306\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.2139 - categorical_accuracy: 0.9328 - val_loss: 0.2298 - val_categorical_accuracy: 0.9328\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.2095 - categorical_accuracy: 0.9347 - val_loss: 0.2309 - val_categorical_accuracy: 0.9307\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.2032 - categorical_accuracy: 0.9365 - val_loss: 0.2304 - val_categorical_accuracy: 0.9296\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.1987 - categorical_accuracy: 0.9371 - val_loss: 0.2281 - val_categorical_accuracy: 0.9329\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.1932 - categorical_accuracy: 0.9400 - val_loss: 0.2335 - val_categorical_accuracy: 0.9314\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.1913 - categorical_accuracy: 0.9389 - val_loss: 0.2291 - val_categorical_accuracy: 0.9321\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.1856 - categorical_accuracy: 0.9415 - val_loss: 0.2282 - val_categorical_accuracy: 0.9326\n",
      "Epoch 21/300\n",
      "1317/1317 - 4s - loss: 0.1825 - categorical_accuracy: 0.9405 - val_loss: 0.2236 - val_categorical_accuracy: 0.9345\n",
      "Epoch 22/300\n",
      "1317/1317 - 4s - loss: 0.1756 - categorical_accuracy: 0.9440 - val_loss: 0.2304 - val_categorical_accuracy: 0.9344\n",
      "Epoch 23/300\n",
      "1317/1317 - 4s - loss: 0.1736 - categorical_accuracy: 0.9439 - val_loss: 0.2236 - val_categorical_accuracy: 0.9341\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.1715 - categorical_accuracy: 0.9444 - val_loss: 0.2285 - val_categorical_accuracy: 0.9345\n",
      "Epoch 25/300\n",
      "1317/1317 - 4s - loss: 0.1697 - categorical_accuracy: 0.9443 - val_loss: 0.2237 - val_categorical_accuracy: 0.9367\n",
      "Epoch 26/300\n",
      "1317/1317 - 4s - loss: 0.1677 - categorical_accuracy: 0.9446 - val_loss: 0.2292 - val_categorical_accuracy: 0.9354\n",
      "Epoch 27/300\n",
      "1317/1317 - 4s - loss: 0.1653 - categorical_accuracy: 0.9458 - val_loss: 0.2333 - val_categorical_accuracy: 0.9342\n",
      "Epoch 28/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.1598 - categorical_accuracy: 0.9478 - val_loss: 0.2365 - val_categorical_accuracy: 0.9308\n",
      "Epoch 00028: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1170 - categorical_accuracy: 0.9630\n",
      "Training loss: 0.1170, Traning accuracy: 0.9630\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.2236 - categorical_accuracy: 0.9341\n",
      "Validation loss:  0.2236, Validation accuracy: 0.9341\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9291362301378115"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and validate model\n",
    "model_an = get_model(X_train, y_train, char_size)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model_an, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khG39SrCr8HD"
   },
   "source": [
    "# **Change Pooling Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blhM2rCIsAYg",
    "outputId": "0df8bd64-1c83-4842-b1cc-e7b2eff48fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 1.4130 - categorical_accuracy: 0.6037 - val_loss: 0.9605 - val_categorical_accuracy: 0.7393\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 0.9407 - categorical_accuracy: 0.7301 - val_loss: 0.7974 - val_categorical_accuracy: 0.7655\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 0.8245 - categorical_accuracy: 0.7595 - val_loss: 0.7153 - val_categorical_accuracy: 0.7865\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 0.7461 - categorical_accuracy: 0.7785 - val_loss: 0.6545 - val_categorical_accuracy: 0.8056\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.6881 - categorical_accuracy: 0.7946 - val_loss: 0.6003 - val_categorical_accuracy: 0.8191\n",
      "Epoch 6/300\n",
      "1317/1317 - 5s - loss: 0.6341 - categorical_accuracy: 0.8137 - val_loss: 0.5522 - val_categorical_accuracy: 0.8341\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.6005 - categorical_accuracy: 0.8242 - val_loss: 0.5193 - val_categorical_accuracy: 0.8506\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.5615 - categorical_accuracy: 0.8358 - val_loss: 0.4897 - val_categorical_accuracy: 0.8605\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.5318 - categorical_accuracy: 0.8446 - val_loss: 0.4649 - val_categorical_accuracy: 0.8691\n",
      "Epoch 10/300\n",
      "1317/1317 - 5s - loss: 0.5105 - categorical_accuracy: 0.8525 - val_loss: 0.4526 - val_categorical_accuracy: 0.8717\n",
      "Epoch 11/300\n",
      "1317/1317 - 5s - loss: 0.4893 - categorical_accuracy: 0.8572 - val_loss: 0.4366 - val_categorical_accuracy: 0.8754\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.4730 - categorical_accuracy: 0.8637 - val_loss: 0.4238 - val_categorical_accuracy: 0.8797\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.4565 - categorical_accuracy: 0.8684 - val_loss: 0.4031 - val_categorical_accuracy: 0.8873\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.4395 - categorical_accuracy: 0.8717 - val_loss: 0.3944 - val_categorical_accuracy: 0.8877\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.4250 - categorical_accuracy: 0.8758 - val_loss: 0.3785 - val_categorical_accuracy: 0.8934\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.4160 - categorical_accuracy: 0.8785 - val_loss: 0.3772 - val_categorical_accuracy: 0.8939\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.4007 - categorical_accuracy: 0.8840 - val_loss: 0.3656 - val_categorical_accuracy: 0.8959\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.3925 - categorical_accuracy: 0.8857 - val_loss: 0.3570 - val_categorical_accuracy: 0.8997\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.3843 - categorical_accuracy: 0.8876 - val_loss: 0.3479 - val_categorical_accuracy: 0.9035\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.3721 - categorical_accuracy: 0.8919 - val_loss: 0.3421 - val_categorical_accuracy: 0.9042\n",
      "Epoch 21/300\n",
      "1317/1317 - 4s - loss: 0.3678 - categorical_accuracy: 0.8912 - val_loss: 0.3376 - val_categorical_accuracy: 0.9062\n",
      "Epoch 22/300\n",
      "1317/1317 - 4s - loss: 0.3597 - categorical_accuracy: 0.8949 - val_loss: 0.3363 - val_categorical_accuracy: 0.9055\n",
      "Epoch 23/300\n",
      "1317/1317 - 4s - loss: 0.3513 - categorical_accuracy: 0.8964 - val_loss: 0.3248 - val_categorical_accuracy: 0.9100\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.3422 - categorical_accuracy: 0.8996 - val_loss: 0.3269 - val_categorical_accuracy: 0.9089\n",
      "Epoch 25/300\n",
      "1317/1317 - 4s - loss: 0.3350 - categorical_accuracy: 0.9009 - val_loss: 0.3299 - val_categorical_accuracy: 0.9097\n",
      "Epoch 26/300\n",
      "1317/1317 - 4s - loss: 0.3297 - categorical_accuracy: 0.9023 - val_loss: 0.3154 - val_categorical_accuracy: 0.9141\n",
      "Epoch 27/300\n",
      "1317/1317 - 4s - loss: 0.3266 - categorical_accuracy: 0.9030 - val_loss: 0.3107 - val_categorical_accuracy: 0.9133\n",
      "Epoch 28/300\n",
      "1317/1317 - 4s - loss: 0.3177 - categorical_accuracy: 0.9056 - val_loss: 0.3063 - val_categorical_accuracy: 0.9150\n",
      "Epoch 29/300\n",
      "1317/1317 - 4s - loss: 0.3129 - categorical_accuracy: 0.9074 - val_loss: 0.3034 - val_categorical_accuracy: 0.9162\n",
      "Epoch 30/300\n",
      "1317/1317 - 4s - loss: 0.3075 - categorical_accuracy: 0.9082 - val_loss: 0.2983 - val_categorical_accuracy: 0.9185\n",
      "Epoch 31/300\n",
      "1317/1317 - 4s - loss: 0.3035 - categorical_accuracy: 0.9090 - val_loss: 0.2978 - val_categorical_accuracy: 0.9172\n",
      "Epoch 32/300\n",
      "1317/1317 - 4s - loss: 0.2974 - categorical_accuracy: 0.9103 - val_loss: 0.3050 - val_categorical_accuracy: 0.9141\n",
      "Epoch 33/300\n",
      "1317/1317 - 4s - loss: 0.2903 - categorical_accuracy: 0.9132 - val_loss: 0.2941 - val_categorical_accuracy: 0.9187\n",
      "Epoch 34/300\n",
      "1317/1317 - 4s - loss: 0.2935 - categorical_accuracy: 0.9129 - val_loss: 0.2929 - val_categorical_accuracy: 0.9210\n",
      "Epoch 35/300\n",
      "1317/1317 - 4s - loss: 0.2864 - categorical_accuracy: 0.9131 - val_loss: 0.2897 - val_categorical_accuracy: 0.9203\n",
      "Epoch 36/300\n",
      "1317/1317 - 4s - loss: 0.2849 - categorical_accuracy: 0.9145 - val_loss: 0.2873 - val_categorical_accuracy: 0.9208\n",
      "Epoch 37/300\n",
      "1317/1317 - 4s - loss: 0.2790 - categorical_accuracy: 0.9159 - val_loss: 0.2832 - val_categorical_accuracy: 0.9221\n",
      "Epoch 38/300\n",
      "1317/1317 - 4s - loss: 0.2761 - categorical_accuracy: 0.9171 - val_loss: 0.2800 - val_categorical_accuracy: 0.9241\n",
      "Epoch 39/300\n",
      "1317/1317 - 4s - loss: 0.2760 - categorical_accuracy: 0.9174 - val_loss: 0.2788 - val_categorical_accuracy: 0.9242\n",
      "Epoch 40/300\n",
      "1317/1317 - 4s - loss: 0.2711 - categorical_accuracy: 0.9175 - val_loss: 0.2789 - val_categorical_accuracy: 0.9243\n",
      "Epoch 41/300\n",
      "1317/1317 - 4s - loss: 0.2656 - categorical_accuracy: 0.9192 - val_loss: 0.2745 - val_categorical_accuracy: 0.9262\n",
      "Epoch 42/300\n",
      "1317/1317 - 4s - loss: 0.2645 - categorical_accuracy: 0.9203 - val_loss: 0.2763 - val_categorical_accuracy: 0.9237\n",
      "Epoch 43/300\n",
      "1317/1317 - 4s - loss: 0.2618 - categorical_accuracy: 0.9212 - val_loss: 0.2741 - val_categorical_accuracy: 0.9262\n",
      "Epoch 44/300\n",
      "1317/1317 - 4s - loss: 0.2604 - categorical_accuracy: 0.9212 - val_loss: 0.2702 - val_categorical_accuracy: 0.9249\n",
      "Epoch 45/300\n",
      "1317/1317 - 4s - loss: 0.2536 - categorical_accuracy: 0.9226 - val_loss: 0.2686 - val_categorical_accuracy: 0.9275\n",
      "Epoch 46/300\n",
      "1317/1317 - 4s - loss: 0.2528 - categorical_accuracy: 0.9231 - val_loss: 0.2707 - val_categorical_accuracy: 0.9260\n",
      "Epoch 47/300\n",
      "1317/1317 - 4s - loss: 0.2514 - categorical_accuracy: 0.9229 - val_loss: 0.2698 - val_categorical_accuracy: 0.9245\n",
      "Epoch 48/300\n",
      "1317/1317 - 4s - loss: 0.2497 - categorical_accuracy: 0.9240 - val_loss: 0.2679 - val_categorical_accuracy: 0.9273\n",
      "Epoch 49/300\n",
      "1317/1317 - 4s - loss: 0.2439 - categorical_accuracy: 0.9248 - val_loss: 0.2657 - val_categorical_accuracy: 0.9274\n",
      "Epoch 50/300\n",
      "1317/1317 - 4s - loss: 0.2434 - categorical_accuracy: 0.9260 - val_loss: 0.2642 - val_categorical_accuracy: 0.9276\n",
      "Epoch 51/300\n",
      "1317/1317 - 4s - loss: 0.2434 - categorical_accuracy: 0.9247 - val_loss: 0.2658 - val_categorical_accuracy: 0.9270\n",
      "Epoch 52/300\n",
      "1317/1317 - 4s - loss: 0.2409 - categorical_accuracy: 0.9267 - val_loss: 0.2641 - val_categorical_accuracy: 0.9281\n",
      "Epoch 53/300\n",
      "1317/1317 - 4s - loss: 0.2367 - categorical_accuracy: 0.9273 - val_loss: 0.2628 - val_categorical_accuracy: 0.9303\n",
      "Epoch 54/300\n",
      "1317/1317 - 4s - loss: 0.2351 - categorical_accuracy: 0.9275 - val_loss: 0.2581 - val_categorical_accuracy: 0.9298\n",
      "Epoch 55/300\n",
      "1317/1317 - 4s - loss: 0.2338 - categorical_accuracy: 0.9273 - val_loss: 0.2612 - val_categorical_accuracy: 0.9282\n",
      "Epoch 56/300\n",
      "1317/1317 - 4s - loss: 0.2317 - categorical_accuracy: 0.9285 - val_loss: 0.2570 - val_categorical_accuracy: 0.9299\n",
      "Epoch 57/300\n",
      "1317/1317 - 4s - loss: 0.2298 - categorical_accuracy: 0.9300 - val_loss: 0.2566 - val_categorical_accuracy: 0.9310\n",
      "Epoch 58/300\n",
      "1317/1317 - 4s - loss: 0.2302 - categorical_accuracy: 0.9290 - val_loss: 0.2592 - val_categorical_accuracy: 0.9291\n",
      "Epoch 59/300\n",
      "1317/1317 - 4s - loss: 0.2266 - categorical_accuracy: 0.9304 - val_loss: 0.2562 - val_categorical_accuracy: 0.9297\n",
      "Epoch 60/300\n",
      "1317/1317 - 4s - loss: 0.2256 - categorical_accuracy: 0.9309 - val_loss: 0.2562 - val_categorical_accuracy: 0.9308\n",
      "Epoch 61/300\n",
      "1317/1317 - 4s - loss: 0.2238 - categorical_accuracy: 0.9308 - val_loss: 0.2553 - val_categorical_accuracy: 0.9310\n",
      "Epoch 62/300\n",
      "1317/1317 - 4s - loss: 0.2203 - categorical_accuracy: 0.9317 - val_loss: 0.2527 - val_categorical_accuracy: 0.9308\n",
      "Epoch 63/300\n",
      "1317/1317 - 4s - loss: 0.2244 - categorical_accuracy: 0.9306 - val_loss: 0.2553 - val_categorical_accuracy: 0.9305\n",
      "Epoch 64/300\n",
      "1317/1317 - 4s - loss: 0.2175 - categorical_accuracy: 0.9324 - val_loss: 0.2543 - val_categorical_accuracy: 0.9321\n",
      "Epoch 65/300\n",
      "1317/1317 - 4s - loss: 0.2165 - categorical_accuracy: 0.9332 - val_loss: 0.2572 - val_categorical_accuracy: 0.9312\n",
      "Epoch 66/300\n",
      "1317/1317 - 4s - loss: 0.2158 - categorical_accuracy: 0.9337 - val_loss: 0.2543 - val_categorical_accuracy: 0.9307\n",
      "Epoch 67/300\n",
      "1317/1317 - 4s - loss: 0.2125 - categorical_accuracy: 0.9353 - val_loss: 0.2513 - val_categorical_accuracy: 0.9334\n",
      "Epoch 68/300\n",
      "1317/1317 - 4s - loss: 0.2125 - categorical_accuracy: 0.9328 - val_loss: 0.2579 - val_categorical_accuracy: 0.9304\n",
      "Epoch 69/300\n",
      "1317/1317 - 4s - loss: 0.2106 - categorical_accuracy: 0.9352 - val_loss: 0.2619 - val_categorical_accuracy: 0.9293\n",
      "Epoch 70/300\n",
      "1317/1317 - 4s - loss: 0.2109 - categorical_accuracy: 0.9331 - val_loss: 0.2520 - val_categorical_accuracy: 0.9326\n",
      "Epoch 71/300\n",
      "1317/1317 - 4s - loss: 0.2097 - categorical_accuracy: 0.9343 - val_loss: 0.2542 - val_categorical_accuracy: 0.9316\n",
      "Epoch 72/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.2094 - categorical_accuracy: 0.9355 - val_loss: 0.2547 - val_categorical_accuracy: 0.9311\n",
      "Epoch 00072: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1666 - categorical_accuracy: 0.9499\n",
      "Training loss: 0.1666, Traning accuracy: 0.9499\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.2513 - categorical_accuracy: 0.9334\n",
      "Validation loss:  0.2513, Validation accuracy: 0.9334\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9305670607726485"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ave = get_model(X_train, y_train, char_size, pooling='GlobalAve')\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model_ave, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjk7Pd9PNkPR"
   },
   "source": [
    "# **Remove Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5O_IHYyOUx6",
    "outputId": "71d50463-6845-4438-c378-5a96f47cf626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_28 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 0.9042 - categorical_accuracy: 0.7562 - val_loss: 0.4924 - val_categorical_accuracy: 0.8587\n",
      "Epoch 2/300\n",
      "1317/1317 - 5s - loss: 0.4371 - categorical_accuracy: 0.8818 - val_loss: 0.3943 - val_categorical_accuracy: 0.8893\n",
      "Epoch 3/300\n",
      "1317/1317 - 5s - loss: 0.3510 - categorical_accuracy: 0.9019 - val_loss: 0.3297 - val_categorical_accuracy: 0.9062\n",
      "Epoch 4/300\n",
      "1317/1317 - 5s - loss: 0.3062 - categorical_accuracy: 0.9133 - val_loss: 0.3222 - val_categorical_accuracy: 0.9053\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.2793 - categorical_accuracy: 0.9198 - val_loss: 0.3418 - val_categorical_accuracy: 0.9041\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 0.2577 - categorical_accuracy: 0.9246 - val_loss: 0.2834 - val_categorical_accuracy: 0.9182\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.2395 - categorical_accuracy: 0.9310 - val_loss: 0.2902 - val_categorical_accuracy: 0.9131\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.2236 - categorical_accuracy: 0.9340 - val_loss: 0.2871 - val_categorical_accuracy: 0.9157\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.2110 - categorical_accuracy: 0.9379 - val_loss: 0.2725 - val_categorical_accuracy: 0.9222\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 0.1998 - categorical_accuracy: 0.9400 - val_loss: 0.2767 - val_categorical_accuracy: 0.9217\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 0.1887 - categorical_accuracy: 0.9436 - val_loss: 0.2801 - val_categorical_accuracy: 0.9224\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.1787 - categorical_accuracy: 0.9455 - val_loss: 0.2848 - val_categorical_accuracy: 0.9202\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.1689 - categorical_accuracy: 0.9482 - val_loss: 0.2743 - val_categorical_accuracy: 0.9244\n",
      "Epoch 14/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.1608 - categorical_accuracy: 0.9501 - val_loss: 0.2807 - val_categorical_accuracy: 0.9238\n",
      "Epoch 00014: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1821 - categorical_accuracy: 0.9466\n",
      "Training loss: 0.1821, Traning accuracy: 0.9466\n",
      "330/330 [==============================] - 1s 3ms/step - loss: 0.2725 - categorical_accuracy: 0.9222\n",
      "Validation loss:  0.2725, Validation accuracy: 0.9222\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9186685744408465"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train, y_train, char_size, dropout=False)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq7n-tfIN6U2"
   },
   "source": [
    "# **Decrease Batch Size to 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKctlJ4-qAFt",
    "outputId": "54374cd3-d62b-4a6f-ae84-bf14ecc24751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_29 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2634/2634 - 8s - loss: 0.8168 - categorical_accuracy: 0.7781 - val_loss: 0.4345 - val_categorical_accuracy: 0.8842\n",
      "Epoch 2/300\n",
      "2634/2634 - 8s - loss: 0.4407 - categorical_accuracy: 0.8786 - val_loss: 0.3421 - val_categorical_accuracy: 0.9007\n",
      "Epoch 3/300\n",
      "2634/2634 - 8s - loss: 0.3608 - categorical_accuracy: 0.8975 - val_loss: 0.2982 - val_categorical_accuracy: 0.9142\n",
      "Epoch 4/300\n",
      "2634/2634 - 8s - loss: 0.3196 - categorical_accuracy: 0.9075 - val_loss: 0.2781 - val_categorical_accuracy: 0.9182\n",
      "Epoch 5/300\n",
      "2634/2634 - 8s - loss: 0.2949 - categorical_accuracy: 0.9131 - val_loss: 0.2782 - val_categorical_accuracy: 0.9175\n",
      "Epoch 6/300\n",
      "2634/2634 - 8s - loss: 0.2748 - categorical_accuracy: 0.9180 - val_loss: 0.2636 - val_categorical_accuracy: 0.9224\n",
      "Epoch 7/300\n",
      "2634/2634 - 8s - loss: 0.2605 - categorical_accuracy: 0.9220 - val_loss: 0.2509 - val_categorical_accuracy: 0.9274\n",
      "Epoch 8/300\n",
      "2634/2634 - 8s - loss: 0.2468 - categorical_accuracy: 0.9251 - val_loss: 0.2513 - val_categorical_accuracy: 0.9262\n",
      "Epoch 9/300\n",
      "2634/2634 - 8s - loss: 0.2375 - categorical_accuracy: 0.9260 - val_loss: 0.2441 - val_categorical_accuracy: 0.9291\n",
      "Epoch 10/300\n",
      "2634/2634 - 8s - loss: 0.2262 - categorical_accuracy: 0.9289 - val_loss: 0.2523 - val_categorical_accuracy: 0.9249\n",
      "Epoch 11/300\n",
      "2634/2634 - 8s - loss: 0.2181 - categorical_accuracy: 0.9321 - val_loss: 0.2395 - val_categorical_accuracy: 0.9295\n",
      "Epoch 12/300\n",
      "2634/2634 - 8s - loss: 0.2124 - categorical_accuracy: 0.9332 - val_loss: 0.2471 - val_categorical_accuracy: 0.9282\n",
      "Epoch 13/300\n",
      "2634/2634 - 8s - loss: 0.2042 - categorical_accuracy: 0.9346 - val_loss: 0.2469 - val_categorical_accuracy: 0.9275\n",
      "Epoch 14/300\n",
      "2634/2634 - 8s - loss: 0.1988 - categorical_accuracy: 0.9367 - val_loss: 0.2359 - val_categorical_accuracy: 0.9300\n",
      "Epoch 15/300\n",
      "2634/2634 - 8s - loss: 0.1970 - categorical_accuracy: 0.9366 - val_loss: 0.2384 - val_categorical_accuracy: 0.9301\n",
      "Epoch 16/300\n",
      "2634/2634 - 8s - loss: 0.1889 - categorical_accuracy: 0.9392 - val_loss: 0.2389 - val_categorical_accuracy: 0.9302\n",
      "Epoch 17/300\n",
      "2634/2634 - 8s - loss: 0.1892 - categorical_accuracy: 0.9382 - val_loss: 0.2390 - val_categorical_accuracy: 0.9308\n",
      "Epoch 18/300\n",
      "2634/2634 - 8s - loss: 0.1791 - categorical_accuracy: 0.9417 - val_loss: 0.2422 - val_categorical_accuracy: 0.9311\n",
      "Epoch 19/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "2634/2634 - 8s - loss: 0.1781 - categorical_accuracy: 0.9421 - val_loss: 0.2551 - val_categorical_accuracy: 0.9254\n",
      "Epoch 00019: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1372 - categorical_accuracy: 0.9567\n",
      "Training loss: 0.1372, Traning accuracy: 0.9567\n",
      "330/330 [==============================] - 1s 3ms/step - loss: 0.2359 - categorical_accuracy: 0.9300\n",
      "Validation loss:  0.2359, Validation accuracy: 0.9300\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9283831613826342"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train, y_train, char_size, batch_size=16)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAa0FdlGOzad"
   },
   "source": [
    "\n",
    "\n",
    "# **Change Strides**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1A-7vGgqU5T",
    "outputId": "ebe7eb3c-5b84-4775-c439-2fcd2ec8ab7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 20, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_30 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 1.2055 - categorical_accuracy: 0.6641 - val_loss: 0.8051 - val_categorical_accuracy: 0.7638\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 0.7787 - categorical_accuracy: 0.7734 - val_loss: 0.6689 - val_categorical_accuracy: 0.8038\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 0.6727 - categorical_accuracy: 0.8050 - val_loss: 0.6048 - val_categorical_accuracy: 0.8227\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 0.6125 - categorical_accuracy: 0.8224 - val_loss: 0.5617 - val_categorical_accuracy: 0.8357\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.5760 - categorical_accuracy: 0.8334 - val_loss: 0.5457 - val_categorical_accuracy: 0.8401\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 0.5435 - categorical_accuracy: 0.8410 - val_loss: 0.5197 - val_categorical_accuracy: 0.8480\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.5240 - categorical_accuracy: 0.8454 - val_loss: 0.5076 - val_categorical_accuracy: 0.8480\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.5019 - categorical_accuracy: 0.8518 - val_loss: 0.4994 - val_categorical_accuracy: 0.8514\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.4858 - categorical_accuracy: 0.8565 - val_loss: 0.4943 - val_categorical_accuracy: 0.8520\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 0.4706 - categorical_accuracy: 0.8580 - val_loss: 0.4873 - val_categorical_accuracy: 0.8552\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 0.4575 - categorical_accuracy: 0.8625 - val_loss: 0.4838 - val_categorical_accuracy: 0.8576\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.4503 - categorical_accuracy: 0.8647 - val_loss: 0.4717 - val_categorical_accuracy: 0.8596\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.4354 - categorical_accuracy: 0.8679 - val_loss: 0.4811 - val_categorical_accuracy: 0.8575\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.4269 - categorical_accuracy: 0.8704 - val_loss: 0.4717 - val_categorical_accuracy: 0.8597\n",
      "Epoch 15/300\n",
      "1317/1317 - 5s - loss: 0.4208 - categorical_accuracy: 0.8713 - val_loss: 0.4671 - val_categorical_accuracy: 0.8600\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.4122 - categorical_accuracy: 0.8737 - val_loss: 0.4662 - val_categorical_accuracy: 0.8622\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.4062 - categorical_accuracy: 0.8760 - val_loss: 0.4650 - val_categorical_accuracy: 0.8615\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.3981 - categorical_accuracy: 0.8781 - val_loss: 0.4628 - val_categorical_accuracy: 0.8624\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.3950 - categorical_accuracy: 0.8789 - val_loss: 0.4623 - val_categorical_accuracy: 0.8623\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.3871 - categorical_accuracy: 0.8806 - val_loss: 0.4588 - val_categorical_accuracy: 0.8630\n",
      "Epoch 21/300\n",
      "1317/1317 - 5s - loss: 0.3834 - categorical_accuracy: 0.8813 - val_loss: 0.4596 - val_categorical_accuracy: 0.8643\n",
      "Epoch 22/300\n",
      "1317/1317 - 5s - loss: 0.3784 - categorical_accuracy: 0.8804 - val_loss: 0.4669 - val_categorical_accuracy: 0.8611\n",
      "Epoch 23/300\n",
      "1317/1317 - 5s - loss: 0.3727 - categorical_accuracy: 0.8838 - val_loss: 0.4670 - val_categorical_accuracy: 0.8631\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.3700 - categorical_accuracy: 0.8844 - val_loss: 0.4660 - val_categorical_accuracy: 0.8644\n",
      "Epoch 25/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.3620 - categorical_accuracy: 0.8869 - val_loss: 0.4679 - val_categorical_accuracy: 0.8638\n",
      "Epoch 00025: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.3042 - categorical_accuracy: 0.9075\n",
      "Training loss: 0.3042, Traning accuracy: 0.9075\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.4588 - categorical_accuracy: 0.8630\n",
      "Validation loss:  0.4588, Validation accuracy: 0.8630\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.8629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8629414865577227"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train, y_train, char_size, strides=5)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UExcTlzo5QXm"
   },
   "source": [
    "# **Change Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVpKUoG65XWI",
    "outputId": "4fbea6c4-93db-442d-e9ff-e36ede1aa844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_31 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 2.4417 - categorical_accuracy: 0.3457 - val_loss: 2.0699 - val_categorical_accuracy: 0.3576\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 2.0278 - categorical_accuracy: 0.3791 - val_loss: 1.9195 - val_categorical_accuracy: 0.4991\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 1.7992 - categorical_accuracy: 0.5169 - val_loss: 1.6223 - val_categorical_accuracy: 0.5393\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 1.5707 - categorical_accuracy: 0.5479 - val_loss: 1.4511 - val_categorical_accuracy: 0.5855\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 1.4366 - categorical_accuracy: 0.5810 - val_loss: 1.3332 - val_categorical_accuracy: 0.5966\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 1.3259 - categorical_accuracy: 0.6047 - val_loss: 1.2235 - val_categorical_accuracy: 0.6238\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 1.2286 - categorical_accuracy: 0.6453 - val_loss: 1.1283 - val_categorical_accuracy: 0.6825\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 1.1398 - categorical_accuracy: 0.6774 - val_loss: 1.0463 - val_categorical_accuracy: 0.7067\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 1.0654 - categorical_accuracy: 0.6979 - val_loss: 0.9783 - val_categorical_accuracy: 0.7262\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 1.0032 - categorical_accuracy: 0.7175 - val_loss: 0.9207 - val_categorical_accuracy: 0.7377\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 0.9485 - categorical_accuracy: 0.7355 - val_loss: 0.8734 - val_categorical_accuracy: 0.7544\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.9015 - categorical_accuracy: 0.7503 - val_loss: 0.8338 - val_categorical_accuracy: 0.7614\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.8594 - categorical_accuracy: 0.7603 - val_loss: 0.7934 - val_categorical_accuracy: 0.7779\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.8259 - categorical_accuracy: 0.7704 - val_loss: 0.7657 - val_categorical_accuracy: 0.7860\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.7995 - categorical_accuracy: 0.7735 - val_loss: 0.7432 - val_categorical_accuracy: 0.7879\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.7762 - categorical_accuracy: 0.7802 - val_loss: 0.7195 - val_categorical_accuracy: 0.7932\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.7573 - categorical_accuracy: 0.7835 - val_loss: 0.7013 - val_categorical_accuracy: 0.7953\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.7398 - categorical_accuracy: 0.7866 - val_loss: 0.6867 - val_categorical_accuracy: 0.7979\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.7217 - categorical_accuracy: 0.7898 - val_loss: 0.6696 - val_categorical_accuracy: 0.8018\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.7077 - categorical_accuracy: 0.7945 - val_loss: 0.6562 - val_categorical_accuracy: 0.8033\n",
      "Epoch 21/300\n",
      "1317/1317 - 4s - loss: 0.6979 - categorical_accuracy: 0.7965 - val_loss: 0.6425 - val_categorical_accuracy: 0.8070\n",
      "Epoch 22/300\n",
      "1317/1317 - 4s - loss: 0.6845 - categorical_accuracy: 0.8002 - val_loss: 0.6314 - val_categorical_accuracy: 0.8144\n",
      "Epoch 23/300\n",
      "1317/1317 - 4s - loss: 0.6697 - categorical_accuracy: 0.8044 - val_loss: 0.6209 - val_categorical_accuracy: 0.8126\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.6574 - categorical_accuracy: 0.8093 - val_loss: 0.6196 - val_categorical_accuracy: 0.8115\n",
      "Epoch 25/300\n",
      "1317/1317 - 4s - loss: 0.6464 - categorical_accuracy: 0.8140 - val_loss: 0.5938 - val_categorical_accuracy: 0.8240\n",
      "Epoch 26/300\n",
      "1317/1317 - 4s - loss: 0.6338 - categorical_accuracy: 0.8183 - val_loss: 0.5903 - val_categorical_accuracy: 0.8349\n",
      "Epoch 27/300\n",
      "1317/1317 - 4s - loss: 0.6231 - categorical_accuracy: 0.8218 - val_loss: 0.5748 - val_categorical_accuracy: 0.8377\n",
      "Epoch 28/300\n",
      "1317/1317 - 4s - loss: 0.6098 - categorical_accuracy: 0.8267 - val_loss: 0.5607 - val_categorical_accuracy: 0.8461\n",
      "Epoch 29/300\n",
      "1317/1317 - 4s - loss: 0.5994 - categorical_accuracy: 0.8318 - val_loss: 0.5492 - val_categorical_accuracy: 0.8477\n",
      "Epoch 30/300\n",
      "1317/1317 - 4s - loss: 0.5880 - categorical_accuracy: 0.8349 - val_loss: 0.5423 - val_categorical_accuracy: 0.8529\n",
      "Epoch 31/300\n",
      "1317/1317 - 4s - loss: 0.5760 - categorical_accuracy: 0.8390 - val_loss: 0.5273 - val_categorical_accuracy: 0.8548\n",
      "Epoch 32/300\n",
      "1317/1317 - 4s - loss: 0.5708 - categorical_accuracy: 0.8415 - val_loss: 0.5213 - val_categorical_accuracy: 0.8580\n",
      "Epoch 33/300\n",
      "1317/1317 - 4s - loss: 0.5590 - categorical_accuracy: 0.8454 - val_loss: 0.5132 - val_categorical_accuracy: 0.8602\n",
      "Epoch 34/300\n",
      "1317/1317 - 4s - loss: 0.5519 - categorical_accuracy: 0.8476 - val_loss: 0.5036 - val_categorical_accuracy: 0.8643\n",
      "Epoch 35/300\n",
      "1317/1317 - 4s - loss: 0.5431 - categorical_accuracy: 0.8506 - val_loss: 0.4954 - val_categorical_accuracy: 0.8678\n",
      "Epoch 36/300\n",
      "1317/1317 - 4s - loss: 0.5378 - categorical_accuracy: 0.8535 - val_loss: 0.4889 - val_categorical_accuracy: 0.8708\n",
      "Epoch 37/300\n",
      "1317/1317 - 4s - loss: 0.5290 - categorical_accuracy: 0.8556 - val_loss: 0.4837 - val_categorical_accuracy: 0.8726\n",
      "Epoch 38/300\n",
      "1317/1317 - 4s - loss: 0.5258 - categorical_accuracy: 0.8583 - val_loss: 0.4751 - val_categorical_accuracy: 0.8738\n",
      "Epoch 39/300\n",
      "1317/1317 - 4s - loss: 0.5155 - categorical_accuracy: 0.8607 - val_loss: 0.4706 - val_categorical_accuracy: 0.8739\n",
      "Epoch 40/300\n",
      "1317/1317 - 4s - loss: 0.5092 - categorical_accuracy: 0.8632 - val_loss: 0.4706 - val_categorical_accuracy: 0.8730\n",
      "Epoch 41/300\n",
      "1317/1317 - 4s - loss: 0.5036 - categorical_accuracy: 0.8637 - val_loss: 0.4621 - val_categorical_accuracy: 0.8776\n",
      "Epoch 42/300\n",
      "1317/1317 - 4s - loss: 0.4959 - categorical_accuracy: 0.8663 - val_loss: 0.4534 - val_categorical_accuracy: 0.8822\n",
      "Epoch 43/300\n",
      "1317/1317 - 4s - loss: 0.4920 - categorical_accuracy: 0.8661 - val_loss: 0.4478 - val_categorical_accuracy: 0.8822\n",
      "Epoch 44/300\n",
      "1317/1317 - 4s - loss: 0.4878 - categorical_accuracy: 0.8685 - val_loss: 0.4430 - val_categorical_accuracy: 0.8839\n",
      "Epoch 45/300\n",
      "1317/1317 - 4s - loss: 0.4823 - categorical_accuracy: 0.8708 - val_loss: 0.4398 - val_categorical_accuracy: 0.8815\n",
      "Epoch 46/300\n",
      "1317/1317 - 4s - loss: 0.4769 - categorical_accuracy: 0.8719 - val_loss: 0.4343 - val_categorical_accuracy: 0.8851\n",
      "Epoch 47/300\n",
      "1317/1317 - 4s - loss: 0.4729 - categorical_accuracy: 0.8716 - val_loss: 0.4328 - val_categorical_accuracy: 0.8841\n",
      "Epoch 48/300\n",
      "1317/1317 - 4s - loss: 0.4666 - categorical_accuracy: 0.8732 - val_loss: 0.4277 - val_categorical_accuracy: 0.8864\n",
      "Epoch 49/300\n",
      "1317/1317 - 4s - loss: 0.4625 - categorical_accuracy: 0.8756 - val_loss: 0.4261 - val_categorical_accuracy: 0.8819\n",
      "Epoch 50/300\n",
      "1317/1317 - 4s - loss: 0.4588 - categorical_accuracy: 0.8763 - val_loss: 0.4220 - val_categorical_accuracy: 0.8857\n",
      "Epoch 51/300\n",
      "1317/1317 - 4s - loss: 0.4549 - categorical_accuracy: 0.8771 - val_loss: 0.4194 - val_categorical_accuracy: 0.8872\n",
      "Epoch 52/300\n",
      "1317/1317 - 4s - loss: 0.4498 - categorical_accuracy: 0.8785 - val_loss: 0.4178 - val_categorical_accuracy: 0.8856\n",
      "Epoch 53/300\n",
      "1317/1317 - 4s - loss: 0.4457 - categorical_accuracy: 0.8804 - val_loss: 0.4111 - val_categorical_accuracy: 0.8918\n",
      "Epoch 54/300\n",
      "1317/1317 - 4s - loss: 0.4439 - categorical_accuracy: 0.8795 - val_loss: 0.4146 - val_categorical_accuracy: 0.8864\n",
      "Epoch 55/300\n",
      "1317/1317 - 4s - loss: 0.4413 - categorical_accuracy: 0.8799 - val_loss: 0.4042 - val_categorical_accuracy: 0.8903\n",
      "Epoch 56/300\n",
      "1317/1317 - 4s - loss: 0.4383 - categorical_accuracy: 0.8819 - val_loss: 0.4021 - val_categorical_accuracy: 0.8902\n",
      "Epoch 57/300\n",
      "1317/1317 - 4s - loss: 0.4340 - categorical_accuracy: 0.8830 - val_loss: 0.4010 - val_categorical_accuracy: 0.8917\n",
      "Epoch 58/300\n",
      "1317/1317 - 4s - loss: 0.4308 - categorical_accuracy: 0.8846 - val_loss: 0.3991 - val_categorical_accuracy: 0.8907\n",
      "Epoch 59/300\n",
      "1317/1317 - 4s - loss: 0.4301 - categorical_accuracy: 0.8846 - val_loss: 0.3970 - val_categorical_accuracy: 0.8908\n",
      "Epoch 60/300\n",
      "1317/1317 - 4s - loss: 0.4238 - categorical_accuracy: 0.8853 - val_loss: 0.3923 - val_categorical_accuracy: 0.8928\n",
      "Epoch 61/300\n",
      "1317/1317 - 4s - loss: 0.4264 - categorical_accuracy: 0.8834 - val_loss: 0.3908 - val_categorical_accuracy: 0.8932\n",
      "Epoch 62/300\n",
      "1317/1317 - 4s - loss: 0.4183 - categorical_accuracy: 0.8863 - val_loss: 0.3908 - val_categorical_accuracy: 0.8930\n",
      "Epoch 63/300\n",
      "1317/1317 - 4s - loss: 0.4152 - categorical_accuracy: 0.8873 - val_loss: 0.3897 - val_categorical_accuracy: 0.8942\n",
      "Epoch 64/300\n",
      "1317/1317 - 4s - loss: 0.4152 - categorical_accuracy: 0.8885 - val_loss: 0.3855 - val_categorical_accuracy: 0.8959\n",
      "Epoch 65/300\n",
      "1317/1317 - 4s - loss: 0.4112 - categorical_accuracy: 0.8878 - val_loss: 0.3814 - val_categorical_accuracy: 0.8951\n",
      "Epoch 66/300\n",
      "1317/1317 - 4s - loss: 0.4083 - categorical_accuracy: 0.8888 - val_loss: 0.3780 - val_categorical_accuracy: 0.8962\n",
      "Epoch 67/300\n",
      "1317/1317 - 4s - loss: 0.4058 - categorical_accuracy: 0.8904 - val_loss: 0.3770 - val_categorical_accuracy: 0.8981\n",
      "Epoch 68/300\n",
      "1317/1317 - 5s - loss: 0.4020 - categorical_accuracy: 0.8916 - val_loss: 0.3761 - val_categorical_accuracy: 0.8971\n",
      "Epoch 69/300\n",
      "1317/1317 - 5s - loss: 0.4003 - categorical_accuracy: 0.8911 - val_loss: 0.3722 - val_categorical_accuracy: 0.8998\n",
      "Epoch 70/300\n",
      "1317/1317 - 4s - loss: 0.3979 - categorical_accuracy: 0.8922 - val_loss: 0.3736 - val_categorical_accuracy: 0.9003\n",
      "Epoch 71/300\n",
      "1317/1317 - 4s - loss: 0.3938 - categorical_accuracy: 0.8938 - val_loss: 0.3688 - val_categorical_accuracy: 0.8981\n",
      "Epoch 72/300\n",
      "1317/1317 - 4s - loss: 0.3937 - categorical_accuracy: 0.8921 - val_loss: 0.3710 - val_categorical_accuracy: 0.8991\n",
      "Epoch 73/300\n",
      "1317/1317 - 4s - loss: 0.3911 - categorical_accuracy: 0.8945 - val_loss: 0.3669 - val_categorical_accuracy: 0.8993\n",
      "Epoch 74/300\n",
      "1317/1317 - 4s - loss: 0.3854 - categorical_accuracy: 0.8957 - val_loss: 0.3631 - val_categorical_accuracy: 0.9003\n",
      "Epoch 75/300\n",
      "1317/1317 - 4s - loss: 0.3834 - categorical_accuracy: 0.8964 - val_loss: 0.3634 - val_categorical_accuracy: 0.9000\n",
      "Epoch 76/300\n",
      "1317/1317 - 4s - loss: 0.3843 - categorical_accuracy: 0.8946 - val_loss: 0.3608 - val_categorical_accuracy: 0.9011\n",
      "Epoch 77/300\n",
      "1317/1317 - 4s - loss: 0.3810 - categorical_accuracy: 0.8967 - val_loss: 0.3572 - val_categorical_accuracy: 0.9028\n",
      "Epoch 78/300\n",
      "1317/1317 - 4s - loss: 0.3791 - categorical_accuracy: 0.8963 - val_loss: 0.3577 - val_categorical_accuracy: 0.9020\n",
      "Epoch 79/300\n",
      "1317/1317 - 4s - loss: 0.3792 - categorical_accuracy: 0.8971 - val_loss: 0.3559 - val_categorical_accuracy: 0.9018\n",
      "Epoch 80/300\n",
      "1317/1317 - 4s - loss: 0.3774 - categorical_accuracy: 0.8954 - val_loss: 0.3685 - val_categorical_accuracy: 0.8986\n",
      "Epoch 81/300\n",
      "1317/1317 - 4s - loss: 0.3750 - categorical_accuracy: 0.8974 - val_loss: 0.3518 - val_categorical_accuracy: 0.9034\n",
      "Epoch 82/300\n",
      "1317/1317 - 4s - loss: 0.3728 - categorical_accuracy: 0.8984 - val_loss: 0.3507 - val_categorical_accuracy: 0.9022\n",
      "Epoch 83/300\n",
      "1317/1317 - 4s - loss: 0.3703 - categorical_accuracy: 0.8984 - val_loss: 0.3483 - val_categorical_accuracy: 0.9044\n",
      "Epoch 84/300\n",
      "1317/1317 - 4s - loss: 0.3657 - categorical_accuracy: 0.8993 - val_loss: 0.3475 - val_categorical_accuracy: 0.9047\n",
      "Epoch 85/300\n",
      "1317/1317 - 4s - loss: 0.3668 - categorical_accuracy: 0.8996 - val_loss: 0.3482 - val_categorical_accuracy: 0.9044\n",
      "Epoch 86/300\n",
      "1317/1317 - 4s - loss: 0.3656 - categorical_accuracy: 0.9007 - val_loss: 0.3447 - val_categorical_accuracy: 0.9053\n",
      "Epoch 87/300\n",
      "1317/1317 - 4s - loss: 0.3645 - categorical_accuracy: 0.8997 - val_loss: 0.3443 - val_categorical_accuracy: 0.9053\n",
      "Epoch 88/300\n",
      "1317/1317 - 4s - loss: 0.3613 - categorical_accuracy: 0.9008 - val_loss: 0.3418 - val_categorical_accuracy: 0.9054\n",
      "Epoch 89/300\n",
      "1317/1317 - 4s - loss: 0.3588 - categorical_accuracy: 0.9024 - val_loss: 0.3471 - val_categorical_accuracy: 0.9046\n",
      "Epoch 90/300\n",
      "1317/1317 - 4s - loss: 0.3588 - categorical_accuracy: 0.9005 - val_loss: 0.3399 - val_categorical_accuracy: 0.9056\n",
      "Epoch 91/300\n",
      "1317/1317 - 4s - loss: 0.3587 - categorical_accuracy: 0.9022 - val_loss: 0.3436 - val_categorical_accuracy: 0.9044\n",
      "Epoch 92/300\n",
      "1317/1317 - 4s - loss: 0.3552 - categorical_accuracy: 0.9026 - val_loss: 0.3382 - val_categorical_accuracy: 0.9056\n",
      "Epoch 93/300\n",
      "1317/1317 - 4s - loss: 0.3502 - categorical_accuracy: 0.9037 - val_loss: 0.3389 - val_categorical_accuracy: 0.9052\n",
      "Epoch 94/300\n",
      "1317/1317 - 4s - loss: 0.3509 - categorical_accuracy: 0.9026 - val_loss: 0.3332 - val_categorical_accuracy: 0.9067\n",
      "Epoch 95/300\n",
      "1317/1317 - 4s - loss: 0.3507 - categorical_accuracy: 0.9033 - val_loss: 0.3462 - val_categorical_accuracy: 0.9034\n",
      "Epoch 96/300\n",
      "1317/1317 - 4s - loss: 0.3509 - categorical_accuracy: 0.9032 - val_loss: 0.3349 - val_categorical_accuracy: 0.9056\n",
      "Epoch 97/300\n",
      "1317/1317 - 4s - loss: 0.3481 - categorical_accuracy: 0.9035 - val_loss: 0.3302 - val_categorical_accuracy: 0.9077\n",
      "Epoch 98/300\n",
      "1317/1317 - 4s - loss: 0.3466 - categorical_accuracy: 0.9047 - val_loss: 0.3298 - val_categorical_accuracy: 0.9091\n",
      "Epoch 99/300\n",
      "1317/1317 - 4s - loss: 0.3467 - categorical_accuracy: 0.9035 - val_loss: 0.3311 - val_categorical_accuracy: 0.9072\n",
      "Epoch 100/300\n",
      "1317/1317 - 4s - loss: 0.3407 - categorical_accuracy: 0.9063 - val_loss: 0.3285 - val_categorical_accuracy: 0.9080\n",
      "Epoch 101/300\n",
      "1317/1317 - 4s - loss: 0.3404 - categorical_accuracy: 0.9069 - val_loss: 0.3302 - val_categorical_accuracy: 0.9089\n",
      "Epoch 102/300\n",
      "1317/1317 - 4s - loss: 0.3397 - categorical_accuracy: 0.9061 - val_loss: 0.3273 - val_categorical_accuracy: 0.9086\n",
      "Epoch 103/300\n",
      "1317/1317 - 4s - loss: 0.3404 - categorical_accuracy: 0.9056 - val_loss: 0.3249 - val_categorical_accuracy: 0.9097\n",
      "Epoch 104/300\n",
      "1317/1317 - 4s - loss: 0.3372 - categorical_accuracy: 0.9059 - val_loss: 0.3253 - val_categorical_accuracy: 0.9092\n",
      "Epoch 105/300\n",
      "1317/1317 - 4s - loss: 0.3369 - categorical_accuracy: 0.9056 - val_loss: 0.3264 - val_categorical_accuracy: 0.9097\n",
      "Epoch 106/300\n",
      "1317/1317 - 4s - loss: 0.3344 - categorical_accuracy: 0.9061 - val_loss: 0.3245 - val_categorical_accuracy: 0.9095\n",
      "Epoch 107/300\n",
      "1317/1317 - 4s - loss: 0.3327 - categorical_accuracy: 0.9079 - val_loss: 0.3224 - val_categorical_accuracy: 0.9099\n",
      "Epoch 108/300\n",
      "1317/1317 - 4s - loss: 0.3347 - categorical_accuracy: 0.9062 - val_loss: 0.3260 - val_categorical_accuracy: 0.9092\n",
      "Epoch 109/300\n",
      "1317/1317 - 4s - loss: 0.3322 - categorical_accuracy: 0.9074 - val_loss: 0.3426 - val_categorical_accuracy: 0.9013\n",
      "Epoch 110/300\n",
      "1317/1317 - 4s - loss: 0.3316 - categorical_accuracy: 0.9080 - val_loss: 0.3201 - val_categorical_accuracy: 0.9110\n",
      "Epoch 111/300\n",
      "1317/1317 - 4s - loss: 0.3290 - categorical_accuracy: 0.9075 - val_loss: 0.3215 - val_categorical_accuracy: 0.9095\n",
      "Epoch 112/300\n",
      "1317/1317 - 4s - loss: 0.3303 - categorical_accuracy: 0.9081 - val_loss: 0.3220 - val_categorical_accuracy: 0.9088\n",
      "Epoch 113/300\n",
      "1317/1317 - 4s - loss: 0.3273 - categorical_accuracy: 0.9097 - val_loss: 0.3154 - val_categorical_accuracy: 0.9121\n",
      "Epoch 114/300\n",
      "1317/1317 - 4s - loss: 0.3245 - categorical_accuracy: 0.9098 - val_loss: 0.3207 - val_categorical_accuracy: 0.9107\n",
      "Epoch 115/300\n",
      "1317/1317 - 4s - loss: 0.3240 - categorical_accuracy: 0.9101 - val_loss: 0.3152 - val_categorical_accuracy: 0.9116\n",
      "Epoch 116/300\n",
      "1317/1317 - 4s - loss: 0.3212 - categorical_accuracy: 0.9108 - val_loss: 0.3194 - val_categorical_accuracy: 0.9106\n",
      "Epoch 117/300\n",
      "1317/1317 - 4s - loss: 0.3237 - categorical_accuracy: 0.9090 - val_loss: 0.3129 - val_categorical_accuracy: 0.9123\n",
      "Epoch 118/300\n",
      "1317/1317 - 4s - loss: 0.3214 - categorical_accuracy: 0.9103 - val_loss: 0.3182 - val_categorical_accuracy: 0.9122\n",
      "Epoch 119/300\n",
      "1317/1317 - 4s - loss: 0.3198 - categorical_accuracy: 0.9101 - val_loss: 0.3137 - val_categorical_accuracy: 0.9125\n",
      "Epoch 120/300\n",
      "1317/1317 - 4s - loss: 0.3202 - categorical_accuracy: 0.9113 - val_loss: 0.3123 - val_categorical_accuracy: 0.9127\n",
      "Epoch 121/300\n",
      "1317/1317 - 4s - loss: 0.3193 - categorical_accuracy: 0.9109 - val_loss: 0.3097 - val_categorical_accuracy: 0.9134\n",
      "Epoch 122/300\n",
      "1317/1317 - 4s - loss: 0.3179 - categorical_accuracy: 0.9117 - val_loss: 0.3071 - val_categorical_accuracy: 0.9139\n",
      "Epoch 123/300\n",
      "1317/1317 - 4s - loss: 0.3144 - categorical_accuracy: 0.9122 - val_loss: 0.3095 - val_categorical_accuracy: 0.9138\n",
      "Epoch 124/300\n",
      "1317/1317 - 4s - loss: 0.3165 - categorical_accuracy: 0.9120 - val_loss: 0.3133 - val_categorical_accuracy: 0.9139\n",
      "Epoch 125/300\n",
      "1317/1317 - 4s - loss: 0.3188 - categorical_accuracy: 0.9104 - val_loss: 0.3082 - val_categorical_accuracy: 0.9151\n",
      "Epoch 126/300\n",
      "1317/1317 - 4s - loss: 0.3134 - categorical_accuracy: 0.9131 - val_loss: 0.3057 - val_categorical_accuracy: 0.9147\n",
      "Epoch 127/300\n",
      "1317/1317 - 4s - loss: 0.3110 - categorical_accuracy: 0.9135 - val_loss: 0.3065 - val_categorical_accuracy: 0.9150\n",
      "Epoch 128/300\n",
      "1317/1317 - 4s - loss: 0.3119 - categorical_accuracy: 0.9121 - val_loss: 0.3042 - val_categorical_accuracy: 0.9154\n",
      "Epoch 129/300\n",
      "1317/1317 - 4s - loss: 0.3114 - categorical_accuracy: 0.9118 - val_loss: 0.3099 - val_categorical_accuracy: 0.9122\n",
      "Epoch 130/300\n",
      "1317/1317 - 4s - loss: 0.3094 - categorical_accuracy: 0.9141 - val_loss: 0.3045 - val_categorical_accuracy: 0.9154\n",
      "Epoch 131/300\n",
      "1317/1317 - 4s - loss: 0.3079 - categorical_accuracy: 0.9135 - val_loss: 0.3034 - val_categorical_accuracy: 0.9143\n",
      "Epoch 132/300\n",
      "1317/1317 - 4s - loss: 0.3095 - categorical_accuracy: 0.9137 - val_loss: 0.3042 - val_categorical_accuracy: 0.9162\n",
      "Epoch 133/300\n",
      "1317/1317 - 4s - loss: 0.3077 - categorical_accuracy: 0.9132 - val_loss: 0.3024 - val_categorical_accuracy: 0.9150\n",
      "Epoch 134/300\n",
      "1317/1317 - 4s - loss: 0.3055 - categorical_accuracy: 0.9152 - val_loss: 0.3006 - val_categorical_accuracy: 0.9151\n",
      "Epoch 135/300\n",
      "1317/1317 - 4s - loss: 0.3068 - categorical_accuracy: 0.9141 - val_loss: 0.3017 - val_categorical_accuracy: 0.9158\n",
      "Epoch 136/300\n",
      "1317/1317 - 4s - loss: 0.3039 - categorical_accuracy: 0.9145 - val_loss: 0.2996 - val_categorical_accuracy: 0.9165\n",
      "Epoch 137/300\n",
      "1317/1317 - 4s - loss: 0.3019 - categorical_accuracy: 0.9149 - val_loss: 0.2987 - val_categorical_accuracy: 0.9150\n",
      "Epoch 138/300\n",
      "1317/1317 - 4s - loss: 0.3029 - categorical_accuracy: 0.9141 - val_loss: 0.2992 - val_categorical_accuracy: 0.9165\n",
      "Epoch 139/300\n",
      "1317/1317 - 4s - loss: 0.3005 - categorical_accuracy: 0.9154 - val_loss: 0.2972 - val_categorical_accuracy: 0.9163\n",
      "Epoch 140/300\n",
      "1317/1317 - 4s - loss: 0.2998 - categorical_accuracy: 0.9162 - val_loss: 0.2975 - val_categorical_accuracy: 0.9161\n",
      "Epoch 141/300\n",
      "1317/1317 - 4s - loss: 0.2997 - categorical_accuracy: 0.9158 - val_loss: 0.2983 - val_categorical_accuracy: 0.9158\n",
      "Epoch 142/300\n",
      "1317/1317 - 5s - loss: 0.3016 - categorical_accuracy: 0.9154 - val_loss: 0.2953 - val_categorical_accuracy: 0.9162\n",
      "Epoch 143/300\n",
      "1317/1317 - 5s - loss: 0.2993 - categorical_accuracy: 0.9153 - val_loss: 0.2961 - val_categorical_accuracy: 0.9152\n",
      "Epoch 144/300\n",
      "1317/1317 - 4s - loss: 0.2985 - categorical_accuracy: 0.9160 - val_loss: 0.2966 - val_categorical_accuracy: 0.9180\n",
      "Epoch 145/300\n",
      "1317/1317 - 4s - loss: 0.2959 - categorical_accuracy: 0.9164 - val_loss: 0.2937 - val_categorical_accuracy: 0.9176\n",
      "Epoch 146/300\n",
      "1317/1317 - 4s - loss: 0.2972 - categorical_accuracy: 0.9162 - val_loss: 0.2997 - val_categorical_accuracy: 0.9155\n",
      "Epoch 147/300\n",
      "1317/1317 - 4s - loss: 0.2945 - categorical_accuracy: 0.9166 - val_loss: 0.3078 - val_categorical_accuracy: 0.9131\n",
      "Epoch 148/300\n",
      "1317/1317 - 4s - loss: 0.2936 - categorical_accuracy: 0.9156 - val_loss: 0.2922 - val_categorical_accuracy: 0.9167\n",
      "Epoch 149/300\n",
      "1317/1317 - 4s - loss: 0.2941 - categorical_accuracy: 0.9164 - val_loss: 0.2912 - val_categorical_accuracy: 0.9172\n",
      "Epoch 150/300\n",
      "1317/1317 - 4s - loss: 0.2921 - categorical_accuracy: 0.9169 - val_loss: 0.2921 - val_categorical_accuracy: 0.9170\n",
      "Epoch 151/300\n",
      "1317/1317 - 4s - loss: 0.2932 - categorical_accuracy: 0.9177 - val_loss: 0.2910 - val_categorical_accuracy: 0.9176\n",
      "Epoch 152/300\n",
      "1317/1317 - 4s - loss: 0.2893 - categorical_accuracy: 0.9189 - val_loss: 0.2921 - val_categorical_accuracy: 0.9193\n",
      "Epoch 153/300\n",
      "1317/1317 - 4s - loss: 0.2898 - categorical_accuracy: 0.9180 - val_loss: 0.2903 - val_categorical_accuracy: 0.9196\n",
      "Epoch 154/300\n",
      "1317/1317 - 4s - loss: 0.2874 - categorical_accuracy: 0.9190 - val_loss: 0.2890 - val_categorical_accuracy: 0.9193\n",
      "Epoch 155/300\n",
      "1317/1317 - 4s - loss: 0.2908 - categorical_accuracy: 0.9183 - val_loss: 0.2913 - val_categorical_accuracy: 0.9191\n",
      "Epoch 156/300\n",
      "1317/1317 - 4s - loss: 0.2880 - categorical_accuracy: 0.9187 - val_loss: 0.2886 - val_categorical_accuracy: 0.9182\n",
      "Epoch 157/300\n",
      "1317/1317 - 4s - loss: 0.2884 - categorical_accuracy: 0.9184 - val_loss: 0.2874 - val_categorical_accuracy: 0.9184\n",
      "Epoch 158/300\n",
      "1317/1317 - 4s - loss: 0.2871 - categorical_accuracy: 0.9184 - val_loss: 0.2941 - val_categorical_accuracy: 0.9166\n",
      "Epoch 159/300\n",
      "1317/1317 - 4s - loss: 0.2839 - categorical_accuracy: 0.9202 - val_loss: 0.2899 - val_categorical_accuracy: 0.9168\n",
      "Epoch 160/300\n",
      "1317/1317 - 4s - loss: 0.2844 - categorical_accuracy: 0.9191 - val_loss: 0.2861 - val_categorical_accuracy: 0.9188\n",
      "Epoch 161/300\n",
      "1317/1317 - 4s - loss: 0.2858 - categorical_accuracy: 0.9197 - val_loss: 0.2867 - val_categorical_accuracy: 0.9173\n",
      "Epoch 162/300\n",
      "1317/1317 - 4s - loss: 0.2819 - categorical_accuracy: 0.9192 - val_loss: 0.2857 - val_categorical_accuracy: 0.9185\n",
      "Epoch 163/300\n",
      "1317/1317 - 4s - loss: 0.2863 - categorical_accuracy: 0.9182 - val_loss: 0.2866 - val_categorical_accuracy: 0.9204\n",
      "Epoch 164/300\n",
      "1317/1317 - 4s - loss: 0.2826 - categorical_accuracy: 0.9191 - val_loss: 0.2867 - val_categorical_accuracy: 0.9199\n",
      "Epoch 165/300\n",
      "1317/1317 - 4s - loss: 0.2835 - categorical_accuracy: 0.9195 - val_loss: 0.2895 - val_categorical_accuracy: 0.9182\n",
      "Epoch 166/300\n",
      "1317/1317 - 4s - loss: 0.2800 - categorical_accuracy: 0.9200 - val_loss: 0.2851 - val_categorical_accuracy: 0.9203\n",
      "Epoch 167/300\n",
      "1317/1317 - 4s - loss: 0.2845 - categorical_accuracy: 0.9200 - val_loss: 0.2863 - val_categorical_accuracy: 0.9188\n",
      "Epoch 168/300\n",
      "1317/1317 - 4s - loss: 0.2778 - categorical_accuracy: 0.9215 - val_loss: 0.2874 - val_categorical_accuracy: 0.9211\n",
      "Epoch 169/300\n",
      "1317/1317 - 4s - loss: 0.2786 - categorical_accuracy: 0.9215 - val_loss: 0.2913 - val_categorical_accuracy: 0.9164\n",
      "Epoch 170/300\n",
      "1317/1317 - 4s - loss: 0.2803 - categorical_accuracy: 0.9201 - val_loss: 0.2835 - val_categorical_accuracy: 0.9207\n",
      "Epoch 171/300\n",
      "1317/1317 - 4s - loss: 0.2765 - categorical_accuracy: 0.9212 - val_loss: 0.2836 - val_categorical_accuracy: 0.9194\n",
      "Epoch 172/300\n",
      "1317/1317 - 4s - loss: 0.2784 - categorical_accuracy: 0.9216 - val_loss: 0.2896 - val_categorical_accuracy: 0.9167\n",
      "Epoch 173/300\n",
      "1317/1317 - 4s - loss: 0.2779 - categorical_accuracy: 0.9213 - val_loss: 0.2840 - val_categorical_accuracy: 0.9187\n",
      "Epoch 174/300\n",
      "1317/1317 - 4s - loss: 0.2767 - categorical_accuracy: 0.9201 - val_loss: 0.2858 - val_categorical_accuracy: 0.9194\n",
      "Epoch 175/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.2769 - categorical_accuracy: 0.9208 - val_loss: 0.2872 - val_categorical_accuracy: 0.9174\n",
      "Epoch 00175: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2371 - categorical_accuracy: 0.9342\n",
      "Training loss: 0.2371, Traning accuracy: 0.9342\n",
      "330/330 [==============================] - 1s 3ms/step - loss: 0.2835 - categorical_accuracy: 0.9207\n",
      "Validation loss:  0.2835, Validation accuracy: 0.9207\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9175389713080804"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train,y_train,char_size,optim='sgd')\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTrm_Ks-KI4g"
   },
   "source": [
    "# **Confusion Matrix to Measure the Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pr_x4tltKSYc",
    "outputId": "b6f00361-22a6-43f4-f761-aa9f2b8e9fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           en  und    es    ja   id   pt   ar  th   fr   tr  ms   ru  hi-Latn  \\\n",
      "en       4661   57     6     1    8    6    0   0    8    0   0    1        0   \n",
      "und       131  923    44    10   59   12    4   0    7   11   0    7        1   \n",
      "es         13   35  1400     0    2   17    0   0    3    1   0    0        0   \n",
      "ja          2    9     0  2458    1    1    0   3    1    0   0    0        0   \n",
      "id         26   52     3     1  719    4    0   0    2    4   0    0        0   \n",
      "pt         11   18    39     0    1  621    0   0    4    0   0    0        0   \n",
      "ar          0    0     0     2    0    0  525   2    0    0   0    0        0   \n",
      "th          0    0     0     0    0    0    0  97    0    0   0    1        0   \n",
      "fr         14   10     4     0    0    3    0   0  193    0   0    0        0   \n",
      "tr          3    4     0     0    3    0    0   0    0  164   0    0        0   \n",
      "ms          1    4     0     0   22    0    0   0    0    1   2    0        0   \n",
      "ru          0    0     0     3    0    0    0   1    0    0   0  239        0   \n",
      "hi-Latn     0    3     0     0    1    0    0   0    0    0   0    0        0   \n",
      "bs          0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "xh          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ko          1    6     0    10    0    0    0   0    0    0   0    0        0   \n",
      "it          3    2     5     0    0    2    0   0    1    0   0    0        0   \n",
      "tl          8   12     3     0    7    0    0   0    0    0   0    0        0   \n",
      "sv          3    1     0     0    0    0    0   0    1    0   0    0        0   \n",
      "ta          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "he          0    0     0     2    0    0    0   0    0    0   0    0        0   \n",
      "de          6    3     0     0    0    0    0   0    1    1   0    0        0   \n",
      "el          0    0     1     2    0    0    0   0    0    0   0    0        0   \n",
      "pl          0    5     0     0    0    1    0   0    0    1   0    0        0   \n",
      "nl          6    2     0     0    0    1    0   0    2    0   0    0        0   \n",
      "fa          0    0     0     0    0    0    2   0    0    0   0    0        0   \n",
      "mr          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ar_LATN     0    2     0     0    0    0    0   0    0    1   0    0        0   \n",
      "sr          0    1     0     0    2    0    0   0    0    0   0    0        0   \n",
      "sw          0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "ur          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ca          0    0     2     0    0    1    0   0    0    0   0    0        0   \n",
      "vi          0    1     0     0    0    1    0   0    0    0   0    0        0   \n",
      "km          0    0     0     1    0    0    0   0    0    0   0    0        0   \n",
      "ja_LATN     0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "mn          0    0     0     0    0    0    0   0    0    0   0    1        0   \n",
      "fi          0    2     0     0    0    0    0   0    0    0   0    0        0   \n",
      "az          0    0     0     0    0    0    0   0    0    2   0    0        0   \n",
      "eu          1    0     0     0    0    0    0   0    0    1   0    0        0   \n",
      "lv          0    1     1     0    1    2    0   0    0    0   0    0        0   \n",
      "zh-TW       0    0     0     3    0    0    0   0    0    0   0    0        0   \n",
      "zu          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "cs          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "bg          0    0     0     0    0    0    0   0    0    0   0    2        0   \n",
      "zh-CN       0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ht          1    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "la          0    0     0     0    0    1    0   0    0    0   0    0        0   \n",
      "yo          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "uk          0    0     0     0    0    0    0   0    0    0   0    2        0   \n",
      "hi          0    0     0     0    0    0    0   0    0    0   0    1        0   \n",
      "da          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "hr          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ro          1    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "jv          0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "no          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ko_LATN     1    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "mk          0    0     0     0    0    0    0   0    0    0   0    1        0   \n",
      "ur_LATN     0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "sk          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ta_LATN     0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "\n",
      "         bs  xh  ko  it  tl  sv  ta  he  de  el  pl  nl  fa  mr  ar_LATN  sr  \\\n",
      "en        0   0   2   2   4   0   0   0   1   0   0   1   0   0        0   0   \n",
      "und       0   0   2   1  13   0   0   0   0   1   1   1   0   0        0   0   \n",
      "es        0   0   0   3   1   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ja        0   0   2   0   0   0   0   1   0   0   0   0   0   0        0   0   \n",
      "id        0   0   0   0   4   0   0   0   0   0   0   1   0   0        0   0   \n",
      "pt        0   0   0   3   1   0   0   0   0   0   0   0   0   0        0   1   \n",
      "ar        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "th        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "fr        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "tr        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ms        0   0   0   0   1   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ru        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "hi-Latn   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "bs        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "xh        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ko        0   0  93   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "it        0   0   0  62   0   0   0   0   0   0   1   0   0   0        0   0   \n",
      "tl        0   0   0   1  58   0   0   0   0   0   0   0   0   0        0   0   \n",
      "sv        0   0   0   0   0  10   0   0   0   0   0   0   0   0        0   0   \n",
      "ta        0   0   0   0   0   0   3   0   0   0   0   0   0   0        0   0   \n",
      "he        0   0   0   0   0   0   0  12   0   0   0   0   0   0        0   0   \n",
      "de        0   0   0   0   0   0   0   0  38   0   0   1   0   0        0   0   \n",
      "el        0   0   0   0   0   0   0   0   0   8   0   0   0   0        0   0   \n",
      "pl        0   0   0   0   1   0   0   0   0   0  18   0   0   0        0   0   \n",
      "nl        0   0   0   0   0   0   0   0   0   0   0  32   0   0        0   0   \n",
      "fa        0   0   0   0   0   0   0   0   0   0   0   0   3   0        0   0   \n",
      "mr        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ar_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "sr        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   3   \n",
      "sw        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ur        0   0   0   0   0   0   0   0   0   0   0   0   2   0        0   0   \n",
      "ca        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "vi        0   0   1   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "km        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ja_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "mn        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "fi        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "az        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "eu        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "lv        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "zh-TW     0   0   1   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "zu        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "cs        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "bg        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "zh-CN     0   0   1   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ht        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "la        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "yo        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "uk        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "hi        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "da        0   0   0   0   0   1   0   0   0   0   0   0   0   0        0   0   \n",
      "hr        0   0   0   1   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ro        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "jv        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "no        0   0   0   0   0   0   0   0   1   0   0   0   0   0        0   0   \n",
      "ko_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "mk        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ur_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "sk        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ta_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "\n",
      "         sw  ur  ca  vi  km  ja_LATN  mn  fi  az  eu  lv  zh-TW  zu  cs  bg  \\\n",
      "en        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "und       0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "es        0   0   0   0   0        0   0   0   1   0   0      0   0   0   0   \n",
      "ja        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "id        0   0   0   0   0        0   0   1   0   0   0      0   0   0   0   \n",
      "pt        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ar        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "th        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "fr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "tr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ms        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ru        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "hi-Latn   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "bs        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "xh        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ko        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "it        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "tl        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "sv        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ta        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "he        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "de        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "el        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "pl        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "nl        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "fa        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "mr        0   0   0   0   0        0   0   0   0   0   0      1   0   0   0   \n",
      "ar_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "sr        0   0   0   0   0        0   0   1   0   0   0      0   0   0   0   \n",
      "sw        1   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ur        0   3   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ca        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "vi        0   0   0   2   0        0   0   0   0   0   0      0   0   0   0   \n",
      "km        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ja_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "mn        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "fi        0   0   0   0   0        0   0   6   0   0   0      0   0   0   0   \n",
      "az        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "eu        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "lv        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "zh-TW     0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "zu        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "cs        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "bg        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "zh-CN     0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ht        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "la        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "yo        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "uk        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "hi        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "da        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "hr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ro        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "jv        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "no        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ko_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "mk        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ur_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "sk        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ta_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "\n",
      "         zh-CN  ht  la  yo  uk  hi  da  hr  ro  jv  no  ko_LATN  mk  ur_LATN  \\\n",
      "en           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "und          0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "es           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ja           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "id           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "pt           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ar           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "th           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "fr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "tr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ms           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ru           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "hi-Latn      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "bs           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "xh           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ko           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "it           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "tl           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sv           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ta           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "he           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "de           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "el           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "pl           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "nl           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "fa           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "mr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ar_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sw           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ur           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ca           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "vi           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "km           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ja_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "mn           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "fi           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "az           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "eu           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "lv           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "zh-TW        0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "zu           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "cs           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "bg           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "zh-CN        0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ht           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "la           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "yo           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "uk           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "hi           0   0   0   0   0   3   0   0   0   0   0        0   0        0   \n",
      "da           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "hr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ro           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "jv           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "no           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ko_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "mk           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ur_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sk           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ta_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "\n",
      "         sk  ta_LATN  \n",
      "en        0        0  \n",
      "und       0        0  \n",
      "es        0        0  \n",
      "ja        0        0  \n",
      "id        0        0  \n",
      "pt        0        0  \n",
      "ar        0        0  \n",
      "th        0        0  \n",
      "fr        0        0  \n",
      "tr        0        0  \n",
      "ms        0        0  \n",
      "ru        0        0  \n",
      "hi-Latn   0        0  \n",
      "bs        0        0  \n",
      "xh        0        0  \n",
      "ko        0        0  \n",
      "it        0        0  \n",
      "tl        0        0  \n",
      "sv        0        0  \n",
      "ta        0        0  \n",
      "he        0        0  \n",
      "de        0        0  \n",
      "el        0        0  \n",
      "pl        0        0  \n",
      "nl        0        0  \n",
      "fa        0        0  \n",
      "mr        0        0  \n",
      "ar_LATN   0        0  \n",
      "sr        0        0  \n",
      "sw        0        0  \n",
      "ur        0        0  \n",
      "ca        0        0  \n",
      "vi        0        0  \n",
      "km        0        0  \n",
      "ja_LATN   0        0  \n",
      "mn        0        0  \n",
      "fi        0        0  \n",
      "az        0        0  \n",
      "eu        0        0  \n",
      "lv        0        0  \n",
      "zh-TW     0        0  \n",
      "zu        0        0  \n",
      "cs        0        0  \n",
      "bg        0        0  \n",
      "zh-CN     0        0  \n",
      "ht        0        0  \n",
      "la        0        0  \n",
      "yo        0        0  \n",
      "uk        0        0  \n",
      "hi        0        0  \n",
      "da        0        0  \n",
      "hr        0        0  \n",
      "ro        0        0  \n",
      "jv        0        0  \n",
      "no        0        0  \n",
      "ko_LATN   0        0  \n",
      "mk        0        0  \n",
      "ur_LATN   0        0  \n",
      "sk        0        0  \n",
      "ta_LATN   0        0  \n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model_ave.predict(X_test)\n",
    "y_pred_idx = [np.argmax(y_pred_probs[i]) for i in range(len(y_pred_probs))]\n",
    "pred_labels = [unique_labels[idx] for idx in y_pred_idx]\n",
    "\n",
    "# confusion matrices\n",
    "test_labels = df_test['label'].unique()\n",
    "\n",
    "cm =  confusion_matrix(df_test['label'], pred_labels, labels=test_labels)\n",
    "cm = pd.DataFrame(cm, index=test_labels, columns=test_labels)\n",
    "print(cm)\n",
    "cm.to_csv(\"confusion matrix.csv\",index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lybD9hycOI-z"
   },
   "source": [
    "**average macro precision, recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rS0o23Z_OO5C",
    "outputId": "a1ca8d8a-e0f6-4978-c329-a26439db80b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average macro (precision, recall) of CNN:  (0.43468218627991834, 0.36771720369235594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# average macro precision and recall \n",
    "ave_precision = precision_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "ave_recall = recall_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "print(\"average macro (precision, recall) of CNN: \", (ave_precision, ave_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrNHKfI6hEuX"
   },
   "source": [
    "**macro precision and recall for each class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Q6NuKrvhRZz",
    "outputId": "568b04db-17e4-47a1-970a-aa2d68fb5b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision and recall of each class: \n",
      "          precision    recall\n",
      "en        0.952585  0.979613\n",
      "und       0.795004  0.751017\n",
      "es        0.928382  0.948509\n",
      "ja        0.985961  0.991929\n",
      "id        0.866265  0.880049\n",
      "pt        0.922734  0.888412\n",
      "ar        0.988701  0.992439\n",
      "th        0.941748  0.989796\n",
      "fr        0.865471  0.861607\n",
      "tr        0.877005  0.942529\n",
      "ms        1.000000  0.064516\n",
      "ru        0.937255  0.983539\n",
      "hi-Latn   0.000000  0.000000\n",
      "bs        0.000000  0.000000\n",
      "xh        0.000000  0.000000\n",
      "ko        0.911765  0.845455\n",
      "it        0.849315  0.815789\n",
      "tl        0.698795  0.651685\n",
      "sv        0.909091  0.666667\n",
      "ta        1.000000  1.000000\n",
      "he        0.923077  0.857143\n",
      "de        0.950000  0.760000\n",
      "el        0.888889  0.727273\n",
      "pl        0.900000  0.692308\n",
      "nl        0.888889  0.744186\n",
      "fa        0.600000  0.600000\n",
      "mr        0.000000  0.000000\n",
      "ar_LATN   0.000000  0.000000\n",
      "sr        0.750000  0.428571\n",
      "sw        1.000000  0.500000\n",
      "ur        1.000000  0.600000\n",
      "ca        0.000000  0.000000\n",
      "vi        1.000000  0.400000\n",
      "km        0.000000  0.000000\n",
      "ja_LATN   0.000000  0.000000\n",
      "mn        0.000000  0.000000\n",
      "fi        0.750000  0.750000\n",
      "az        0.000000  0.000000\n",
      "eu        0.000000  0.000000\n",
      "lv        0.000000  0.000000\n",
      "zh-TW     0.000000  0.000000\n",
      "zu        0.000000  0.000000\n",
      "cs        0.000000  0.000000\n",
      "bg        0.000000  0.000000\n",
      "zh-CN     0.000000  0.000000\n",
      "ht        0.000000  0.000000\n",
      "la        0.000000  0.000000\n",
      "yo        0.000000  0.000000\n",
      "uk        0.000000  0.000000\n",
      "hi        1.000000  0.750000\n",
      "da        0.000000  0.000000\n",
      "hr        0.000000  0.000000\n",
      "ro        0.000000  0.000000\n",
      "jv        0.000000  0.000000\n",
      "no        0.000000  0.000000\n",
      "ko_LATN   0.000000  0.000000\n",
      "mk        0.000000  0.000000\n",
      "ur_LATN   0.000000  0.000000\n",
      "sk        0.000000  0.000000\n",
      "ta_LATN   0.000000  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# precision and recall of each label\n",
    "precision = precision_score(df_test['label'], pred_labels, labels=test_labels, average=None).reshape(-1,1)\n",
    "recall = recall_score(df_test['label'], pred_labels, labels=test_labels, average=None).reshape(-1,1)\n",
    "\n",
    "# concatenate precision and recall of each model\n",
    "metrics = np.concatenate([precision, recall],axis=1)\n",
    "\n",
    "# add column names and row index labels, print metrics \n",
    "metrics = pd.DataFrame(metrics, columns=['precision', 'recall'])\n",
    "metrics.index = test_labels\n",
    "\n",
    "print('\\nprecision and recall of each class: \\n', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmunuqnsXPk_",
    "outputId": "d45e5edf-7309-4e5a-942f-61124269c205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tweet\n",
      "label         \n",
      "ar         529\n",
      "ar_LATN      3\n",
      "az           2\n",
      "bg           2\n",
      "bs           1\n",
      "ca           3\n",
      "cs           1\n",
      "da           1\n",
      "de          50\n",
      "el          11\n",
      "en        4758\n",
      "es        1476\n",
      "eu           2\n",
      "fa           5\n",
      "fi           8\n",
      "fr         224\n",
      "he          14\n",
      "hi           4\n",
      "hi-Latn      4\n",
      "hr           1\n",
      "ht           1\n",
      "id         817\n",
      "it          76\n",
      "ja        2478\n",
      "ja_LATN      1\n",
      "jv           1\n",
      "km           1\n",
      "ko         110\n",
      "ko_LATN      1\n",
      "la           1\n",
      "lv           5\n",
      "mk           1\n",
      "mn           1\n",
      "mr           1\n",
      "ms          31\n",
      "nl          43\n",
      "no           1\n",
      "pl          26\n",
      "pt         699\n",
      "ro           2\n",
      "ru         243\n",
      "sk           1\n",
      "sr           7\n",
      "sv          15\n",
      "sw           2\n",
      "ta           3\n",
      "ta_LATN      1\n",
      "th          98\n",
      "tl          89\n",
      "tr         174\n",
      "uk           2\n",
      "und       1229\n",
      "ur           5\n",
      "ur_LATN      1\n",
      "vi           5\n",
      "xh           1\n",
      "yo           1\n",
      "zh-CN        1\n",
      "zh-TW        4\n",
      "zu           1\n"
     ]
    }
   ],
   "source": [
    "print(df_test.groupby(['label']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZultiK2K0ta"
   },
   "source": [
    "# **Heatmap Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "hTz82P7LK6JY",
    "outputId": "09b26af3-757b-4d24-b68f-e37db71db001"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pooling strategy</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batch size</th>\n",
       "      <th>strides</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pooling strategy  dropout  batch size  strides  optimizer  accuracy\n",
       "0                 0      0.2          32        1          0    0.9291\n",
       "1                 1      0.2          32        1          0    0.9306\n",
       "2                 0      0.0          32        1          0    0.9187\n",
       "3                 0      0.2          16        1          0    0.9284\n",
       "4                 0      0.2          32        5          0    0.8629\n",
       "5                 0      0.2          32        1          1    0.9175"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global max pooling: 0, global average pooling:1\n",
    "# optimizer='adam':0, optimizer='sgd':1\n",
    "table = pd.DataFrame([[0,0.2,32,1,0,0.9291],[1,0.2,32,1,0,0.9306], \n",
    "         [0,0,32,1,0,0.9187],[0,0.2,16,1,0,0.9284],[0,0.2,32,5,0,0.8629],[0,0.2,32,1,1,0.9175]],\n",
    "          columns=['pooling strategy','dropout','batch size','strides','optimizer','accuracy'])\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "b3S4uxICfgJL",
    "outputId": "30012f2f-9e46-4164-de94-ff72ff2e41c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f826c4feac8>"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(table.corr(),annot=True, fmt='.1g', cmap= 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HGiI_QcEh5i"
   },
   "source": [
    "# **Compare with MLP**\n",
    "MLP is the best model in Ex01.\n",
    "As the data preprocess is different here from Ex01, so here I train the MLP again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BhmX83RKFWm",
    "outputId": "9a74e94a-0dbf-4877-dfe7-cb12348b9265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.26667468\n",
      "Validation score: 0.317578\n",
      "Iteration 2, loss = 2.59435415\n",
      "Validation score: 0.279803\n",
      "Iteration 3, loss = 2.41048761\n",
      "Validation score: 0.401291\n",
      "Iteration 4, loss = 2.30742557\n",
      "Validation score: 0.454252\n",
      "Iteration 5, loss = 2.23086669\n",
      "Validation score: 0.431283\n",
      "Iteration 6, loss = 2.17749465\n",
      "Validation score: 0.430524\n",
      "Iteration 7, loss = 2.12853890\n",
      "Validation score: 0.354784\n",
      "Iteration 8, loss = 2.08967746\n",
      "Validation score: 0.424260\n",
      "Iteration 9, loss = 2.03874302\n",
      "Validation score: 0.395786\n",
      "Iteration 10, loss = 2.00305406\n",
      "Validation score: 0.413629\n",
      "Iteration 11, loss = 1.97431382\n",
      "Validation score: 0.457479\n",
      "Iteration 12, loss = 1.95007042\n",
      "Validation score: 0.464313\n",
      "Iteration 13, loss = 1.93143979\n",
      "Validation score: 0.433751\n",
      "Iteration 14, loss = 1.90136044\n",
      "Validation score: 0.474943\n",
      "Iteration 15, loss = 1.86623576\n",
      "Validation score: 0.457479\n",
      "Iteration 16, loss = 1.85407321\n",
      "Validation score: 0.456150\n",
      "Iteration 17, loss = 1.82918793\n",
      "Validation score: 0.512149\n",
      "Iteration 18, loss = 1.80762350\n",
      "Validation score: 0.500000\n",
      "Iteration 19, loss = 1.78563944\n",
      "Validation score: 0.487092\n",
      "Iteration 20, loss = 1.76750916\n",
      "Validation score: 0.488990\n",
      "Iteration 21, loss = 1.74379829\n",
      "Validation score: 0.514806\n",
      "Iteration 22, loss = 1.72197258\n",
      "Validation score: 0.481397\n",
      "Iteration 23, loss = 1.71200615\n",
      "Validation score: 0.507024\n",
      "Iteration 24, loss = 1.70505542\n",
      "Validation score: 0.461465\n",
      "Iteration 25, loss = 1.68361175\n",
      "Validation score: 0.448937\n",
      "Iteration 26, loss = 1.66778501\n",
      "Validation score: 0.409453\n",
      "Iteration 27, loss = 1.65088574\n",
      "Validation score: 0.507024\n",
      "Iteration 28, loss = 1.63535224\n",
      "Validation score: 0.403759\n",
      "Iteration 29, loss = 1.62242504\n",
      "Validation score: 0.517274\n",
      "Iteration 30, loss = 1.60585169\n",
      "Validation score: 0.507973\n",
      "Iteration 31, loss = 1.59606338\n",
      "Validation score: 0.485194\n",
      "Iteration 32, loss = 1.58581322\n",
      "Validation score: 0.492407\n",
      "Iteration 33, loss = 1.56613798\n",
      "Validation score: 0.506454\n",
      "Iteration 34, loss = 1.56178028\n",
      "Validation score: 0.544609\n",
      "Iteration 35, loss = 1.53342298\n",
      "Validation score: 0.424639\n",
      "Iteration 36, loss = 1.51462316\n",
      "Validation score: 0.500569\n",
      "Iteration 37, loss = 1.50294571\n",
      "Validation score: 0.458428\n",
      "Iteration 38, loss = 1.49311008\n",
      "Validation score: 0.466781\n",
      "Iteration 39, loss = 1.49055642\n",
      "Validation score: 0.497912\n",
      "Iteration 40, loss = 1.46610267\n",
      "Validation score: 0.481967\n",
      "Iteration 41, loss = 1.45601440\n",
      "Validation score: 0.527335\n",
      "Iteration 42, loss = 1.44264126\n",
      "Validation score: 0.474374\n",
      "Iteration 43, loss = 1.43268946\n",
      "Validation score: 0.491458\n",
      "Iteration 44, loss = 1.43368457\n",
      "Validation score: 0.511390\n",
      "Iteration 45, loss = 1.41433579\n",
      "Validation score: 0.521450\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.5674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5674373070261315"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train models\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(800,),shuffle=True, random_state=RANDOM_STATE, verbose=True, activation='tanh', solver='adam', early_stopping=True)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(mlp, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dAsZ3pDfoTU"
   },
   "source": [
    "**macro precision, recall of MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbkFHglDfecj",
    "outputId": "6277049a-1ea2-48b7-84a7-a1ccf8f94b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average macro (precision, recall) of the MLP:  (0.10010165566557795, 0.05949356025692754)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = mlp.predict(X_test)\n",
    "y_pred_idx = [np.argmax(y_pred_probs[i]) for i in range(len(y_pred_probs))]\n",
    "pred_labels = [unique_labels[idx] for idx in y_pred_idx]\n",
    "\n",
    "# average macro precision and recall \n",
    "ave_precision = precision_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "ave_recall = recall_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "print(\"average macro (precision, recall) of the MLP: \", (ave_precision, ave_recall))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ex03_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
