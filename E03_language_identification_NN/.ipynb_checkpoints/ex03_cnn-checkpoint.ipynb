{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-IeIpm79Fqi",
    "outputId": "112b2649-02be-4dd9-ff8c-b49fca3b03d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
      "\r",
      "\u001b[K     |██████▍                         | 10kB 29.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=2ca470fc96934152855d52618f1113359d81893c05a44c197c73effadd51f44d\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynDK5thyzl_v"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import csv, re, sys\n",
    "from io import StringIO\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import emoji, string\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from keras import layers, utils\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, BatchNormalization, Activation, Concatenate, Dense, Dropout, Input, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "#from keras.models import load_model\n",
    "#from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "import math\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdU0eW2fbQjs"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1\n",
    "EMBEDDING_SIZE = 100\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbiXkA8QAeyV"
   },
   "source": [
    "# **Define functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4R3thLDAdZu"
   },
   "outputs": [],
   "source": [
    "# load file into dataframe\n",
    "def load_dataset(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.content.decode('utf8')\n",
    "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
    "    df.columns = ['tweet', 'label']\n",
    "    return df\n",
    "\n",
    "\n",
    "# clean text data\n",
    "def clean_text(text):\n",
    "  # remove url\n",
    "  text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "  # remove @sb. \n",
    "  text = re.sub('@\\S+|@\\S+', '', text)\n",
    "  # remove #sth.\n",
    "  text = re.sub('#\\S+|#\\S+','',text)\n",
    "  # remove numbers\n",
    "  text = re.sub(r'[0-9]+','',text)\n",
    "  # remove other punctuations\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "  # remove emoji\n",
    "  text = ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "  return text\n",
    "\n",
    "\n",
    "# get the max, mean, median character lengths of the tweets\n",
    "def get_length(train, test):\n",
    "  lengths_tr = [len(s.strip()) for s in train['tweet'] ]\n",
    "  lengths_te = [len(s.strip()) for s in test['tweet']]\n",
    "  print(\"maximum lengths in training and test data:\",max(lengths_tr), max(lengths_te))\n",
    "  print(\"average lengths in training and test data:\", np.mean(lengths_tr), np.mean(lengths_te))\n",
    "  print(\"medium lengths in training and test data:\", np.median(lengths_tr), np.median(lengths_te))\n",
    "  return max(max(lengths_tr), max(lengths_te))\n",
    "\n",
    "# tokenize, word to index to sequence the text, one hot encoding to vectorize labels\n",
    "def preprocess(df_train, df_test, MAX_LENGTH):\n",
    "\n",
    "  text_train = df_train['tweet']\n",
    "  text_test = df_test['tweet']\n",
    "  label_train = df_train['label']\n",
    "  label_test = df_test['label']\n",
    "\n",
    "  # tokenize\n",
    "  tokenizer = Tokenizer(num_words=None, lower=True, char_level=True)\n",
    "  tokenizer.fit_on_texts(text_train)\n",
    "  X_train = tokenizer.texts_to_sequences(text_train)\n",
    "  X_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "  char_size = len(tokenizer.word_index) + 1 \n",
    "\n",
    "  print(text_train[5000])\n",
    "  print(X_train[5000])\n",
    "\n",
    "  X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
    "  X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
    "\n",
    "  # one-hot encoding for labels\n",
    "  enc = LabelBinarizer().fit(label_train)\n",
    "  y_train = enc.transform(label_train)\n",
    "  y_test = enc.transform(label_test)\n",
    "\n",
    "  return X_train, y_train, X_test, label_test, char_size\n",
    "  \n",
    "\n",
    "# create model for grid search cv, to get best num_filters and kernel size\n",
    "def create_model(num_filters, kernel_size, strides=1, char_size=5039, EMBEDING_SIZE=100, MAX_LENGTH=100):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(char_size, EMBEDDING_SIZE, input_length=MAX_LENGTH))\n",
    "    model.add(layers.Conv1D(num_filters, kernel_size, strides=1, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(69, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# train models under different pooling strategy, dropout and strides\n",
    "def get_model(X,y,char_size,pooling='GlobalMax', dropout=True, strides=1, batch_size=32, optim='adam',epochs=300):\n",
    "    \n",
    "    # initialize CNN model\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=char_size, output_dim=EMBEDDING_SIZE, input_length=MAX_LENGTH, trainable=False))\n",
    "    model.add(Conv1D(128, 3, activation='relu', strides=strides)) \n",
    "    if pooling=='GlobalMax':\n",
    "      model.add(GlobalMaxPooling1D())\n",
    "    elif pooling=='GlobalAve':\n",
    "      model.add(GlobalAveragePooling1D())\n",
    "    if dropout:\n",
    "      model.add(Dropout(0.5))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(69, activation='softmax'))\n",
    "    model.compile(optimizer=optim, loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # split dataset into training and validation sets\n",
    "    Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE )\n",
    "\n",
    "    # define early stop\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "\n",
    "    # fit model on training set and validate on validation set\n",
    "    history = model.fit(Xtrain,ytrain,epochs=epochs,verbose=2,validation_data=(Xval,yval), callbacks=[es],batch_size=batch_size)\n",
    "    loss, accuracy = model.evaluate(Xtrain, ytrain,verbose=1)\n",
    "    print(\"Training loss: {:.4f}, Traning accuracy: {:.4f}\".format(loss, accuracy))\n",
    "    loss, accuracy = model.evaluate(Xval,yval,verbose=1)\n",
    "    print(\"Validation loss:  {:.4f}, Validation accuracy: {:.4f}\".format(loss, accuracy))\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "# predict test labels, print out classification report\n",
    "def prediction(model, X_test, label_test, unique_labels):\n",
    "  y_pred_probs = model.predict(X_test)\n",
    "  #print(y_pred_probs[0])\n",
    "  y_pred_idx = [np.argmax(y_pred_probs[i]) for i in range(len(y_pred_probs))]\n",
    "  y_pred_label = [unique_labels[idx] for idx in y_pred_idx]\n",
    "  accuracy = accuracy_score(y_pred_label, label_test)\n",
    "  print(\"Test Accuracy is: {:.4f}\".format(accuracy))\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjjza8k5xkwu"
   },
   "source": [
    "# **Load files into dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kj4_cIgho3Qt"
   },
   "outputs": [],
   "source": [
    "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
    "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCLdrs43pJC1"
   },
   "outputs": [],
   "source": [
    "df_train_dev = load_dataset(url_train_dev)\n",
    "df_test = load_dataset(url_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBowmpaI6t8V"
   },
   "source": [
    "# **Inspect the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULdxA6w11CEn",
    "outputId": "742a4c08-233a-4f4b-ea27-30019667857e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52675 entries, 0 to 52674\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   52675 non-null  object\n",
      " 1   label   52675 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 823.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "WcekVCla1zMH",
    "outputId": "6d72b636-59aa-4e16-ae54-b5a0db2ad209"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يا ابو سلو عرفتني</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ب ريال أكفل معتمر في رمضان ، ولك بإذن الله مثل...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...    ar\n",
       "1  فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...    ar\n",
       "2  ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...    ar\n",
       "3                                  يا ابو سلو عرفتني    ar\n",
       "4  ب ريال أكفل معتمر في رمضان ، ولك بإذن الله مثل...    ar"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m71TMZ0W1xWK",
    "outputId": "9a9103eb-7bc0-40bf-dee6-6de310c230eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tweet\n",
      "label         \n",
      "ar        2199\n",
      "ar_LATN     12\n",
      "az           1\n",
      "bg           2\n",
      "bn           8\n",
      "bs           4\n",
      "ca          22\n",
      "cs           4\n",
      "cy           1\n",
      "da           7\n",
      "de         171\n",
      "dv           1\n",
      "el          28\n",
      "en       18508\n",
      "es        5930\n",
      "et           2\n",
      "fa          18\n",
      "fi          15\n",
      "fr         946\n",
      "gl           3\n",
      "ha           1\n",
      "he          27\n",
      "hi          16\n",
      "hi-Latn     15\n",
      "hr           5\n",
      "ht           2\n",
      "hu          15\n",
      "hy           2\n",
      "id        3006\n",
      "is           1\n",
      "it         339\n",
      "ja       10421\n",
      "ja_LATN      1\n",
      "jv          10\n",
      "km           2\n",
      "ko         458\n",
      "ko_LATN      1\n",
      "ms         119\n",
      "ne           5\n",
      "nl         182\n",
      "no          11\n",
      "pl          93\n",
      "ps           1\n",
      "ps_LATN      1\n",
      "pt        2878\n",
      "ro          12\n",
      "ru         978\n",
      "si           1\n",
      "sl           2\n",
      "sq           9\n",
      "sr          22\n",
      "su          10\n",
      "sv          54\n",
      "sw           6\n",
      "ta           9\n",
      "ta_LATN      1\n",
      "th         462\n",
      "tl         320\n",
      "tn           1\n",
      "tr         669\n",
      "uk          16\n",
      "und       4537\n",
      "ur           7\n",
      "ur_LATN     12\n",
      "vi          16\n",
      "wo           1\n",
      "xh           1\n",
      "zh-CN       25\n",
      "zh-TW       10\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.groupby(['label']).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQuE9fKn1--R",
    "outputId": "e6f7a090-c6a7-4c7c-b750-cd00339be6e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = df_train_dev.label.unique()\n",
    "len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUb1ZXhI_9ZB",
    "outputId": "62503a50-3465-4325-85c7-36cec5f8e689"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique labels in test set\n",
    "len(df_test.label.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwIIsmwK22Uf"
   },
   "source": [
    "# **Clean the data**\n",
    "* remove url\n",
    "* remove \"#topics\", \"@sb\"\n",
    "* remove numbers\n",
    "* remove punctuations\n",
    "* remove emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOgTx2_r20cx"
   },
   "outputs": [],
   "source": [
    "df_train_dev['tweet'] = df_train_dev['tweet'].apply(clean_text)\n",
    "df_test['tweet'] = df_test['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFmxxWTgTLJO",
    "outputId": "29e53f6c-c149-48e3-80b0-cac1b320457d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum lengths in training and test data: 5979 3602\n",
      "average lengths in training and test data: 43.219003322259134 43.388658784547026\n",
      "medium lengths in training and test data: 34.0 35.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5979"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# character length of tweets\n",
    "get_length(df_train_dev, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qTfwiFmNRRI"
   },
   "source": [
    "#  **Preprocess / vectorization**\n",
    "* one-hot encoding to vectorize labels\n",
    "* character indices to encode texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JyYzQFghx1m",
    "outputId": "2576a16b-630d-4f07-e3a0-ea9baffc68e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at the very least I ate the whole Slayer burger\n",
      "[3, 6, 1, 6, 14, 2, 1, 23, 2, 9, 18, 1, 10, 2, 3, 8, 6, 1, 5, 1, 3, 6, 2, 1, 6, 14, 2, 1, 21, 14, 4, 10, 2, 1, 8, 10, 3, 18, 2, 9, 1, 19, 11, 9, 16, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, label_test, char_size = preprocess(df_train_dev, df_test,MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULR-m1SwMh7Q",
    "outputId": "8219b925-9c18-4c24-fc8c-806beb5cbe4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5039"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjU2jcNj92xn"
   },
   "source": [
    "# **Hyperparameter Search by RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ax0g_VhLq6l"
   },
   "outputs": [],
   "source": [
    "param_grid = dict(num_filters=[64, 128],\n",
    "                  kernel_size=[3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C79nM9hUALPY",
    "outputId": "ca0631da-eb37-4ec5-da78-ceccf936d39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 20.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=4, error_score=nan,\n",
      "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82e0c276d8>,\n",
      "                   iid='deprecated', n_iter=1, n_jobs=None,\n",
      "                   param_distributions={'kernel_size': [3, 5],\n",
      "                                        'num_filters': [64, 128]},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=1)\n",
      "0.6232661493122578\n",
      "{'num_filters': 128, 'kernel_size': 3}\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model,\n",
    "                            epochs=40, batch_size=32,\n",
    "                            verbose=False)\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=4, verbose=1, n_iter=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid_result)\n",
    "print(grid_result.best_score_)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7laxpj1rzx9"
   },
   "source": [
    "# **Train the Anchor Model and Predict Test Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeEthiWMCRFI",
    "outputId": "8975533d-1f40-4184-f97f-2f90a150fbae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_20 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 1.1091 - categorical_accuracy: 0.6968 - val_loss: 0.6042 - val_categorical_accuracy: 0.8208\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 0.6279 - categorical_accuracy: 0.8228 - val_loss: 0.4418 - val_categorical_accuracy: 0.8766\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 0.5165 - categorical_accuracy: 0.8557 - val_loss: 0.3819 - val_categorical_accuracy: 0.8925\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 0.4566 - categorical_accuracy: 0.8703 - val_loss: 0.3413 - val_categorical_accuracy: 0.9015\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.4249 - categorical_accuracy: 0.8806 - val_loss: 0.3170 - val_categorical_accuracy: 0.9077\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 0.3979 - categorical_accuracy: 0.8851 - val_loss: 0.3059 - val_categorical_accuracy: 0.9120\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.3802 - categorical_accuracy: 0.8885 - val_loss: 0.2903 - val_categorical_accuracy: 0.9157\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.3635 - categorical_accuracy: 0.8934 - val_loss: 0.2832 - val_categorical_accuracy: 0.9150\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.3491 - categorical_accuracy: 0.8955 - val_loss: 0.2741 - val_categorical_accuracy: 0.9186\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 0.3424 - categorical_accuracy: 0.8998 - val_loss: 0.2653 - val_categorical_accuracy: 0.9220\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 0.3330 - categorical_accuracy: 0.9010 - val_loss: 0.2588 - val_categorical_accuracy: 0.9256\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.3240 - categorical_accuracy: 0.9045 - val_loss: 0.2625 - val_categorical_accuracy: 0.9220\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.3200 - categorical_accuracy: 0.9042 - val_loss: 0.2536 - val_categorical_accuracy: 0.9250\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.3157 - categorical_accuracy: 0.9049 - val_loss: 0.2512 - val_categorical_accuracy: 0.9275\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.3099 - categorical_accuracy: 0.9065 - val_loss: 0.2481 - val_categorical_accuracy: 0.9278\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.3024 - categorical_accuracy: 0.9087 - val_loss: 0.2475 - val_categorical_accuracy: 0.9283\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.2984 - categorical_accuracy: 0.9097 - val_loss: 0.2498 - val_categorical_accuracy: 0.9242\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.2996 - categorical_accuracy: 0.9093 - val_loss: 0.2448 - val_categorical_accuracy: 0.9273\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.2889 - categorical_accuracy: 0.9118 - val_loss: 0.2427 - val_categorical_accuracy: 0.9267\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.2915 - categorical_accuracy: 0.9108 - val_loss: 0.2473 - val_categorical_accuracy: 0.9265\n",
      "Epoch 21/300\n",
      "1317/1317 - 4s - loss: 0.2884 - categorical_accuracy: 0.9122 - val_loss: 0.2390 - val_categorical_accuracy: 0.9288\n",
      "Epoch 22/300\n",
      "1317/1317 - 4s - loss: 0.2845 - categorical_accuracy: 0.9136 - val_loss: 0.2395 - val_categorical_accuracy: 0.9296\n",
      "Epoch 23/300\n",
      "1317/1317 - 4s - loss: 0.2834 - categorical_accuracy: 0.9143 - val_loss: 0.2416 - val_categorical_accuracy: 0.9271\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.2812 - categorical_accuracy: 0.9128 - val_loss: 0.2368 - val_categorical_accuracy: 0.9288\n",
      "Epoch 25/300\n",
      "1317/1317 - 4s - loss: 0.2794 - categorical_accuracy: 0.9131 - val_loss: 0.2378 - val_categorical_accuracy: 0.9277\n",
      "Epoch 26/300\n",
      "1317/1317 - 4s - loss: 0.2736 - categorical_accuracy: 0.9150 - val_loss: 0.2342 - val_categorical_accuracy: 0.9294\n",
      "Epoch 27/300\n",
      "1317/1317 - 4s - loss: 0.2747 - categorical_accuracy: 0.9149 - val_loss: 0.2351 - val_categorical_accuracy: 0.9300\n",
      "Epoch 28/300\n",
      "1317/1317 - 4s - loss: 0.2702 - categorical_accuracy: 0.9153 - val_loss: 0.2292 - val_categorical_accuracy: 0.9301\n",
      "Epoch 29/300\n",
      "1317/1317 - 4s - loss: 0.2696 - categorical_accuracy: 0.9176 - val_loss: 0.2362 - val_categorical_accuracy: 0.9299\n",
      "Epoch 30/300\n",
      "1317/1317 - 4s - loss: 0.2649 - categorical_accuracy: 0.9176 - val_loss: 0.2327 - val_categorical_accuracy: 0.9297\n",
      "Epoch 31/300\n",
      "1317/1317 - 4s - loss: 0.2652 - categorical_accuracy: 0.9178 - val_loss: 0.2345 - val_categorical_accuracy: 0.9299\n",
      "Epoch 32/300\n",
      "1317/1317 - 4s - loss: 0.2648 - categorical_accuracy: 0.9165 - val_loss: 0.2303 - val_categorical_accuracy: 0.9304\n",
      "Epoch 33/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.2650 - categorical_accuracy: 0.9185 - val_loss: 0.2321 - val_categorical_accuracy: 0.9309\n",
      "Epoch 00033: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1698 - categorical_accuracy: 0.9466\n",
      "Training loss: 0.1698, Traning accuracy: 0.9466\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.2292 - categorical_accuracy: 0.9301\n",
      "Validation loss:  0.2292, Validation accuracy: 0.9301\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9264251826191732"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and validate model\n",
    "model_an = get_model(X_train, y_train, char_size)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model_an, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khG39SrCr8HD"
   },
   "source": [
    "# **Change Pooling Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blhM2rCIsAYg",
    "outputId": "0cf11ae0-b3f7-4fa7-a89f-8a6afe86ab8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 1.5078 - categorical_accuracy: 0.5742 - val_loss: 1.0805 - val_categorical_accuracy: 0.6920\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 1.0568 - categorical_accuracy: 0.6950 - val_loss: 0.8622 - val_categorical_accuracy: 0.7569\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 0.9075 - categorical_accuracy: 0.7384 - val_loss: 0.7822 - val_categorical_accuracy: 0.7766\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 0.8228 - categorical_accuracy: 0.7608 - val_loss: 0.6929 - val_categorical_accuracy: 0.7900\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.7613 - categorical_accuracy: 0.7739 - val_loss: 0.6462 - val_categorical_accuracy: 0.8021\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 0.7136 - categorical_accuracy: 0.7868 - val_loss: 0.6040 - val_categorical_accuracy: 0.8141\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.6723 - categorical_accuracy: 0.7998 - val_loss: 0.5682 - val_categorical_accuracy: 0.8247\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.6305 - categorical_accuracy: 0.8140 - val_loss: 0.5307 - val_categorical_accuracy: 0.8443\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.5969 - categorical_accuracy: 0.8254 - val_loss: 0.5016 - val_categorical_accuracy: 0.8516\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 0.5710 - categorical_accuracy: 0.8332 - val_loss: 0.4746 - val_categorical_accuracy: 0.8632\n",
      "Epoch 11/300\n",
      "1317/1317 - 5s - loss: 0.5422 - categorical_accuracy: 0.8416 - val_loss: 0.4580 - val_categorical_accuracy: 0.8730\n",
      "Epoch 12/300\n",
      "1317/1317 - 5s - loss: 0.5238 - categorical_accuracy: 0.8485 - val_loss: 0.4409 - val_categorical_accuracy: 0.8758\n",
      "Epoch 13/300\n",
      "1317/1317 - 5s - loss: 0.5039 - categorical_accuracy: 0.8538 - val_loss: 0.4229 - val_categorical_accuracy: 0.8776\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.4889 - categorical_accuracy: 0.8579 - val_loss: 0.4093 - val_categorical_accuracy: 0.8798\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.4772 - categorical_accuracy: 0.8617 - val_loss: 0.4050 - val_categorical_accuracy: 0.8807\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.4641 - categorical_accuracy: 0.8652 - val_loss: 0.3885 - val_categorical_accuracy: 0.8871\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.4497 - categorical_accuracy: 0.8685 - val_loss: 0.3824 - val_categorical_accuracy: 0.8882\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.4401 - categorical_accuracy: 0.8718 - val_loss: 0.3761 - val_categorical_accuracy: 0.8905\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.4341 - categorical_accuracy: 0.8746 - val_loss: 0.3672 - val_categorical_accuracy: 0.8944\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.4237 - categorical_accuracy: 0.8772 - val_loss: 0.3582 - val_categorical_accuracy: 0.8944\n",
      "Epoch 21/300\n",
      "1317/1317 - 4s - loss: 0.4159 - categorical_accuracy: 0.8780 - val_loss: 0.3593 - val_categorical_accuracy: 0.8944\n",
      "Epoch 22/300\n",
      "1317/1317 - 4s - loss: 0.4091 - categorical_accuracy: 0.8801 - val_loss: 0.3500 - val_categorical_accuracy: 0.8975\n",
      "Epoch 23/300\n",
      "1317/1317 - 4s - loss: 0.3996 - categorical_accuracy: 0.8838 - val_loss: 0.3455 - val_categorical_accuracy: 0.9002\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.3933 - categorical_accuracy: 0.8849 - val_loss: 0.3432 - val_categorical_accuracy: 0.8993\n",
      "Epoch 25/300\n",
      "1317/1317 - 4s - loss: 0.3895 - categorical_accuracy: 0.8859 - val_loss: 0.3356 - val_categorical_accuracy: 0.9037\n",
      "Epoch 26/300\n",
      "1317/1317 - 4s - loss: 0.3824 - categorical_accuracy: 0.8871 - val_loss: 0.3294 - val_categorical_accuracy: 0.9043\n",
      "Epoch 27/300\n",
      "1317/1317 - 4s - loss: 0.3786 - categorical_accuracy: 0.8885 - val_loss: 0.3275 - val_categorical_accuracy: 0.9056\n",
      "Epoch 28/300\n",
      "1317/1317 - 4s - loss: 0.3721 - categorical_accuracy: 0.8906 - val_loss: 0.3271 - val_categorical_accuracy: 0.9057\n",
      "Epoch 29/300\n",
      "1317/1317 - 4s - loss: 0.3664 - categorical_accuracy: 0.8931 - val_loss: 0.3187 - val_categorical_accuracy: 0.9075\n",
      "Epoch 30/300\n",
      "1317/1317 - 4s - loss: 0.3641 - categorical_accuracy: 0.8930 - val_loss: 0.3165 - val_categorical_accuracy: 0.9076\n",
      "Epoch 31/300\n",
      "1317/1317 - 4s - loss: 0.3572 - categorical_accuracy: 0.8950 - val_loss: 0.3139 - val_categorical_accuracy: 0.9088\n",
      "Epoch 32/300\n",
      "1317/1317 - 4s - loss: 0.3596 - categorical_accuracy: 0.8927 - val_loss: 0.3137 - val_categorical_accuracy: 0.9102\n",
      "Epoch 33/300\n",
      "1317/1317 - 4s - loss: 0.3489 - categorical_accuracy: 0.8961 - val_loss: 0.3082 - val_categorical_accuracy: 0.9106\n",
      "Epoch 34/300\n",
      "1317/1317 - 4s - loss: 0.3492 - categorical_accuracy: 0.8962 - val_loss: 0.3066 - val_categorical_accuracy: 0.9133\n",
      "Epoch 35/300\n",
      "1317/1317 - 4s - loss: 0.3426 - categorical_accuracy: 0.8973 - val_loss: 0.3020 - val_categorical_accuracy: 0.9126\n",
      "Epoch 36/300\n",
      "1317/1317 - 4s - loss: 0.3437 - categorical_accuracy: 0.8981 - val_loss: 0.2976 - val_categorical_accuracy: 0.9166\n",
      "Epoch 37/300\n",
      "1317/1317 - 4s - loss: 0.3377 - categorical_accuracy: 0.8997 - val_loss: 0.2970 - val_categorical_accuracy: 0.9132\n",
      "Epoch 38/300\n",
      "1317/1317 - 4s - loss: 0.3335 - categorical_accuracy: 0.9007 - val_loss: 0.2988 - val_categorical_accuracy: 0.9141\n",
      "Epoch 39/300\n",
      "1317/1317 - 4s - loss: 0.3363 - categorical_accuracy: 0.8995 - val_loss: 0.3000 - val_categorical_accuracy: 0.9134\n",
      "Epoch 40/300\n",
      "1317/1317 - 4s - loss: 0.3316 - categorical_accuracy: 0.9016 - val_loss: 0.2915 - val_categorical_accuracy: 0.9150\n",
      "Epoch 41/300\n",
      "1317/1317 - 4s - loss: 0.3298 - categorical_accuracy: 0.9016 - val_loss: 0.2891 - val_categorical_accuracy: 0.9170\n",
      "Epoch 42/300\n",
      "1317/1317 - 4s - loss: 0.3265 - categorical_accuracy: 0.9026 - val_loss: 0.2882 - val_categorical_accuracy: 0.9174\n",
      "Epoch 43/300\n",
      "1317/1317 - 4s - loss: 0.3228 - categorical_accuracy: 0.9048 - val_loss: 0.2883 - val_categorical_accuracy: 0.9150\n",
      "Epoch 44/300\n",
      "1317/1317 - 4s - loss: 0.3212 - categorical_accuracy: 0.9041 - val_loss: 0.2876 - val_categorical_accuracy: 0.9170\n",
      "Epoch 45/300\n",
      "1317/1317 - 4s - loss: 0.3164 - categorical_accuracy: 0.9050 - val_loss: 0.2848 - val_categorical_accuracy: 0.9196\n",
      "Epoch 46/300\n",
      "1317/1317 - 4s - loss: 0.3190 - categorical_accuracy: 0.9042 - val_loss: 0.2843 - val_categorical_accuracy: 0.9189\n",
      "Epoch 47/300\n",
      "1317/1317 - 4s - loss: 0.3132 - categorical_accuracy: 0.9056 - val_loss: 0.2826 - val_categorical_accuracy: 0.9181\n",
      "Epoch 48/300\n",
      "1317/1317 - 4s - loss: 0.3093 - categorical_accuracy: 0.9069 - val_loss: 0.2806 - val_categorical_accuracy: 0.9205\n",
      "Epoch 49/300\n",
      "1317/1317 - 4s - loss: 0.3078 - categorical_accuracy: 0.9066 - val_loss: 0.2785 - val_categorical_accuracy: 0.9199\n",
      "Epoch 50/300\n",
      "1317/1317 - 4s - loss: 0.3044 - categorical_accuracy: 0.9083 - val_loss: 0.2755 - val_categorical_accuracy: 0.9233\n",
      "Epoch 51/300\n",
      "1317/1317 - 4s - loss: 0.3031 - categorical_accuracy: 0.9096 - val_loss: 0.2764 - val_categorical_accuracy: 0.9196\n",
      "Epoch 52/300\n",
      "1317/1317 - 4s - loss: 0.3031 - categorical_accuracy: 0.9075 - val_loss: 0.2712 - val_categorical_accuracy: 0.9223\n",
      "Epoch 53/300\n",
      "1317/1317 - 5s - loss: 0.3025 - categorical_accuracy: 0.9092 - val_loss: 0.2714 - val_categorical_accuracy: 0.9221\n",
      "Epoch 54/300\n",
      "1317/1317 - 4s - loss: 0.2980 - categorical_accuracy: 0.9092 - val_loss: 0.2756 - val_categorical_accuracy: 0.9209\n",
      "Epoch 55/300\n",
      "1317/1317 - 4s - loss: 0.2985 - categorical_accuracy: 0.9094 - val_loss: 0.2702 - val_categorical_accuracy: 0.9222\n",
      "Epoch 56/300\n",
      "1317/1317 - 4s - loss: 0.2985 - categorical_accuracy: 0.9102 - val_loss: 0.2668 - val_categorical_accuracy: 0.9240\n",
      "Epoch 57/300\n",
      "1317/1317 - 4s - loss: 0.2938 - categorical_accuracy: 0.9105 - val_loss: 0.2692 - val_categorical_accuracy: 0.9238\n",
      "Epoch 58/300\n",
      "1317/1317 - 4s - loss: 0.2915 - categorical_accuracy: 0.9123 - val_loss: 0.2708 - val_categorical_accuracy: 0.9205\n",
      "Epoch 59/300\n",
      "1317/1317 - 4s - loss: 0.2929 - categorical_accuracy: 0.9115 - val_loss: 0.2683 - val_categorical_accuracy: 0.9238\n",
      "Epoch 60/300\n",
      "1317/1317 - 4s - loss: 0.2913 - categorical_accuracy: 0.9117 - val_loss: 0.2688 - val_categorical_accuracy: 0.9227\n",
      "Epoch 61/300\n",
      "1317/1317 - 4s - loss: 0.2891 - categorical_accuracy: 0.9112 - val_loss: 0.2661 - val_categorical_accuracy: 0.9245\n",
      "Epoch 62/300\n",
      "1317/1317 - 4s - loss: 0.2886 - categorical_accuracy: 0.9132 - val_loss: 0.2661 - val_categorical_accuracy: 0.9245\n",
      "Epoch 63/300\n",
      "1317/1317 - 4s - loss: 0.2862 - categorical_accuracy: 0.9138 - val_loss: 0.2641 - val_categorical_accuracy: 0.9245\n",
      "Epoch 64/300\n",
      "1317/1317 - 4s - loss: 0.2858 - categorical_accuracy: 0.9131 - val_loss: 0.2624 - val_categorical_accuracy: 0.9270\n",
      "Epoch 65/300\n",
      "1317/1317 - 4s - loss: 0.2802 - categorical_accuracy: 0.9140 - val_loss: 0.2652 - val_categorical_accuracy: 0.9239\n",
      "Epoch 66/300\n",
      "1317/1317 - 4s - loss: 0.2816 - categorical_accuracy: 0.9135 - val_loss: 0.2635 - val_categorical_accuracy: 0.9245\n",
      "Epoch 67/300\n",
      "1317/1317 - 4s - loss: 0.2820 - categorical_accuracy: 0.9147 - val_loss: 0.2641 - val_categorical_accuracy: 0.9250\n",
      "Epoch 68/300\n",
      "1317/1317 - 4s - loss: 0.2791 - categorical_accuracy: 0.9142 - val_loss: 0.2621 - val_categorical_accuracy: 0.9253\n",
      "Epoch 69/300\n",
      "1317/1317 - 4s - loss: 0.2784 - categorical_accuracy: 0.9154 - val_loss: 0.2599 - val_categorical_accuracy: 0.9280\n",
      "Epoch 70/300\n",
      "1317/1317 - 4s - loss: 0.2802 - categorical_accuracy: 0.9147 - val_loss: 0.2612 - val_categorical_accuracy: 0.9277\n",
      "Epoch 71/300\n",
      "1317/1317 - 4s - loss: 0.2777 - categorical_accuracy: 0.9146 - val_loss: 0.2602 - val_categorical_accuracy: 0.9280\n",
      "Epoch 72/300\n",
      "1317/1317 - 4s - loss: 0.2767 - categorical_accuracy: 0.9150 - val_loss: 0.2605 - val_categorical_accuracy: 0.9248\n",
      "Epoch 73/300\n",
      "1317/1317 - 4s - loss: 0.2737 - categorical_accuracy: 0.9165 - val_loss: 0.2622 - val_categorical_accuracy: 0.9263\n",
      "Epoch 74/300\n",
      "1317/1317 - 4s - loss: 0.2714 - categorical_accuracy: 0.9159 - val_loss: 0.2589 - val_categorical_accuracy: 0.9284\n",
      "Epoch 75/300\n",
      "1317/1317 - 4s - loss: 0.2707 - categorical_accuracy: 0.9172 - val_loss: 0.2579 - val_categorical_accuracy: 0.9272\n",
      "Epoch 76/300\n",
      "1317/1317 - 4s - loss: 0.2725 - categorical_accuracy: 0.9159 - val_loss: 0.2541 - val_categorical_accuracy: 0.9305\n",
      "Epoch 77/300\n",
      "1317/1317 - 4s - loss: 0.2699 - categorical_accuracy: 0.9180 - val_loss: 0.2547 - val_categorical_accuracy: 0.9292\n",
      "Epoch 78/300\n",
      "1317/1317 - 4s - loss: 0.2687 - categorical_accuracy: 0.9183 - val_loss: 0.2531 - val_categorical_accuracy: 0.9304\n",
      "Epoch 79/300\n",
      "1317/1317 - 4s - loss: 0.2712 - categorical_accuracy: 0.9173 - val_loss: 0.2549 - val_categorical_accuracy: 0.9281\n",
      "Epoch 80/300\n",
      "1317/1317 - 4s - loss: 0.2688 - categorical_accuracy: 0.9184 - val_loss: 0.2558 - val_categorical_accuracy: 0.9262\n",
      "Epoch 81/300\n",
      "1317/1317 - 4s - loss: 0.2671 - categorical_accuracy: 0.9179 - val_loss: 0.2540 - val_categorical_accuracy: 0.9276\n",
      "Epoch 82/300\n",
      "1317/1317 - 4s - loss: 0.2671 - categorical_accuracy: 0.9180 - val_loss: 0.2568 - val_categorical_accuracy: 0.9278\n",
      "Epoch 83/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.2648 - categorical_accuracy: 0.9186 - val_loss: 0.2539 - val_categorical_accuracy: 0.9286\n",
      "Epoch 00083: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1952 - categorical_accuracy: 0.9404\n",
      "Training loss: 0.1952, Traning accuracy: 0.9404\n",
      "330/330 [==============================] - 1s 3ms/step - loss: 0.2531 - categorical_accuracy: 0.9304\n",
      "Validation loss:  0.2531, Validation accuracy: 0.9304\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9261239551171022"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train, y_train, char_size, pooling='GlobalAve')\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjk7Pd9PNkPR"
   },
   "source": [
    "# **Remove Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5O_IHYyOUx6",
    "outputId": "419e4516-48be-40d8-88a6-738b28b6b0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 5s - loss: 0.8845 - categorical_accuracy: 0.7623 - val_loss: 0.4706 - val_categorical_accuracy: 0.8709\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 0.4304 - categorical_accuracy: 0.8834 - val_loss: 0.3781 - val_categorical_accuracy: 0.8983\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 0.3508 - categorical_accuracy: 0.9026 - val_loss: 0.3329 - val_categorical_accuracy: 0.9056\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 0.3089 - categorical_accuracy: 0.9128 - val_loss: 0.3108 - val_categorical_accuracy: 0.9107\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.2790 - categorical_accuracy: 0.9198 - val_loss: 0.3095 - val_categorical_accuracy: 0.9097\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 0.2567 - categorical_accuracy: 0.9264 - val_loss: 0.2896 - val_categorical_accuracy: 0.9159\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.2393 - categorical_accuracy: 0.9292 - val_loss: 0.2792 - val_categorical_accuracy: 0.9183\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.2229 - categorical_accuracy: 0.9346 - val_loss: 0.2878 - val_categorical_accuracy: 0.9160\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.2088 - categorical_accuracy: 0.9377 - val_loss: 0.2819 - val_categorical_accuracy: 0.9196\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 0.1952 - categorical_accuracy: 0.9422 - val_loss: 0.2841 - val_categorical_accuracy: 0.9193\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 0.1848 - categorical_accuracy: 0.9444 - val_loss: 0.2977 - val_categorical_accuracy: 0.9165\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.1761 - categorical_accuracy: 0.9464 - val_loss: 0.2683 - val_categorical_accuracy: 0.9237\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.1673 - categorical_accuracy: 0.9485 - val_loss: 0.2860 - val_categorical_accuracy: 0.9193\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.1577 - categorical_accuracy: 0.9509 - val_loss: 0.2742 - val_categorical_accuracy: 0.9224\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.1498 - categorical_accuracy: 0.9530 - val_loss: 0.2908 - val_categorical_accuracy: 0.9187\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.1425 - categorical_accuracy: 0.9553 - val_loss: 0.2953 - val_categorical_accuracy: 0.9188\n",
      "Epoch 17/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.1367 - categorical_accuracy: 0.9566 - val_loss: 0.2882 - val_categorical_accuracy: 0.9182\n",
      "Epoch 00017: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1462 - categorical_accuracy: 0.9567\n",
      "Training loss: 0.1462, Traning accuracy: 0.9567\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.2683 - categorical_accuracy: 0.9237\n",
      "Validation loss:  0.2683, Validation accuracy: 0.9237\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9197228706980948"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train, y_train, char_size, dropout=False)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq7n-tfIN6U2"
   },
   "source": [
    "# **Decrease Batch Size to 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKctlJ4-qAFt",
    "outputId": "866667ac-f017-42e5-eb15-39d57008db21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_14 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2634/2634 - 8s - loss: 0.9487 - categorical_accuracy: 0.7405 - val_loss: 0.4918 - val_categorical_accuracy: 0.8672\n",
      "Epoch 2/300\n",
      "2634/2634 - 8s - loss: 0.5379 - categorical_accuracy: 0.8503 - val_loss: 0.3816 - val_categorical_accuracy: 0.8943\n",
      "Epoch 3/300\n",
      "2634/2634 - 8s - loss: 0.4571 - categorical_accuracy: 0.8703 - val_loss: 0.3354 - val_categorical_accuracy: 0.9027\n",
      "Epoch 4/300\n",
      "2634/2634 - 8s - loss: 0.4196 - categorical_accuracy: 0.8780 - val_loss: 0.3225 - val_categorical_accuracy: 0.9062\n",
      "Epoch 5/300\n",
      "2634/2634 - 8s - loss: 0.3953 - categorical_accuracy: 0.8854 - val_loss: 0.2972 - val_categorical_accuracy: 0.9130\n",
      "Epoch 6/300\n",
      "2634/2634 - 8s - loss: 0.3763 - categorical_accuracy: 0.8921 - val_loss: 0.2883 - val_categorical_accuracy: 0.9144\n",
      "Epoch 7/300\n",
      "2634/2634 - 8s - loss: 0.3608 - categorical_accuracy: 0.8956 - val_loss: 0.2801 - val_categorical_accuracy: 0.9171\n",
      "Epoch 8/300\n",
      "2634/2634 - 8s - loss: 0.3473 - categorical_accuracy: 0.8978 - val_loss: 0.2776 - val_categorical_accuracy: 0.9174\n",
      "Epoch 9/300\n",
      "2634/2634 - 8s - loss: 0.3409 - categorical_accuracy: 0.8995 - val_loss: 0.2655 - val_categorical_accuracy: 0.9230\n",
      "Epoch 10/300\n",
      "2634/2634 - 8s - loss: 0.3276 - categorical_accuracy: 0.9030 - val_loss: 0.2660 - val_categorical_accuracy: 0.9182\n",
      "Epoch 11/300\n",
      "2634/2634 - 8s - loss: 0.3252 - categorical_accuracy: 0.9025 - val_loss: 0.2596 - val_categorical_accuracy: 0.9229\n",
      "Epoch 12/300\n",
      "2634/2634 - 8s - loss: 0.3138 - categorical_accuracy: 0.9065 - val_loss: 0.2542 - val_categorical_accuracy: 0.9216\n",
      "Epoch 13/300\n",
      "2634/2634 - 8s - loss: 0.3133 - categorical_accuracy: 0.9046 - val_loss: 0.2499 - val_categorical_accuracy: 0.9273\n",
      "Epoch 14/300\n",
      "2634/2634 - 8s - loss: 0.3055 - categorical_accuracy: 0.9068 - val_loss: 0.2455 - val_categorical_accuracy: 0.9251\n",
      "Epoch 15/300\n",
      "2634/2634 - 8s - loss: 0.3016 - categorical_accuracy: 0.9089 - val_loss: 0.2541 - val_categorical_accuracy: 0.9259\n",
      "Epoch 16/300\n",
      "2634/2634 - 8s - loss: 0.2978 - categorical_accuracy: 0.9079 - val_loss: 0.2491 - val_categorical_accuracy: 0.9283\n",
      "Epoch 17/300\n",
      "2634/2634 - 8s - loss: 0.2979 - categorical_accuracy: 0.9081 - val_loss: 0.2456 - val_categorical_accuracy: 0.9268\n",
      "Epoch 18/300\n",
      "2634/2634 - 8s - loss: 0.2932 - categorical_accuracy: 0.9117 - val_loss: 0.2408 - val_categorical_accuracy: 0.9299\n",
      "Epoch 19/300\n",
      "2634/2634 - 8s - loss: 0.2923 - categorical_accuracy: 0.9114 - val_loss: 0.2456 - val_categorical_accuracy: 0.9263\n",
      "Epoch 20/300\n",
      "2634/2634 - 8s - loss: 0.2878 - categorical_accuracy: 0.9120 - val_loss: 0.2403 - val_categorical_accuracy: 0.9265\n",
      "Epoch 21/300\n",
      "2634/2634 - 8s - loss: 0.2853 - categorical_accuracy: 0.9130 - val_loss: 0.2439 - val_categorical_accuracy: 0.9263\n",
      "Epoch 22/300\n",
      "2634/2634 - 8s - loss: 0.2821 - categorical_accuracy: 0.9126 - val_loss: 0.2397 - val_categorical_accuracy: 0.9297\n",
      "Epoch 23/300\n",
      "2634/2634 - 8s - loss: 0.2800 - categorical_accuracy: 0.9132 - val_loss: 0.2459 - val_categorical_accuracy: 0.9285\n",
      "Epoch 24/300\n",
      "2634/2634 - 8s - loss: 0.2766 - categorical_accuracy: 0.9150 - val_loss: 0.2444 - val_categorical_accuracy: 0.9278\n",
      "Epoch 25/300\n",
      "2634/2634 - 8s - loss: 0.2778 - categorical_accuracy: 0.9139 - val_loss: 0.2396 - val_categorical_accuracy: 0.9283\n",
      "Epoch 26/300\n",
      "2634/2634 - 8s - loss: 0.2774 - categorical_accuracy: 0.9143 - val_loss: 0.2407 - val_categorical_accuracy: 0.9283\n",
      "Epoch 27/300\n",
      "2634/2634 - 8s - loss: 0.2700 - categorical_accuracy: 0.9154 - val_loss: 0.2456 - val_categorical_accuracy: 0.9276\n",
      "Epoch 28/300\n",
      "2634/2634 - 8s - loss: 0.2716 - categorical_accuracy: 0.9155 - val_loss: 0.2414 - val_categorical_accuracy: 0.9275\n",
      "Epoch 29/300\n",
      "2634/2634 - 8s - loss: 0.2689 - categorical_accuracy: 0.9175 - val_loss: 0.2419 - val_categorical_accuracy: 0.9278\n",
      "Epoch 30/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "2634/2634 - 9s - loss: 0.2675 - categorical_accuracy: 0.9165 - val_loss: 0.2443 - val_categorical_accuracy: 0.9278\n",
      "Epoch 00030: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.1721 - categorical_accuracy: 0.9458\n",
      "Training loss: 0.1721, Traning accuracy: 0.9458\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.2396 - categorical_accuracy: 0.9283\n",
      "Validation loss:  0.2396, Validation accuracy: 0.9283\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9262745688681376"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train, y_train, char_size, batch_size=16)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAa0FdlGOzad"
   },
   "source": [
    "\n",
    "\n",
    "# **Change Strides**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1A-7vGgqU5T",
    "outputId": "d183b45b-4f96-451a-bbd7-63ef415dffe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 20, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_15 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 1.3164 - categorical_accuracy: 0.6331 - val_loss: 0.8685 - val_categorical_accuracy: 0.7513\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 0.9020 - categorical_accuracy: 0.7361 - val_loss: 0.7317 - val_categorical_accuracy: 0.7859\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 0.7989 - categorical_accuracy: 0.7656 - val_loss: 0.6594 - val_categorical_accuracy: 0.8009\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 0.7345 - categorical_accuracy: 0.7861 - val_loss: 0.6153 - val_categorical_accuracy: 0.8194\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 0.6878 - categorical_accuracy: 0.7998 - val_loss: 0.5791 - val_categorical_accuracy: 0.8339\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 0.6520 - categorical_accuracy: 0.8106 - val_loss: 0.5535 - val_categorical_accuracy: 0.8405\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 0.6303 - categorical_accuracy: 0.8167 - val_loss: 0.5365 - val_categorical_accuracy: 0.8448\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 0.6102 - categorical_accuracy: 0.8236 - val_loss: 0.5257 - val_categorical_accuracy: 0.8451\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 0.5968 - categorical_accuracy: 0.8246 - val_loss: 0.5185 - val_categorical_accuracy: 0.8492\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 0.5833 - categorical_accuracy: 0.8278 - val_loss: 0.5068 - val_categorical_accuracy: 0.8513\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 0.5759 - categorical_accuracy: 0.8289 - val_loss: 0.5012 - val_categorical_accuracy: 0.8558\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 0.5642 - categorical_accuracy: 0.8323 - val_loss: 0.4927 - val_categorical_accuracy: 0.8535\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.5593 - categorical_accuracy: 0.8344 - val_loss: 0.4946 - val_categorical_accuracy: 0.8539\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.5466 - categorical_accuracy: 0.8387 - val_loss: 0.4874 - val_categorical_accuracy: 0.8561\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.5444 - categorical_accuracy: 0.8370 - val_loss: 0.4791 - val_categorical_accuracy: 0.8589\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.5374 - categorical_accuracy: 0.8394 - val_loss: 0.4775 - val_categorical_accuracy: 0.8572\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.5334 - categorical_accuracy: 0.8408 - val_loss: 0.4780 - val_categorical_accuracy: 0.8593\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.5332 - categorical_accuracy: 0.8404 - val_loss: 0.4756 - val_categorical_accuracy: 0.8598\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.5207 - categorical_accuracy: 0.8439 - val_loss: 0.4802 - val_categorical_accuracy: 0.8582\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.5220 - categorical_accuracy: 0.8425 - val_loss: 0.4705 - val_categorical_accuracy: 0.8610\n",
      "Epoch 21/300\n",
      "1317/1317 - 4s - loss: 0.5159 - categorical_accuracy: 0.8448 - val_loss: 0.4726 - val_categorical_accuracy: 0.8592\n",
      "Epoch 22/300\n",
      "1317/1317 - 4s - loss: 0.5097 - categorical_accuracy: 0.8463 - val_loss: 0.4740 - val_categorical_accuracy: 0.8591\n",
      "Epoch 23/300\n",
      "1317/1317 - 4s - loss: 0.5081 - categorical_accuracy: 0.8459 - val_loss: 0.4707 - val_categorical_accuracy: 0.8607\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.5045 - categorical_accuracy: 0.8452 - val_loss: 0.4698 - val_categorical_accuracy: 0.8615\n",
      "Epoch 25/300\n",
      "1317/1317 - 4s - loss: 0.5024 - categorical_accuracy: 0.8489 - val_loss: 0.4728 - val_categorical_accuracy: 0.8591\n",
      "Epoch 26/300\n",
      "1317/1317 - 4s - loss: 0.5037 - categorical_accuracy: 0.8475 - val_loss: 0.4625 - val_categorical_accuracy: 0.8642\n",
      "Epoch 27/300\n",
      "1317/1317 - 4s - loss: 0.4999 - categorical_accuracy: 0.8482 - val_loss: 0.4687 - val_categorical_accuracy: 0.8607\n",
      "Epoch 28/300\n",
      "1317/1317 - 4s - loss: 0.4941 - categorical_accuracy: 0.8505 - val_loss: 0.4650 - val_categorical_accuracy: 0.8626\n",
      "Epoch 29/300\n",
      "1317/1317 - 4s - loss: 0.4918 - categorical_accuracy: 0.8511 - val_loss: 0.4660 - val_categorical_accuracy: 0.8624\n",
      "Epoch 30/300\n",
      "1317/1317 - 4s - loss: 0.4909 - categorical_accuracy: 0.8522 - val_loss: 0.4683 - val_categorical_accuracy: 0.8610\n",
      "Epoch 31/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.4898 - categorical_accuracy: 0.8516 - val_loss: 0.4650 - val_categorical_accuracy: 0.8623\n",
      "Epoch 00031: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.3702 - categorical_accuracy: 0.8881\n",
      "Training loss: 0.3702, Traning accuracy: 0.8881\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.4625 - categorical_accuracy: 0.8642\n",
      "Validation loss:  0.4625, Validation accuracy: 0.8642\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.8596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8595526771594246"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train, y_train, char_size, strides=5)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UExcTlzo5QXm"
   },
   "source": [
    "# **Change Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVpKUoG65XWI",
    "outputId": "05dac9db-b293-4b96-9423-70dfaa2990eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 100, 100)          503900    \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_17 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 69)                6969      \n",
      "=================================================================\n",
      "Total params: 562,297\n",
      "Trainable params: 58,397\n",
      "Non-trainable params: 503,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1317/1317 - 4s - loss: 2.5311 - categorical_accuracy: 0.3417 - val_loss: 2.0953 - val_categorical_accuracy: 0.3576\n",
      "Epoch 2/300\n",
      "1317/1317 - 4s - loss: 2.0822 - categorical_accuracy: 0.3525 - val_loss: 2.0241 - val_categorical_accuracy: 0.3651\n",
      "Epoch 3/300\n",
      "1317/1317 - 4s - loss: 1.9862 - categorical_accuracy: 0.4142 - val_loss: 1.8541 - val_categorical_accuracy: 0.5369\n",
      "Epoch 4/300\n",
      "1317/1317 - 4s - loss: 1.7823 - categorical_accuracy: 0.5131 - val_loss: 1.6158 - val_categorical_accuracy: 0.5381\n",
      "Epoch 5/300\n",
      "1317/1317 - 4s - loss: 1.6042 - categorical_accuracy: 0.5314 - val_loss: 1.4742 - val_categorical_accuracy: 0.5432\n",
      "Epoch 6/300\n",
      "1317/1317 - 4s - loss: 1.4828 - categorical_accuracy: 0.5710 - val_loss: 1.3585 - val_categorical_accuracy: 0.5949\n",
      "Epoch 7/300\n",
      "1317/1317 - 4s - loss: 1.3803 - categorical_accuracy: 0.5955 - val_loss: 1.2535 - val_categorical_accuracy: 0.6339\n",
      "Epoch 8/300\n",
      "1317/1317 - 4s - loss: 1.2881 - categorical_accuracy: 0.6284 - val_loss: 1.1595 - val_categorical_accuracy: 0.6653\n",
      "Epoch 9/300\n",
      "1317/1317 - 4s - loss: 1.2117 - categorical_accuracy: 0.6554 - val_loss: 1.0827 - val_categorical_accuracy: 0.6807\n",
      "Epoch 10/300\n",
      "1317/1317 - 4s - loss: 1.1447 - categorical_accuracy: 0.6777 - val_loss: 1.0170 - val_categorical_accuracy: 0.7188\n",
      "Epoch 11/300\n",
      "1317/1317 - 4s - loss: 1.0859 - categorical_accuracy: 0.6968 - val_loss: 0.9588 - val_categorical_accuracy: 0.7293\n",
      "Epoch 12/300\n",
      "1317/1317 - 4s - loss: 1.0304 - categorical_accuracy: 0.7135 - val_loss: 0.9088 - val_categorical_accuracy: 0.7528\n",
      "Epoch 13/300\n",
      "1317/1317 - 4s - loss: 0.9842 - categorical_accuracy: 0.7266 - val_loss: 0.8662 - val_categorical_accuracy: 0.7647\n",
      "Epoch 14/300\n",
      "1317/1317 - 4s - loss: 0.9458 - categorical_accuracy: 0.7385 - val_loss: 0.8449 - val_categorical_accuracy: 0.7555\n",
      "Epoch 15/300\n",
      "1317/1317 - 4s - loss: 0.9120 - categorical_accuracy: 0.7449 - val_loss: 0.7975 - val_categorical_accuracy: 0.7752\n",
      "Epoch 16/300\n",
      "1317/1317 - 4s - loss: 0.8842 - categorical_accuracy: 0.7520 - val_loss: 0.7722 - val_categorical_accuracy: 0.7817\n",
      "Epoch 17/300\n",
      "1317/1317 - 4s - loss: 0.8633 - categorical_accuracy: 0.7572 - val_loss: 0.7517 - val_categorical_accuracy: 0.7820\n",
      "Epoch 18/300\n",
      "1317/1317 - 4s - loss: 0.8437 - categorical_accuracy: 0.7608 - val_loss: 0.7387 - val_categorical_accuracy: 0.7870\n",
      "Epoch 19/300\n",
      "1317/1317 - 4s - loss: 0.8256 - categorical_accuracy: 0.7654 - val_loss: 0.7143 - val_categorical_accuracy: 0.7946\n",
      "Epoch 20/300\n",
      "1317/1317 - 4s - loss: 0.8094 - categorical_accuracy: 0.7696 - val_loss: 0.7007 - val_categorical_accuracy: 0.7939\n",
      "Epoch 21/300\n",
      "1317/1317 - 4s - loss: 0.7913 - categorical_accuracy: 0.7736 - val_loss: 0.6860 - val_categorical_accuracy: 0.7984\n",
      "Epoch 22/300\n",
      "1317/1317 - 4s - loss: 0.7823 - categorical_accuracy: 0.7763 - val_loss: 0.6702 - val_categorical_accuracy: 0.8009\n",
      "Epoch 23/300\n",
      "1317/1317 - 4s - loss: 0.7624 - categorical_accuracy: 0.7797 - val_loss: 0.6569 - val_categorical_accuracy: 0.8042\n",
      "Epoch 24/300\n",
      "1317/1317 - 4s - loss: 0.7535 - categorical_accuracy: 0.7848 - val_loss: 0.6493 - val_categorical_accuracy: 0.8070\n",
      "Epoch 25/300\n",
      "1317/1317 - 4s - loss: 0.7385 - categorical_accuracy: 0.7879 - val_loss: 0.6364 - val_categorical_accuracy: 0.8085\n",
      "Epoch 26/300\n",
      "1317/1317 - 4s - loss: 0.7286 - categorical_accuracy: 0.7907 - val_loss: 0.6232 - val_categorical_accuracy: 0.8179\n",
      "Epoch 27/300\n",
      "1317/1317 - 4s - loss: 0.7168 - categorical_accuracy: 0.7954 - val_loss: 0.6120 - val_categorical_accuracy: 0.8169\n",
      "Epoch 28/300\n",
      "1317/1317 - 4s - loss: 0.7039 - categorical_accuracy: 0.7982 - val_loss: 0.6019 - val_categorical_accuracy: 0.8250\n",
      "Epoch 29/300\n",
      "1317/1317 - 4s - loss: 0.6915 - categorical_accuracy: 0.8024 - val_loss: 0.5928 - val_categorical_accuracy: 0.8357\n",
      "Epoch 30/300\n",
      "1317/1317 - 4s - loss: 0.6834 - categorical_accuracy: 0.8075 - val_loss: 0.5859 - val_categorical_accuracy: 0.8268\n",
      "Epoch 31/300\n",
      "1317/1317 - 4s - loss: 0.6718 - categorical_accuracy: 0.8105 - val_loss: 0.5686 - val_categorical_accuracy: 0.8366\n",
      "Epoch 32/300\n",
      "1317/1317 - 4s - loss: 0.6664 - categorical_accuracy: 0.8132 - val_loss: 0.5601 - val_categorical_accuracy: 0.8422\n",
      "Epoch 33/300\n",
      "1317/1317 - 4s - loss: 0.6569 - categorical_accuracy: 0.8168 - val_loss: 0.5504 - val_categorical_accuracy: 0.8480\n",
      "Epoch 34/300\n",
      "1317/1317 - 4s - loss: 0.6474 - categorical_accuracy: 0.8196 - val_loss: 0.5437 - val_categorical_accuracy: 0.8531\n",
      "Epoch 35/300\n",
      "1317/1317 - 5s - loss: 0.6368 - categorical_accuracy: 0.8225 - val_loss: 0.5354 - val_categorical_accuracy: 0.8533\n",
      "Epoch 36/300\n",
      "1317/1317 - 5s - loss: 0.6301 - categorical_accuracy: 0.8248 - val_loss: 0.5280 - val_categorical_accuracy: 0.8549\n",
      "Epoch 37/300\n",
      "1317/1317 - 4s - loss: 0.6213 - categorical_accuracy: 0.8290 - val_loss: 0.5185 - val_categorical_accuracy: 0.8574\n",
      "Epoch 38/300\n",
      "1317/1317 - 4s - loss: 0.6145 - categorical_accuracy: 0.8307 - val_loss: 0.5175 - val_categorical_accuracy: 0.8555\n",
      "Epoch 39/300\n",
      "1317/1317 - 4s - loss: 0.6038 - categorical_accuracy: 0.8348 - val_loss: 0.5082 - val_categorical_accuracy: 0.8607\n",
      "Epoch 40/300\n",
      "1317/1317 - 4s - loss: 0.5988 - categorical_accuracy: 0.8368 - val_loss: 0.4995 - val_categorical_accuracy: 0.8676\n",
      "Epoch 41/300\n",
      "1317/1317 - 4s - loss: 0.5925 - categorical_accuracy: 0.8374 - val_loss: 0.4900 - val_categorical_accuracy: 0.8691\n",
      "Epoch 42/300\n",
      "1317/1317 - 4s - loss: 0.5871 - categorical_accuracy: 0.8405 - val_loss: 0.4859 - val_categorical_accuracy: 0.8708\n",
      "Epoch 43/300\n",
      "1317/1317 - 4s - loss: 0.5804 - categorical_accuracy: 0.8426 - val_loss: 0.4814 - val_categorical_accuracy: 0.8687\n",
      "Epoch 44/300\n",
      "1317/1317 - 4s - loss: 0.5742 - categorical_accuracy: 0.8436 - val_loss: 0.4744 - val_categorical_accuracy: 0.8758\n",
      "Epoch 45/300\n",
      "1317/1317 - 4s - loss: 0.5688 - categorical_accuracy: 0.8445 - val_loss: 0.4690 - val_categorical_accuracy: 0.8737\n",
      "Epoch 46/300\n",
      "1317/1317 - 4s - loss: 0.5621 - categorical_accuracy: 0.8470 - val_loss: 0.4676 - val_categorical_accuracy: 0.8770\n",
      "Epoch 47/300\n",
      "1317/1317 - 4s - loss: 0.5599 - categorical_accuracy: 0.8489 - val_loss: 0.4610 - val_categorical_accuracy: 0.8776\n",
      "Epoch 48/300\n",
      "1317/1317 - 4s - loss: 0.5550 - categorical_accuracy: 0.8491 - val_loss: 0.4578 - val_categorical_accuracy: 0.8774\n",
      "Epoch 49/300\n",
      "1317/1317 - 4s - loss: 0.5482 - categorical_accuracy: 0.8512 - val_loss: 0.4532 - val_categorical_accuracy: 0.8790\n",
      "Epoch 50/300\n",
      "1317/1317 - 4s - loss: 0.5423 - categorical_accuracy: 0.8545 - val_loss: 0.4506 - val_categorical_accuracy: 0.8782\n",
      "Epoch 51/300\n",
      "1317/1317 - 4s - loss: 0.5405 - categorical_accuracy: 0.8522 - val_loss: 0.4449 - val_categorical_accuracy: 0.8832\n",
      "Epoch 52/300\n",
      "1317/1317 - 4s - loss: 0.5377 - categorical_accuracy: 0.8548 - val_loss: 0.4408 - val_categorical_accuracy: 0.8816\n",
      "Epoch 53/300\n",
      "1317/1317 - 4s - loss: 0.5315 - categorical_accuracy: 0.8551 - val_loss: 0.4437 - val_categorical_accuracy: 0.8821\n",
      "Epoch 54/300\n",
      "1317/1317 - 4s - loss: 0.5297 - categorical_accuracy: 0.8570 - val_loss: 0.4392 - val_categorical_accuracy: 0.8818\n",
      "Epoch 55/300\n",
      "1317/1317 - 4s - loss: 0.5234 - categorical_accuracy: 0.8576 - val_loss: 0.4330 - val_categorical_accuracy: 0.8850\n",
      "Epoch 56/300\n",
      "1317/1317 - 4s - loss: 0.5223 - categorical_accuracy: 0.8574 - val_loss: 0.4294 - val_categorical_accuracy: 0.8862\n",
      "Epoch 57/300\n",
      "1317/1317 - 4s - loss: 0.5169 - categorical_accuracy: 0.8597 - val_loss: 0.4269 - val_categorical_accuracy: 0.8869\n",
      "Epoch 58/300\n",
      "1317/1317 - 4s - loss: 0.5139 - categorical_accuracy: 0.8618 - val_loss: 0.4249 - val_categorical_accuracy: 0.8857\n",
      "Epoch 59/300\n",
      "1317/1317 - 4s - loss: 0.5136 - categorical_accuracy: 0.8605 - val_loss: 0.4186 - val_categorical_accuracy: 0.8897\n",
      "Epoch 60/300\n",
      "1317/1317 - 4s - loss: 0.5062 - categorical_accuracy: 0.8615 - val_loss: 0.4171 - val_categorical_accuracy: 0.8886\n",
      "Epoch 61/300\n",
      "1317/1317 - 4s - loss: 0.5049 - categorical_accuracy: 0.8624 - val_loss: 0.4201 - val_categorical_accuracy: 0.8880\n",
      "Epoch 62/300\n",
      "1317/1317 - 4s - loss: 0.4994 - categorical_accuracy: 0.8635 - val_loss: 0.4095 - val_categorical_accuracy: 0.8923\n",
      "Epoch 63/300\n",
      "1317/1317 - 4s - loss: 0.5031 - categorical_accuracy: 0.8624 - val_loss: 0.4127 - val_categorical_accuracy: 0.8899\n",
      "Epoch 64/300\n",
      "1317/1317 - 4s - loss: 0.4980 - categorical_accuracy: 0.8647 - val_loss: 0.4086 - val_categorical_accuracy: 0.8906\n",
      "Epoch 65/300\n",
      "1317/1317 - 4s - loss: 0.4933 - categorical_accuracy: 0.8652 - val_loss: 0.4126 - val_categorical_accuracy: 0.8897\n",
      "Epoch 66/300\n",
      "1317/1317 - 4s - loss: 0.4894 - categorical_accuracy: 0.8672 - val_loss: 0.4064 - val_categorical_accuracy: 0.8923\n",
      "Epoch 67/300\n",
      "1317/1317 - 4s - loss: 0.4897 - categorical_accuracy: 0.8668 - val_loss: 0.4032 - val_categorical_accuracy: 0.8935\n",
      "Epoch 68/300\n",
      "1317/1317 - 4s - loss: 0.4890 - categorical_accuracy: 0.8678 - val_loss: 0.4011 - val_categorical_accuracy: 0.8934\n",
      "Epoch 69/300\n",
      "1317/1317 - 4s - loss: 0.4812 - categorical_accuracy: 0.8672 - val_loss: 0.3949 - val_categorical_accuracy: 0.8940\n",
      "Epoch 70/300\n",
      "1317/1317 - 4s - loss: 0.4809 - categorical_accuracy: 0.8687 - val_loss: 0.3938 - val_categorical_accuracy: 0.8950\n",
      "Epoch 71/300\n",
      "1317/1317 - 4s - loss: 0.4770 - categorical_accuracy: 0.8695 - val_loss: 0.3952 - val_categorical_accuracy: 0.8945\n",
      "Epoch 72/300\n",
      "1317/1317 - 4s - loss: 0.4787 - categorical_accuracy: 0.8707 - val_loss: 0.3899 - val_categorical_accuracy: 0.8944\n",
      "Epoch 73/300\n",
      "1317/1317 - 4s - loss: 0.4725 - categorical_accuracy: 0.8716 - val_loss: 0.3894 - val_categorical_accuracy: 0.8951\n",
      "Epoch 74/300\n",
      "1317/1317 - 4s - loss: 0.4718 - categorical_accuracy: 0.8721 - val_loss: 0.3910 - val_categorical_accuracy: 0.8935\n",
      "Epoch 75/300\n",
      "1317/1317 - 4s - loss: 0.4666 - categorical_accuracy: 0.8709 - val_loss: 0.3855 - val_categorical_accuracy: 0.8949\n",
      "Epoch 76/300\n",
      "1317/1317 - 4s - loss: 0.4641 - categorical_accuracy: 0.8727 - val_loss: 0.3842 - val_categorical_accuracy: 0.8954\n",
      "Epoch 77/300\n",
      "1317/1317 - 4s - loss: 0.4672 - categorical_accuracy: 0.8723 - val_loss: 0.3817 - val_categorical_accuracy: 0.8967\n",
      "Epoch 78/300\n",
      "1317/1317 - 4s - loss: 0.4625 - categorical_accuracy: 0.8736 - val_loss: 0.3806 - val_categorical_accuracy: 0.8971\n",
      "Epoch 79/300\n",
      "1317/1317 - 4s - loss: 0.4622 - categorical_accuracy: 0.8739 - val_loss: 0.3779 - val_categorical_accuracy: 0.8963\n",
      "Epoch 80/300\n",
      "1317/1317 - 4s - loss: 0.4564 - categorical_accuracy: 0.8749 - val_loss: 0.3781 - val_categorical_accuracy: 0.8968\n",
      "Epoch 81/300\n",
      "1317/1317 - 4s - loss: 0.4536 - categorical_accuracy: 0.8771 - val_loss: 0.3718 - val_categorical_accuracy: 0.8969\n",
      "Epoch 82/300\n",
      "1317/1317 - 4s - loss: 0.4581 - categorical_accuracy: 0.8751 - val_loss: 0.3720 - val_categorical_accuracy: 0.8979\n",
      "Epoch 83/300\n",
      "1317/1317 - 4s - loss: 0.4496 - categorical_accuracy: 0.8767 - val_loss: 0.3728 - val_categorical_accuracy: 0.8980\n",
      "Epoch 84/300\n",
      "1317/1317 - 4s - loss: 0.4498 - categorical_accuracy: 0.8754 - val_loss: 0.3689 - val_categorical_accuracy: 0.9012\n",
      "Epoch 85/300\n",
      "1317/1317 - 4s - loss: 0.4502 - categorical_accuracy: 0.8752 - val_loss: 0.3686 - val_categorical_accuracy: 0.8995\n",
      "Epoch 86/300\n",
      "1317/1317 - 4s - loss: 0.4489 - categorical_accuracy: 0.8782 - val_loss: 0.3757 - val_categorical_accuracy: 0.8950\n",
      "Epoch 87/300\n",
      "1317/1317 - 4s - loss: 0.4443 - categorical_accuracy: 0.8793 - val_loss: 0.3644 - val_categorical_accuracy: 0.8996\n",
      "Epoch 88/300\n",
      "1317/1317 - 4s - loss: 0.4457 - categorical_accuracy: 0.8784 - val_loss: 0.3679 - val_categorical_accuracy: 0.8973\n",
      "Epoch 89/300\n",
      "1317/1317 - 4s - loss: 0.4455 - categorical_accuracy: 0.8769 - val_loss: 0.3613 - val_categorical_accuracy: 0.9011\n",
      "Epoch 90/300\n",
      "1317/1317 - 4s - loss: 0.4422 - categorical_accuracy: 0.8782 - val_loss: 0.3641 - val_categorical_accuracy: 0.8989\n",
      "Epoch 91/300\n",
      "1317/1317 - 4s - loss: 0.4401 - categorical_accuracy: 0.8784 - val_loss: 0.3595 - val_categorical_accuracy: 0.9002\n",
      "Epoch 92/300\n",
      "1317/1317 - 4s - loss: 0.4382 - categorical_accuracy: 0.8795 - val_loss: 0.3600 - val_categorical_accuracy: 0.8996\n",
      "Epoch 93/300\n",
      "1317/1317 - 4s - loss: 0.4352 - categorical_accuracy: 0.8799 - val_loss: 0.3560 - val_categorical_accuracy: 0.9022\n",
      "Epoch 94/300\n",
      "1317/1317 - 4s - loss: 0.4321 - categorical_accuracy: 0.8807 - val_loss: 0.3661 - val_categorical_accuracy: 0.8975\n",
      "Epoch 95/300\n",
      "1317/1317 - 4s - loss: 0.4345 - categorical_accuracy: 0.8792 - val_loss: 0.3533 - val_categorical_accuracy: 0.9023\n",
      "Epoch 96/300\n",
      "1317/1317 - 4s - loss: 0.4334 - categorical_accuracy: 0.8802 - val_loss: 0.3518 - val_categorical_accuracy: 0.9026\n",
      "Epoch 97/300\n",
      "1317/1317 - 4s - loss: 0.4270 - categorical_accuracy: 0.8826 - val_loss: 0.3540 - val_categorical_accuracy: 0.9006\n",
      "Epoch 98/300\n",
      "1317/1317 - 4s - loss: 0.4301 - categorical_accuracy: 0.8821 - val_loss: 0.3550 - val_categorical_accuracy: 0.9011\n",
      "Epoch 99/300\n",
      "1317/1317 - 4s - loss: 0.4283 - categorical_accuracy: 0.8818 - val_loss: 0.3492 - val_categorical_accuracy: 0.9032\n",
      "Epoch 100/300\n",
      "1317/1317 - 4s - loss: 0.4295 - categorical_accuracy: 0.8805 - val_loss: 0.3484 - val_categorical_accuracy: 0.9021\n",
      "Epoch 101/300\n",
      "1317/1317 - 4s - loss: 0.4282 - categorical_accuracy: 0.8804 - val_loss: 0.3486 - val_categorical_accuracy: 0.9037\n",
      "Epoch 102/300\n",
      "1317/1317 - 4s - loss: 0.4253 - categorical_accuracy: 0.8828 - val_loss: 0.3467 - val_categorical_accuracy: 0.9032\n",
      "Epoch 103/300\n",
      "1317/1317 - 4s - loss: 0.4212 - categorical_accuracy: 0.8825 - val_loss: 0.3458 - val_categorical_accuracy: 0.9031\n",
      "Epoch 104/300\n",
      "1317/1317 - 4s - loss: 0.4194 - categorical_accuracy: 0.8833 - val_loss: 0.3445 - val_categorical_accuracy: 0.9037\n",
      "Epoch 105/300\n",
      "1317/1317 - 4s - loss: 0.4183 - categorical_accuracy: 0.8832 - val_loss: 0.3416 - val_categorical_accuracy: 0.9051\n",
      "Epoch 106/300\n",
      "1317/1317 - 4s - loss: 0.4149 - categorical_accuracy: 0.8847 - val_loss: 0.3408 - val_categorical_accuracy: 0.9041\n",
      "Epoch 107/300\n",
      "1317/1317 - 4s - loss: 0.4205 - categorical_accuracy: 0.8822 - val_loss: 0.3433 - val_categorical_accuracy: 0.9037\n",
      "Epoch 108/300\n",
      "1317/1317 - 4s - loss: 0.4161 - categorical_accuracy: 0.8844 - val_loss: 0.3389 - val_categorical_accuracy: 0.9056\n",
      "Epoch 109/300\n",
      "1317/1317 - 4s - loss: 0.4157 - categorical_accuracy: 0.8837 - val_loss: 0.3380 - val_categorical_accuracy: 0.9045\n",
      "Epoch 110/300\n",
      "1317/1317 - 5s - loss: 0.4151 - categorical_accuracy: 0.8848 - val_loss: 0.3404 - val_categorical_accuracy: 0.9049\n",
      "Epoch 111/300\n",
      "1317/1317 - 5s - loss: 0.4144 - categorical_accuracy: 0.8845 - val_loss: 0.3407 - val_categorical_accuracy: 0.9033\n",
      "Epoch 112/300\n",
      "1317/1317 - 4s - loss: 0.4118 - categorical_accuracy: 0.8845 - val_loss: 0.3407 - val_categorical_accuracy: 0.9040\n",
      "Epoch 113/300\n",
      "1317/1317 - 4s - loss: 0.4143 - categorical_accuracy: 0.8837 - val_loss: 0.3346 - val_categorical_accuracy: 0.9060\n",
      "Epoch 114/300\n",
      "1317/1317 - 4s - loss: 0.4088 - categorical_accuracy: 0.8871 - val_loss: 0.3350 - val_categorical_accuracy: 0.9064\n",
      "Epoch 115/300\n",
      "1317/1317 - 4s - loss: 0.4081 - categorical_accuracy: 0.8859 - val_loss: 0.3378 - val_categorical_accuracy: 0.9043\n",
      "Epoch 116/300\n",
      "1317/1317 - 4s - loss: 0.4067 - categorical_accuracy: 0.8855 - val_loss: 0.3304 - val_categorical_accuracy: 0.9061\n",
      "Epoch 117/300\n",
      "1317/1317 - 4s - loss: 0.4051 - categorical_accuracy: 0.8867 - val_loss: 0.3313 - val_categorical_accuracy: 0.9063\n",
      "Epoch 118/300\n",
      "1317/1317 - 4s - loss: 0.4074 - categorical_accuracy: 0.8866 - val_loss: 0.3314 - val_categorical_accuracy: 0.9062\n",
      "Epoch 119/300\n",
      "1317/1317 - 4s - loss: 0.4053 - categorical_accuracy: 0.8867 - val_loss: 0.3334 - val_categorical_accuracy: 0.9049\n",
      "Epoch 120/300\n",
      "1317/1317 - 4s - loss: 0.4052 - categorical_accuracy: 0.8875 - val_loss: 0.3293 - val_categorical_accuracy: 0.9068\n",
      "Epoch 121/300\n",
      "1317/1317 - 4s - loss: 0.4050 - categorical_accuracy: 0.8862 - val_loss: 0.3292 - val_categorical_accuracy: 0.9075\n",
      "Epoch 122/300\n",
      "1317/1317 - 4s - loss: 0.4031 - categorical_accuracy: 0.8872 - val_loss: 0.3329 - val_categorical_accuracy: 0.9055\n",
      "Epoch 123/300\n",
      "1317/1317 - 4s - loss: 0.4012 - categorical_accuracy: 0.8867 - val_loss: 0.3396 - val_categorical_accuracy: 0.9021\n",
      "Epoch 124/300\n",
      "1317/1317 - 4s - loss: 0.3993 - categorical_accuracy: 0.8885 - val_loss: 0.3305 - val_categorical_accuracy: 0.9068\n",
      "Epoch 125/300\n",
      "1317/1317 - 4s - loss: 0.3990 - categorical_accuracy: 0.8883 - val_loss: 0.3257 - val_categorical_accuracy: 0.9069\n",
      "Epoch 126/300\n",
      "1317/1317 - 4s - loss: 0.3942 - categorical_accuracy: 0.8886 - val_loss: 0.3240 - val_categorical_accuracy: 0.9078\n",
      "Epoch 127/300\n",
      "1317/1317 - 4s - loss: 0.4009 - categorical_accuracy: 0.8873 - val_loss: 0.3249 - val_categorical_accuracy: 0.9082\n",
      "Epoch 128/300\n",
      "1317/1317 - 4s - loss: 0.3943 - categorical_accuracy: 0.8890 - val_loss: 0.3246 - val_categorical_accuracy: 0.9072\n",
      "Epoch 129/300\n",
      "1317/1317 - 4s - loss: 0.3969 - categorical_accuracy: 0.8893 - val_loss: 0.3247 - val_categorical_accuracy: 0.9080\n",
      "Epoch 130/300\n",
      "1317/1317 - 4s - loss: 0.3923 - categorical_accuracy: 0.8909 - val_loss: 0.3229 - val_categorical_accuracy: 0.9081\n",
      "Epoch 131/300\n",
      "1317/1317 - 4s - loss: 0.3963 - categorical_accuracy: 0.8896 - val_loss: 0.3238 - val_categorical_accuracy: 0.9090\n",
      "Epoch 132/300\n",
      "1317/1317 - 4s - loss: 0.3917 - categorical_accuracy: 0.8895 - val_loss: 0.3232 - val_categorical_accuracy: 0.9081\n",
      "Epoch 133/300\n",
      "1317/1317 - 4s - loss: 0.3944 - categorical_accuracy: 0.8894 - val_loss: 0.3239 - val_categorical_accuracy: 0.9074\n",
      "Epoch 134/300\n",
      "1317/1317 - 4s - loss: 0.3910 - categorical_accuracy: 0.8903 - val_loss: 0.3202 - val_categorical_accuracy: 0.9079\n",
      "Epoch 135/300\n",
      "1317/1317 - 4s - loss: 0.3891 - categorical_accuracy: 0.8910 - val_loss: 0.3197 - val_categorical_accuracy: 0.9091\n",
      "Epoch 136/300\n",
      "1317/1317 - 4s - loss: 0.3868 - categorical_accuracy: 0.8915 - val_loss: 0.3274 - val_categorical_accuracy: 0.9054\n",
      "Epoch 137/300\n",
      "1317/1317 - 4s - loss: 0.3868 - categorical_accuracy: 0.8918 - val_loss: 0.3180 - val_categorical_accuracy: 0.9093\n",
      "Epoch 138/300\n",
      "1317/1317 - 4s - loss: 0.3896 - categorical_accuracy: 0.8903 - val_loss: 0.3179 - val_categorical_accuracy: 0.9089\n",
      "Epoch 139/300\n",
      "1317/1317 - 4s - loss: 0.3854 - categorical_accuracy: 0.8909 - val_loss: 0.3167 - val_categorical_accuracy: 0.9100\n",
      "Epoch 140/300\n",
      "1317/1317 - 4s - loss: 0.3885 - categorical_accuracy: 0.8907 - val_loss: 0.3187 - val_categorical_accuracy: 0.9094\n",
      "Epoch 141/300\n",
      "1317/1317 - 4s - loss: 0.3851 - categorical_accuracy: 0.8918 - val_loss: 0.3151 - val_categorical_accuracy: 0.9092\n",
      "Epoch 142/300\n",
      "1317/1317 - 4s - loss: 0.3844 - categorical_accuracy: 0.8921 - val_loss: 0.3185 - val_categorical_accuracy: 0.9073\n",
      "Epoch 143/300\n",
      "1317/1317 - 4s - loss: 0.3832 - categorical_accuracy: 0.8919 - val_loss: 0.3182 - val_categorical_accuracy: 0.9094\n",
      "Epoch 144/300\n",
      "1317/1317 - 4s - loss: 0.3829 - categorical_accuracy: 0.8918 - val_loss: 0.3129 - val_categorical_accuracy: 0.9108\n",
      "Epoch 145/300\n",
      "1317/1317 - 4s - loss: 0.3810 - categorical_accuracy: 0.8918 - val_loss: 0.3144 - val_categorical_accuracy: 0.9104\n",
      "Epoch 146/300\n",
      "1317/1317 - 4s - loss: 0.3810 - categorical_accuracy: 0.8932 - val_loss: 0.3154 - val_categorical_accuracy: 0.9117\n",
      "Epoch 147/300\n",
      "1317/1317 - 4s - loss: 0.3822 - categorical_accuracy: 0.8917 - val_loss: 0.3103 - val_categorical_accuracy: 0.9115\n",
      "Epoch 148/300\n",
      "1317/1317 - 4s - loss: 0.3773 - categorical_accuracy: 0.8930 - val_loss: 0.3130 - val_categorical_accuracy: 0.9098\n",
      "Epoch 149/300\n",
      "1317/1317 - 4s - loss: 0.3803 - categorical_accuracy: 0.8923 - val_loss: 0.3127 - val_categorical_accuracy: 0.9103\n",
      "Epoch 150/300\n",
      "1317/1317 - 4s - loss: 0.3765 - categorical_accuracy: 0.8936 - val_loss: 0.3105 - val_categorical_accuracy: 0.9109\n",
      "Epoch 151/300\n",
      "1317/1317 - 4s - loss: 0.3785 - categorical_accuracy: 0.8914 - val_loss: 0.3123 - val_categorical_accuracy: 0.9114\n",
      "Epoch 152/300\n",
      "1317/1317 - 4s - loss: 0.3754 - categorical_accuracy: 0.8933 - val_loss: 0.3065 - val_categorical_accuracy: 0.9121\n",
      "Epoch 153/300\n",
      "1317/1317 - 4s - loss: 0.3785 - categorical_accuracy: 0.8933 - val_loss: 0.3130 - val_categorical_accuracy: 0.9101\n",
      "Epoch 154/300\n",
      "1317/1317 - 4s - loss: 0.3734 - categorical_accuracy: 0.8949 - val_loss: 0.3094 - val_categorical_accuracy: 0.9105\n",
      "Epoch 155/300\n",
      "1317/1317 - 4s - loss: 0.3754 - categorical_accuracy: 0.8938 - val_loss: 0.3160 - val_categorical_accuracy: 0.9070\n",
      "Epoch 156/300\n",
      "1317/1317 - 4s - loss: 0.3731 - categorical_accuracy: 0.8943 - val_loss: 0.3086 - val_categorical_accuracy: 0.9135\n",
      "Epoch 157/300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1317/1317 - 4s - loss: 0.3747 - categorical_accuracy: 0.8927 - val_loss: 0.3096 - val_categorical_accuracy: 0.9112\n",
      "Epoch 00157: early stopping\n",
      "1317/1317 [==============================] - 3s 2ms/step - loss: 0.2861 - categorical_accuracy: 0.9200\n",
      "Training loss: 0.2861, Traning accuracy: 0.9200\n",
      "330/330 [==============================] - 1s 2ms/step - loss: 0.3065 - categorical_accuracy: 0.9121\n",
      "Validation loss:  0.3065, Validation accuracy: 0.9121\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.9108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9107613525114843"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(X_train,y_train,char_size,optim='sgd')\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(model, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTrm_Ks-KI4g"
   },
   "source": [
    "# **Confusion Matrix to Measure the Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pr_x4tltKSYc",
    "outputId": "b78e477b-b77e-49d2-cce4-7501168b0421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           en  und    es    ja   id   pt   ar  th   fr   tr  ms   ru  hi-Latn  \\\n",
      "en       4663   40    20     0   11    9    0   0    5    1   0    1        0   \n",
      "und       169  852    63     9   87   15    4   0    5    5   0    5        0   \n",
      "es         13   16  1427     0    5    9    0   0    3    0   0    0        0   \n",
      "ja          0   14     0  2460    0    0    0   0    1    0   0    0        0   \n",
      "id         27   22     5     2  752    2    0   0    1    2   0    0        0   \n",
      "pt         15   10    53     0    3  610    0   0    6    0   0    0        0   \n",
      "ar          0    0     0     0    0    0  528   0    0    0   0    0        0   \n",
      "th          0    0     0     2    0    0    0  96    0    0   0    0        0   \n",
      "fr         25    2     8     0    2    3    0   0  183    1   0    0        0   \n",
      "tr          3    3     1     0   12    0    0   0    0  154   0    0        0   \n",
      "ms          1    0     0     0   30    0    0   0    0    0   0    0        0   \n",
      "ru          0    1     0     0    0    0    0   0    0    0   0  242        0   \n",
      "hi-Latn     2    1     0     0    1    0    0   0    0    0   0    0        0   \n",
      "bs          0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "xh          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ko          0    8     0     4    0    0    0   1    0    1   0    0        0   \n",
      "it          2    3    13     0    1    4    0   0    1    1   0    0        0   \n",
      "tl         12    7     2     0   13    0    0   0    0    0   0    0        0   \n",
      "sv          2    0     0     1    0    0    0   0    0    0   0    0        0   \n",
      "ta          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "he          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "de          9    0     0     0    0    0    0   0    1    0   0    0        0   \n",
      "el          0    1     1     1    0    0    0   0    0    0   0    0        0   \n",
      "pl          1    4     0     0    0    1    0   0    0    0   0    0        0   \n",
      "nl          9    2     0     0    0    0    0   0    4    0   0    0        0   \n",
      "fa          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "mr          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ar_LATN     0    1     0     0    2    0    0   0    0    0   0    0        0   \n",
      "sr          0    0     0     0    4    0    0   0    0    1   0    0        0   \n",
      "sw          0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "ur          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ca          0    0     2     0    0    0    0   0    1    0   0    0        0   \n",
      "vi          1    0     0     0    2    0    0   0    0    0   0    0        0   \n",
      "km          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ja_LATN     0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "mn          0    0     0     0    0    0    0   0    0    0   0    1        0   \n",
      "fi          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "az          0    0     0     0    0    0    0   0    0    2   0    0        0   \n",
      "eu          1    0     0     0    0    0    0   0    0    0   0    0        1   \n",
      "lv          0    3     1     0    0    0    0   0    0    0   0    0        0   \n",
      "zh-TW       0    0     0     4    0    0    0   0    0    0   0    0        0   \n",
      "zu          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "cs          0    0     0     0    0    1    0   0    0    0   0    0        0   \n",
      "bg          0    0     0     0    0    0    0   0    0    0   0    2        0   \n",
      "zh-CN       0    0     0     1    0    0    0   0    0    0   0    0        0   \n",
      "ht          1    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "la          0    0     0     0    0    1    0   0    0    0   0    0        0   \n",
      "yo          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "uk          0    0     0     0    0    0    0   0    0    0   0    2        0   \n",
      "hi          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "da          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "hr          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ro          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "jv          0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "no          0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ko_LATN     1    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "mk          0    0     0     0    0    0    0   0    0    0   0    1        0   \n",
      "ur_LATN     0    0     0     0    0    0    0   0    0    0   0    0        0   \n",
      "sk          0    1     0     0    0    0    0   0    0    0   0    0        0   \n",
      "ta_LATN     0    0     0     0    1    0    0   0    0    0   0    0        0   \n",
      "\n",
      "         bs  xh  ko  it  tl  sv  ta  he  de  el  pl  nl  fa  mr  ar_LATN  sr  \\\n",
      "en        0   0   0   1   2   1   0   0   0   0   2   1   0   0        0   0   \n",
      "und       0   0   3   2   4   0   0   0   1   0   0   3   0   0        0   0   \n",
      "es        0   0   0   2   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ja        0   0   2   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "id        0   0   0   0   4   0   0   0   0   0   0   0   0   0        0   0   \n",
      "pt        0   0   0   2   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ar        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "th        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "fr        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "tr        0   0   0   0   0   1   0   0   0   0   0   0   0   0        0   0   \n",
      "ms        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ru        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "hi-Latn   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "bs        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "xh        0   0   0   0   1   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ko        0   0  93   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "it        0   0   0  51   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "tl        0   0   0   1  54   0   0   0   0   0   0   0   0   0        0   0   \n",
      "sv        0   0   0   0   0  10   0   0   0   0   1   1   0   0        0   0   \n",
      "ta        0   0   0   0   0   0   3   0   0   0   0   0   0   0        0   0   \n",
      "he        0   0   0   0   0   0   0  13   0   0   0   0   0   0        0   0   \n",
      "de        0   0   0   0   0   0   0   0  39   0   0   1   0   0        0   0   \n",
      "el        0   0   1   0   0   0   0   0   0   6   0   0   0   0        0   0   \n",
      "pl        0   0   0   0   1   0   0   0   0   0  18   1   0   0        0   0   \n",
      "nl        0   0   0   0   0   0   0   0   0   0   0  28   0   0        0   0   \n",
      "fa        0   0   0   0   0   0   0   0   0   0   0   0   2   0        0   0   \n",
      "mr        0   0   0   0   0   1   0   0   0   0   0   0   0   0        0   0   \n",
      "ar_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "sr        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "sw        0   0   0   0   1   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ur        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ca        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "vi        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "km        0   0   1   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ja_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "mn        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "fi        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "az        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "eu        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "lv        0   0   0   0   0   0   0   0   0   0   1   0   0   0        0   0   \n",
      "zh-TW     0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "zu        0   0   0   0   1   0   0   0   0   0   0   0   0   0        0   0   \n",
      "cs        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "bg        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "zh-CN     0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ht        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "la        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "yo        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "uk        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "hi        0   0   1   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "da        0   0   0   0   0   1   0   0   0   0   0   0   0   0        0   0   \n",
      "hr        0   0   0   1   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ro        0   0   0   1   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "jv        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "no        0   0   0   0   0   0   0   0   0   0   0   1   0   0        0   0   \n",
      "ko_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "mk        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ur_LATN   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0   0   \n",
      "sk        0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "ta_LATN   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0   0   \n",
      "\n",
      "         sw  ur  ca  vi  km  ja_LATN  mn  fi  az  eu  lv  zh-TW  zu  cs  bg  \\\n",
      "en        0   0   0   1   0        0   0   0   0   0   0      0   0   0   0   \n",
      "und       0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "es        0   0   0   1   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ja        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "id        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "pt        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ar        0   0   0   0   0        0   0   0   0   0   0      1   0   0   0   \n",
      "th        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "fr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "tr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ms        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ru        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "hi-Latn   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "bs        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "xh        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ko        0   0   0   3   0        0   0   0   0   0   0      0   0   0   0   \n",
      "it        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "tl        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "sv        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ta        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "he        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "de        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "el        0   0   0   1   0        0   0   0   0   0   0      0   0   0   0   \n",
      "pl        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "nl        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "fa        0   3   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "mr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ar_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "sr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "sw        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ur        0   5   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ca        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "vi        0   0   0   2   0        0   0   0   0   0   0      0   0   0   0   \n",
      "km        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ja_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "mn        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "fi        0   0   0   0   0        0   0   8   0   0   0      0   0   0   0   \n",
      "az        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "eu        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "lv        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "zh-TW     0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "zu        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "cs        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "bg        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "zh-CN     0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ht        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "la        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "yo        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "uk        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "hi        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "da        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "hr        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ro        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "jv        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "no        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ko_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "mk        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ur_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "sk        0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "ta_LATN   0   0   0   0   0        0   0   0   0   0   0      0   0   0   0   \n",
      "\n",
      "         zh-CN  ht  la  yo  uk  hi  da  hr  ro  jv  no  ko_LATN  mk  ur_LATN  \\\n",
      "en           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "und          0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "es           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ja           1   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "id           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "pt           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ar           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "th           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "fr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "tr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ms           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ru           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "hi-Latn      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "bs           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "xh           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ko           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "it           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "tl           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sv           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ta           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "he           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "de           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "el           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "pl           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "nl           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "fa           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "mr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ar_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sw           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ur           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ca           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "vi           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "km           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ja_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "mn           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "fi           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "az           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "eu           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "lv           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "zh-TW        0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "zu           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "cs           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "bg           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "zh-CN        0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ht           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "la           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "yo           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "uk           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "hi           0   0   0   0   0   3   0   0   0   0   0        0   0        0   \n",
      "da           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "hr           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ro           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "jv           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "no           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ko_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "mk           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ur_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "sk           0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "ta_LATN      0   0   0   0   0   0   0   0   0   0   0        0   0        0   \n",
      "\n",
      "         sk  ta_LATN  \n",
      "en        0        0  \n",
      "und       0        0  \n",
      "es        0        0  \n",
      "ja        0        0  \n",
      "id        0        0  \n",
      "pt        0        0  \n",
      "ar        0        0  \n",
      "th        0        0  \n",
      "fr        0        0  \n",
      "tr        0        0  \n",
      "ms        0        0  \n",
      "ru        0        0  \n",
      "hi-Latn   0        0  \n",
      "bs        0        0  \n",
      "xh        0        0  \n",
      "ko        0        0  \n",
      "it        0        0  \n",
      "tl        0        0  \n",
      "sv        0        0  \n",
      "ta        0        0  \n",
      "he        0        0  \n",
      "de        0        0  \n",
      "el        0        0  \n",
      "pl        0        0  \n",
      "nl        0        0  \n",
      "fa        0        0  \n",
      "mr        0        0  \n",
      "ar_LATN   0        0  \n",
      "sr        0        0  \n",
      "sw        0        0  \n",
      "ur        0        0  \n",
      "ca        0        0  \n",
      "vi        0        0  \n",
      "km        0        0  \n",
      "ja_LATN   0        0  \n",
      "mn        0        0  \n",
      "fi        0        0  \n",
      "az        0        0  \n",
      "eu        0        0  \n",
      "lv        0        0  \n",
      "zh-TW     0        0  \n",
      "zu        0        0  \n",
      "cs        0        0  \n",
      "bg        0        0  \n",
      "zh-CN     0        0  \n",
      "ht        0        0  \n",
      "la        0        0  \n",
      "yo        0        0  \n",
      "uk        0        0  \n",
      "hi        0        0  \n",
      "da        0        0  \n",
      "hr        0        0  \n",
      "ro        0        0  \n",
      "jv        0        0  \n",
      "no        0        0  \n",
      "ko_LATN   0        0  \n",
      "mk        0        0  \n",
      "ur_LATN   0        0  \n",
      "sk        0        0  \n",
      "ta_LATN   0        0  \n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model_an.predict(X_test)\n",
    "y_pred_idx = [np.argmax(y_pred_probs[i]) for i in range(len(y_pred_probs))]\n",
    "pred_labels = [unique_labels[idx] for idx in y_pred_idx]\n",
    "\n",
    "# confusion matrices\n",
    "test_labels = df_test['label'].unique()\n",
    "\n",
    "cm =  confusion_matrix(df_test['label'], pred_labels, labels=test_labels)\n",
    "cm = pd.DataFrame(cm, index=test_labels, columns=test_labels)\n",
    "print(cm)\n",
    "cm.to_csv(\"confusion matrix.csv\",index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lybD9hycOI-z"
   },
   "source": [
    "**average macro precision, recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rS0o23Z_OO5C",
    "outputId": "df0cb746-a0f7-4d69-f2ee-256587375a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average macro (precision, recall) of CNN:  (0.38052137842921757, 0.3506492363964591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# average macro precision and recall \n",
    "ave_precision = precision_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "ave_recall = recall_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "print(\"average macro (precision, recall) of CNN: \", (ave_precision, ave_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrNHKfI6hEuX"
   },
   "source": [
    "**macro precision and recall for each class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Q6NuKrvhRZz",
    "outputId": "cc452b39-b9e5-454e-931a-c4e00bf60c3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics of Multi-layer perceptron model: \n",
      "          precision    recall\n",
      "en        0.940690  0.980034\n",
      "und       0.856281  0.693247\n",
      "es        0.894110  0.966802\n",
      "ja        0.990338  0.992736\n",
      "id        0.809473  0.920441\n",
      "pt        0.931298  0.872675\n",
      "ar        0.992481  0.998110\n",
      "th        0.989691  0.979592\n",
      "fr        0.867299  0.816964\n",
      "tr        0.916667  0.885057\n",
      "ms        0.000000  0.000000\n",
      "ru        0.952756  0.995885\n",
      "hi-Latn   0.000000  0.000000\n",
      "bs        0.000000  0.000000\n",
      "xh        0.000000  0.000000\n",
      "ko        0.920792  0.845455\n",
      "it        0.836066  0.671053\n",
      "tl        0.794118  0.606742\n",
      "sv        0.714286  0.666667\n",
      "ta        1.000000  1.000000\n",
      "he        1.000000  0.928571\n",
      "de        0.975000  0.780000\n",
      "el        1.000000  0.545455\n",
      "pl        0.818182  0.692308\n",
      "nl        0.756757  0.651163\n",
      "fa        1.000000  0.400000\n",
      "mr        0.000000  0.000000\n",
      "ar_LATN   0.000000  0.000000\n",
      "sr        0.000000  0.000000\n",
      "sw        0.000000  0.000000\n",
      "ur        0.625000  1.000000\n",
      "ca        0.000000  0.000000\n",
      "vi        0.250000  0.400000\n",
      "km        0.000000  0.000000\n",
      "ja_LATN   0.000000  0.000000\n",
      "mn        0.000000  0.000000\n",
      "fi        1.000000  1.000000\n",
      "az        0.000000  0.000000\n",
      "eu        0.000000  0.000000\n",
      "lv        0.000000  0.000000\n",
      "zh-TW     0.000000  0.000000\n",
      "zu        0.000000  0.000000\n",
      "cs        0.000000  0.000000\n",
      "bg        0.000000  0.000000\n",
      "zh-CN     0.000000  0.000000\n",
      "ht        0.000000  0.000000\n",
      "la        0.000000  0.000000\n",
      "yo        0.000000  0.000000\n",
      "uk        0.000000  0.000000\n",
      "hi        1.000000  0.750000\n",
      "da        0.000000  0.000000\n",
      "hr        0.000000  0.000000\n",
      "ro        0.000000  0.000000\n",
      "jv        0.000000  0.000000\n",
      "no        0.000000  0.000000\n",
      "ko_LATN   0.000000  0.000000\n",
      "mk        0.000000  0.000000\n",
      "ur_LATN   0.000000  0.000000\n",
      "sk        0.000000  0.000000\n",
      "ta_LATN   0.000000  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# precision and recall of each label\n",
    "precision = precision_score(df_test['label'], pred_labels, labels=test_labels, average=None).reshape(-1,1)\n",
    "recall = recall_score(df_test['label'], pred_labels, labels=test_labels, average=None).reshape(-1,1)\n",
    "\n",
    "# concatenate precision and recall of each model\n",
    "metrics = np.concatenate([precision, recall],axis=1)\n",
    "\n",
    "# add column names and row index labels, print metrics \n",
    "metrics = pd.DataFrame(metrics, columns=['precision', 'recall'])\n",
    "metrics.index = test_labels\n",
    "\n",
    "print('\\nMetrics of Multi-layer perceptron model: \\n', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmunuqnsXPk_",
    "outputId": "d45e5edf-7309-4e5a-942f-61124269c205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tweet\n",
      "label         \n",
      "ar         529\n",
      "ar_LATN      3\n",
      "az           2\n",
      "bg           2\n",
      "bs           1\n",
      "ca           3\n",
      "cs           1\n",
      "da           1\n",
      "de          50\n",
      "el          11\n",
      "en        4758\n",
      "es        1476\n",
      "eu           2\n",
      "fa           5\n",
      "fi           8\n",
      "fr         224\n",
      "he          14\n",
      "hi           4\n",
      "hi-Latn      4\n",
      "hr           1\n",
      "ht           1\n",
      "id         817\n",
      "it          76\n",
      "ja        2478\n",
      "ja_LATN      1\n",
      "jv           1\n",
      "km           1\n",
      "ko         110\n",
      "ko_LATN      1\n",
      "la           1\n",
      "lv           5\n",
      "mk           1\n",
      "mn           1\n",
      "mr           1\n",
      "ms          31\n",
      "nl          43\n",
      "no           1\n",
      "pl          26\n",
      "pt         699\n",
      "ro           2\n",
      "ru         243\n",
      "sk           1\n",
      "sr           7\n",
      "sv          15\n",
      "sw           2\n",
      "ta           3\n",
      "ta_LATN      1\n",
      "th          98\n",
      "tl          89\n",
      "tr         174\n",
      "uk           2\n",
      "und       1229\n",
      "ur           5\n",
      "ur_LATN      1\n",
      "vi           5\n",
      "xh           1\n",
      "yo           1\n",
      "zh-CN        1\n",
      "zh-TW        4\n",
      "zu           1\n"
     ]
    }
   ],
   "source": [
    "print(df_test.groupby(['label']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZultiK2K0ta"
   },
   "source": [
    "# **Heatmap Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "hTz82P7LK6JY",
    "outputId": "a9b42816-4d31-4281-f6dc-1e93ed72892c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pooling strategy</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batch size</th>\n",
       "      <th>strides</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pooling strategy  dropout  batch size  strides  optimizer  accuracy\n",
       "0                 0      0.5          32        1          0    0.9264\n",
       "1                 1      0.5          32        1          0    0.9261\n",
       "2                 0      0.0          32        1          0    0.9197\n",
       "3                 0      0.5          16        1          0    0.9263\n",
       "4                 0      0.5          32        5          0    0.8596\n",
       "5                 0      0.5          32        1          1    0.9108"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global max pooling: 0, global average pooling:1\n",
    "# optimizer='adam':0, optimizer='sgd':1\n",
    "table = pd.DataFrame([[0,0.5,32,1,0,0.9264],[1,0.5,32,1,0,0.9261], \n",
    "         [0,0,32,1,0,0.9197],[0,0.5,16,1,0,0.9263],[0,0.5,32,5,0,0.8596],[0,0.5,32,1,1,0.9108]],\n",
    "          columns=['pooling strategy','dropout','batch size','strides','optimizer','accuracy'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "b3S4uxICfgJL",
    "outputId": "2f3d0203-da54-45e4-b747-006e656b7923"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f82dfee06a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(table.corr(),annot=True, fmt='.1g', cmap= 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HGiI_QcEh5i"
   },
   "source": [
    "# **Compare with MLP**\n",
    "MLP is the best model in Ex01.\n",
    "As the data preprocess is different here from Ex01, so here I train the MLP again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BhmX83RKFWm",
    "outputId": "6f530f16-4c1a-4b0c-feb0-145ee201db0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.26667468\n",
      "Validation score: 0.317578\n",
      "Iteration 2, loss = 2.59435415\n",
      "Validation score: 0.279803\n",
      "Iteration 3, loss = 2.41048761\n",
      "Validation score: 0.401291\n",
      "Iteration 4, loss = 2.30742557\n",
      "Validation score: 0.454252\n",
      "Iteration 5, loss = 2.23086669\n",
      "Validation score: 0.431283\n",
      "Iteration 6, loss = 2.17749465\n",
      "Validation score: 0.430524\n",
      "Iteration 7, loss = 2.12853890\n",
      "Validation score: 0.354784\n",
      "Iteration 8, loss = 2.08967746\n",
      "Validation score: 0.424260\n",
      "Iteration 9, loss = 2.03874302\n",
      "Validation score: 0.395786\n",
      "Iteration 10, loss = 2.00305406\n",
      "Validation score: 0.413629\n",
      "Iteration 11, loss = 1.97431382\n",
      "Validation score: 0.457479\n",
      "Iteration 12, loss = 1.95007042\n",
      "Validation score: 0.464313\n",
      "Iteration 13, loss = 1.93143979\n",
      "Validation score: 0.433751\n",
      "Iteration 14, loss = 1.90136044\n",
      "Validation score: 0.474943\n",
      "Iteration 15, loss = 1.86623576\n",
      "Validation score: 0.457479\n",
      "Iteration 16, loss = 1.85407321\n",
      "Validation score: 0.456150\n",
      "Iteration 17, loss = 1.82918793\n",
      "Validation score: 0.512149\n",
      "Iteration 18, loss = 1.80762350\n",
      "Validation score: 0.500000\n",
      "Iteration 19, loss = 1.78563944\n",
      "Validation score: 0.487092\n",
      "Iteration 20, loss = 1.76750916\n",
      "Validation score: 0.488990\n",
      "Iteration 21, loss = 1.74379829\n",
      "Validation score: 0.514806\n",
      "Iteration 22, loss = 1.72197258\n",
      "Validation score: 0.481397\n",
      "Iteration 23, loss = 1.71200615\n",
      "Validation score: 0.507024\n",
      "Iteration 24, loss = 1.70505542\n",
      "Validation score: 0.461465\n",
      "Iteration 25, loss = 1.68361175\n",
      "Validation score: 0.448937\n",
      "Iteration 26, loss = 1.66778501\n",
      "Validation score: 0.409453\n",
      "Iteration 27, loss = 1.65088574\n",
      "Validation score: 0.507024\n",
      "Iteration 28, loss = 1.63535224\n",
      "Validation score: 0.403759\n",
      "Iteration 29, loss = 1.62242504\n",
      "Validation score: 0.517274\n",
      "Iteration 30, loss = 1.60585169\n",
      "Validation score: 0.507973\n",
      "Iteration 31, loss = 1.59606338\n",
      "Validation score: 0.485194\n",
      "Iteration 32, loss = 1.58581322\n",
      "Validation score: 0.492407\n",
      "Iteration 33, loss = 1.56613798\n",
      "Validation score: 0.506454\n",
      "Iteration 34, loss = 1.56178028\n",
      "Validation score: 0.544609\n",
      "Iteration 35, loss = 1.53342298\n",
      "Validation score: 0.424639\n",
      "Iteration 36, loss = 1.51462316\n",
      "Validation score: 0.500569\n",
      "Iteration 37, loss = 1.50294571\n",
      "Validation score: 0.458428\n",
      "Iteration 38, loss = 1.49311008\n",
      "Validation score: 0.466781\n",
      "Iteration 39, loss = 1.49055642\n",
      "Validation score: 0.497912\n",
      "Iteration 40, loss = 1.46610267\n",
      "Validation score: 0.481967\n",
      "Iteration 41, loss = 1.45601440\n",
      "Validation score: 0.527335\n",
      "Iteration 42, loss = 1.44264126\n",
      "Validation score: 0.474374\n",
      "Iteration 43, loss = 1.43268946\n",
      "Validation score: 0.491458\n",
      "Iteration 44, loss = 1.43368457\n",
      "Validation score: 0.511390\n",
      "Iteration 45, loss = 1.41433579\n",
      "Validation score: 0.521450\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "-------------prediction accuracy--------------\n",
      "Test Accuracy is: 0.5674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5674373070261315"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train models\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(800,),shuffle=True, random_state=RANDOM_STATE, verbose=True, activation='tanh', solver='adam', early_stopping=True)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "print(\"-------------prediction accuracy--------------\")\n",
    "prediction(mlp, X_test, label_test, unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dAsZ3pDfoTU"
   },
   "source": [
    "**macro precision, recall of MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbkFHglDfecj",
    "outputId": "1fea1b80-5521-454e-bb6a-daabfcc06c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average macro (precision, recall) of CNN:  (0.10010165566557795, 0.05949356025692754)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = mlp.predict(X_test)\n",
    "y_pred_idx = [np.argmax(y_pred_probs[i]) for i in range(len(y_pred_probs))]\n",
    "pred_labels = [unique_labels[idx] for idx in y_pred_idx]\n",
    "\n",
    "# average macro precision and recall \n",
    "ave_precision = precision_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "ave_recall = recall_score(df_test['label'], pred_labels, labels=test_labels, average='macro')\n",
    "print(\"average macro (precision, recall) of CNN: \", (ave_precision, ave_recall))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ex03_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
