{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex01_mlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2kUmUfikpaz"
      },
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from io import StringIO\n",
        "import requests\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing, linear_model, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss, make_scorer, recall_score, precision_score, f1_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "RANDOM_STATE = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iAQkWFXk-N2"
      },
      "source": [
        "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
        "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeYQxpnalJmR"
      },
      "source": [
        "def load_dataset(url):\n",
        "    r = requests.get(url)\n",
        "    data = r.content.decode('utf8')\n",
        "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
        "    df.columns = ['tweet', 'label']\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoq6s5GKlSi0"
      },
      "source": [
        "df_train_dev = load_dataset(url_train_dev)\n",
        "df_test = load_dataset(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM1GZZxplXmu",
        "outputId": "ef152afe-e71b-409f-9919-d2b00b3d715c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train_dev.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 52675 entries, 0 to 52674\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   tweet   52675 non-null  object\n",
            " 1   label   52675 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 823.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S1yCGbAlYYZ"
      },
      "source": [
        "# clean data, remove @someone and urls \n",
        "def clean(s):\n",
        "  s = re.sub('http://\\S+|https://\\S+', '', s)\n",
        "  s = re.sub('@\\S+|@\\S+', '', s)\n",
        "  s = re.sub('#\\S+|#\\S+','',s)\n",
        "  return s\n",
        "  \n",
        "df_train_dev['tweet'] = df_train_dev['tweet'].apply(lambda s: clean(s))\n",
        "df_test['tweet'] = df_test['tweet'].apply(lambda s: clean(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFry5welb5U"
      },
      "source": [
        "# Preprocess the training and testing dataframe. \n",
        "\n",
        "# shuffle datasets\n",
        "df_train = shuffle(df_train_dev, random_state = RANDOM_STATE)\n",
        "df_test = shuffle(df_test, random_state = RANDOM_STATE)\n",
        "  \n",
        "X_train = df_train['tweet']\n",
        "y_train = df_train['label']\n",
        "X_test = df_test['tweet']\n",
        "y_test = df_test['label']\n",
        "  \n",
        "# use bag of words method to vectorize features based on the corpus in training set\n",
        "vectorizer = CountVectorizer().fit(X_train)\n",
        "X_train = vectorizer.transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# numeric encode for y\n",
        "lbl_enc = preprocessing.LabelEncoder().fit(y_train.values)\n",
        "y_train = lbl_enc.transform(y_train.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8glKIWUYlm9c",
        "outputId": "ab5c8e6a-cd0f-404e-8251-cc2bb461e137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train models\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(800,),shuffle=True, random_state=RANDOM_STATE, verbose=True, activation='tanh', solver='adam', early_stopping=True)\n",
        "mlp.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.08286788\n",
            "Validation score: 0.831625\n",
            "Iteration 2, loss = 0.27861275\n",
            "Validation score: 0.845103\n",
            "Iteration 3, loss = 0.10001385\n",
            "Validation score: 0.748481\n",
            "Iteration 4, loss = 0.05138546\n",
            "Validation score: 0.743546\n",
            "Iteration 5, loss = 0.03680021\n",
            "Validation score: 0.738610\n",
            "Iteration 6, loss = 0.03097394\n",
            "Validation score: 0.733675\n",
            "Iteration 7, loss = 0.02722776\n",
            "Validation score: 0.731967\n",
            "Iteration 8, loss = 0.02519911\n",
            "Validation score: 0.730638\n",
            "Iteration 9, loss = 0.02553247\n",
            "Validation score: 0.733106\n",
            "Iteration 10, loss = 0.02533378\n",
            "Validation score: 0.734434\n",
            "Iteration 11, loss = 0.02260676\n",
            "Validation score: 0.731777\n",
            "Iteration 12, loss = 0.02228501\n",
            "Validation score: 0.723424\n",
            "Iteration 13, loss = 0.02217279\n",
            "Validation score: 0.730448\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(800,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66vY7fpnlraE"
      },
      "source": [
        "\n",
        "# predict test labels by the best model of MLPClassifier\n",
        "y_test_pred = mlp.predict(X_test)\n",
        "# inversely transform the numeric labels back to string labels\n",
        "label_pred = lbl_enc.inverse_transform(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjDrFulCl5lj",
        "outputId": "dc2f67c5-246c-4c23-8ffd-7614acdc8a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accur = accuracy_score(y_test, label_pred)\n",
        "print(\"accuracy of MLP model is: %.3f\"% accur)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of MLP model is: 0.842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo3e1ebvmEFI",
        "outputId": "c4eb7317-8340-411b-d138-48a6dfd0c37a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# average macro precision and recall \n",
        "labels = np.unique(y_test)\n",
        "ave_precision = precision_score(y_test, label_pred, labels=labels, average='macro')\n",
        "ave_recall = recall_score(y_test, label_pred, labels=labels, average='macro')\n",
        "print(\"average macro (precision, recall) of MLP: \", (ave_precision, ave_recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average macro (precision, recall) of MLP:  (0.3799551750905021, 0.24026011207184375)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvoFU6eimPrR",
        "outputId": "84011bea-cbab-4eac-fa8d-b6eca797ef2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# precision and recall of each label\n",
        "precision = precision_score(y_test, label_pred, labels=labels, average=None).reshape(-1,1)\n",
        "recall = recall_score(y_test, label_pred, labels=labels, average=None).reshape(-1,1)\n",
        "\n",
        "# concatenate precision and recall of each model\n",
        "metrics = np.concatenate([precision, recall],axis=1)\n",
        "\n",
        "# add column names and row index labels, print metrics \n",
        "metrics = pd.DataFrame(metrics, columns=['precision', 'recall'])\n",
        "metrics.index = labels\n",
        "\n",
        "print('\\nMetrics of Multi-layer perceptron model: \\n', metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Metrics of Multi-layer perceptron model: \n",
            "          precision    recall\n",
            "ar        0.991416  0.873346\n",
            "ar_LATN   0.000000  0.000000\n",
            "az        0.000000  0.000000\n",
            "bg        0.000000  0.000000\n",
            "bs        0.000000  0.000000\n",
            "ca        0.000000  0.000000\n",
            "cs        0.000000  0.000000\n",
            "da        0.000000  0.000000\n",
            "de        0.972973  0.720000\n",
            "el        1.000000  0.090909\n",
            "en        0.957755  0.957755\n",
            "es        0.947368  0.902439\n",
            "eu        0.000000  0.000000\n",
            "fa        1.000000  0.400000\n",
            "fi        0.000000  0.000000\n",
            "fr        0.894009  0.866071\n",
            "he        1.000000  0.071429\n",
            "hi        1.000000  0.250000\n",
            "hi-Latn   0.000000  0.000000\n",
            "hr        0.000000  0.000000\n",
            "ht        0.000000  0.000000\n",
            "id        0.924016  0.833537\n",
            "it        0.964286  0.710526\n",
            "ja        0.661708  0.969330\n",
            "ja_LATN   0.000000  0.000000\n",
            "jv        0.000000  0.000000\n",
            "km        0.000000  0.000000\n",
            "ko        0.942857  0.300000\n",
            "ko_LATN   0.000000  0.000000\n",
            "la        0.000000  0.000000\n",
            "lv        0.000000  0.000000\n",
            "mk        0.000000  0.000000\n",
            "mn        0.000000  0.000000\n",
            "mr        0.000000  0.000000\n",
            "ms        0.571429  0.258065\n",
            "nl        1.000000  0.813953\n",
            "no        0.000000  0.000000\n",
            "pl        0.857143  0.230769\n",
            "pt        0.933530  0.904149\n",
            "ro        0.000000  0.000000\n",
            "ru        0.973822  0.765432\n",
            "sk        0.000000  0.000000\n",
            "sr        0.000000  0.000000\n",
            "sv        1.000000  0.666667\n",
            "sw        0.000000  0.000000\n",
            "ta        0.000000  0.000000\n",
            "ta_LATN   0.000000  0.000000\n",
            "th        0.968750  0.632653\n",
            "tl        0.873016  0.617978\n",
            "tr        0.962687  0.741379\n",
            "uk        0.000000  0.000000\n",
            "und       0.400545  0.239219\n",
            "ur        1.000000  0.400000\n",
            "ur_LATN   0.000000  0.000000\n",
            "vi        1.000000  0.200000\n",
            "xh        0.000000  0.000000\n",
            "yo        0.000000  0.000000\n",
            "zh-CN     0.000000  0.000000\n",
            "zh-TW     0.000000  0.000000\n",
            "zu        0.000000  0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}